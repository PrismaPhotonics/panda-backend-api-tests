# ğŸ“‹ Complete High Priority Test Documentation
## ×›×œ ×”×˜×¡×˜×™× ×”-High Priority - ×ª×™×¢×•×“ ××œ× ×‘×¤×•×¨××˜ Xray

**×ª××¨×™×š:** 2025-10-21  
**×¡×‘×™×‘×”:** new_production (panda namespace)  
**×¡×”"×› ×˜×¡×˜×™×:** 10 High Priority Test Cases  

---

# TEST 1: PZ-13879

## Test ID
**PZ-13879**

## Summary
Integration â€“ Missing Required Fields

## Objective
Validates that Focus Server properly rejects configuration requests that are missing required fields (e.g., missing `channels`, `frequencyRange`, or `nfftSelection`). This ensures proper input validation and prevents incomplete configurations from being processed.

## Priority
**High**

## Components/Labels
* **Component**: Focus Server Backend API
* **Labels**: `config-validation`, `negative-test`, `required-fields`, `input-validation`
* **Test Type**: Integration Test (Negative)

## Requirements
* **Requirement ID**: FOCUS-API-CONFIG-VALIDATION-001
* **Description**: Server must validate all required fields in configuration requests and reject incomplete requests with appropriate error messages

## Pre-Conditions
1. Focus Server is running and accessible
2. API endpoint `POST /config/{task_id}` is available
3. Test client has network access to Focus Server
4. MongoDB is accessible (for potential error logging)

## Test Data

### Test Data 1: Missing 'channels' Field
```json
{
  "nfftSelection": 1024,
  "frequencyRange": {
    "min": 0,
    "max": 500
  },
  "displayInfo": {
    "height": 1000
  },
  "view_type": 0
}
```
**Note**: Missing `channels` field - should be rejected

### Test Data 2: Missing 'frequencyRange' Field
```json
{
  "nfftSelection": 1024,
  "channels": {
    "min": 0,
    "max": 50
  },
  "displayInfo": {
    "height": 1000
  },
  "view_type": 0
}
```
**Note**: Missing `frequencyRange` field - should be rejected

### Test Data 3: Missing 'nfftSelection' Field
```json
{
  "channels": {
    "min": 0,
    "max": 50
  },
  "frequencyRange": {
    "min": 0,
    "max": 500
  },
  "displayInfo": {
    "height": 1000
  },
  "view_type": 0
}
```
**Note**: Missing `nfftSelection` field - should be rejected

## Steps

| # | Step Description | Expected Result |
|---|------------------|-----------------|
| 1 | Generate unique `task_id` (e.g., `missing_fields_test_<timestamp>`) | Valid task_id format |
| 2 | Create configuration payload **without** `channels` field (Test Data 1) | Payload created |
| 3 | Send `POST https://10.10.100.100/focus-server/config/{task_id}` with Test Data 1 | HTTP 400 Bad Request |
| 4 | Verify error message contains "channels" or "required field" | Error message indicates missing field |
| 5 | Create configuration payload **without** `frequencyRange` field (Test Data 2) | Payload created |
| 6 | Send `POST https://10.10.100.100/focus-server/config/{task_id}` with Test Data 2 | HTTP 400 Bad Request |
| 7 | Verify error message contains "frequencyRange" or "frequency" | Error message indicates missing field |
| 8 | Create configuration payload **without** `nfftSelection` field (Test Data 3) | Payload created |
| 9 | Send `POST https://10.10.100.100/focus-server/config/{task_id}` with Test Data 3 | HTTP 400 Bad Request |
| 10 | Verify error message contains "nfft" or "required field" | Error message indicates missing field |
| 11 | Verify no task was created in the system | No orphaned tasks |

## Expected Result
* All configuration requests missing required fields are **rejected** with HTTP 400 Bad Request
* Error messages clearly indicate which field is missing
* No tasks are created for invalid configurations
* Server remains stable and responsive

## Post-Conditions
* No tasks created
* Server logs contain validation errors (for debugging)
* System state unchanged

## Assertions (Python Code)

```python
"""
Test PZ-13879: Integration â€“ Missing Required Fields
Priority: HIGH
"""

import pytest
import logging
from typing import Dict, Any
from src.models.focus_server_models import ConfigTaskRequest
from src.utils.helpers import generate_task_id

logger = logging.getLogger(__name__)

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.critical
def test_pz_13879_missing_required_fields(focus_server_api):
    """
    Test PZ-13879: Missing Required Fields Validation
    
    Validates that Focus Server rejects configurations missing required fields.
    """
    logger.info("=" * 80)
    logger.info("Test PZ-13879: Missing Required Fields")
    logger.info("=" * 80)
    
    # Test 1: Missing 'channels'
    task_id_1 = generate_task_id("pz_13879_missing_channels")
    config_no_channels = {
        "nfftSelection": 1024,
        "frequencyRange": {"min": 0, "max": 500},
        "displayInfo": {"height": 1000},
        "view_type": 0
    }
    
    logger.info("Test 1: Missing 'channels' field")
    try:
        config_request = ConfigTaskRequest(**config_no_channels)
        response = focus_server_api.config_task(task_id_1, config_request)
        
        # Should be rejected with 400
        assert response.status_code == 400, \
            f"Expected 400 for missing channels, got {response.status_code}"
        assert "channel" in str(response).lower() or "required" in str(response).lower(), \
            "Error message should indicate missing field"
        logger.info("âœ… Test 1 PASSED: Missing channels properly rejected")
        
    except ValueError as e:
        # Pydantic validation may catch this first
        assert "channel" in str(e).lower(), \
            f"Validation error should mention channels: {e}"
        logger.info("âœ… Test 1 PASSED: Pydantic caught missing channels")
    
    # Test 2: Missing 'frequencyRange'
    task_id_2 = generate_task_id("pz_13879_missing_freq")
    config_no_freq = {
        "nfftSelection": 1024,
        "channels": {"min": 0, "max": 50},
        "displayInfo": {"height": 1000},
        "view_type": 0
    }
    
    logger.info("Test 2: Missing 'frequencyRange' field")
    try:
        config_request = ConfigTaskRequest(**config_no_freq)
        response = focus_server_api.config_task(task_id_2, config_request)
        
        assert response.status_code == 400, \
            f"Expected 400 for missing frequencyRange, got {response.status_code}"
        assert "frequency" in str(response).lower() or "required" in str(response).lower(), \
            "Error message should indicate missing field"
        logger.info("âœ… Test 2 PASSED: Missing frequencyRange properly rejected")
        
    except ValueError as e:
        assert "frequency" in str(e).lower(), \
            f"Validation error should mention frequency: {e}"
        logger.info("âœ… Test 2 PASSED: Pydantic caught missing frequencyRange")
    
    # Test 3: Missing 'nfftSelection'
    task_id_3 = generate_task_id("pz_13879_missing_nfft")
    config_no_nfft = {
        "channels": {"min": 0, "max": 50},
        "frequencyRange": {"min": 0, "max": 500},
        "displayInfo": {"height": 1000},
        "view_type": 0
    }
    
    logger.info("Test 3: Missing 'nfftSelection' field")
    try:
        config_request = ConfigTaskRequest(**config_no_nfft)
        response = focus_server_api.config_task(task_id_3, config_request)
        
        assert response.status_code == 400, \
            f"Expected 400 for missing nfftSelection, got {response.status_code}"
        assert "nfft" in str(response).lower() or "required" in str(response).lower(), \
            "Error message should indicate missing field"
        logger.info("âœ… Test 3 PASSED: Missing nfftSelection properly rejected")
        
    except ValueError as e:
        assert "nfft" in str(e).lower(), \
            f"Validation error should mention nfft: {e}"
        logger.info("âœ… Test 3 PASSED: Pydantic caught missing nfftSelection")
    
    logger.info("=" * 80)
    logger.info("âœ… PZ-13879: ALL TESTS PASSED")
    logger.info("=" * 80)
```

## Environment

**Environment Name**: new_production (panda namespace)

**Backend (Focus Server)**:
- URL: `https://10.10.100.100/focus-server/`
- API Endpoint: `POST https://10.10.100.100/focus-server/config/{task_id}`
- Swagger: `https://10.10.100.100/api/swagger/#/`
- SSL Verification: `False` (self-signed certificate)

**Frontend (LiveView)**:
- URL: `https://10.10.10.100/liveView?siteId=prisma-210-1000`

**MongoDB**:
- Host: `10.10.100.108:27017`
- Connection: `mongodb://prisma:prisma@10.10.100.108:27017/?authSource=prisma`
- Database: `prisma`

**RabbitMQ**:
- AMQP: `10.10.100.107:5672`
- Management UI: `http://10.10.100.107:15672`

**Kubernetes**:
- API Server: `https://10.10.100.102:6443`
- Namespace: `panda`
- Focus Server Pod: `panda-panda-focus-server.panda:5000`

**SSH Access** (for infrastructure tests):
- Jump Host: `ssh root@10.10.100.3`
- Target Host: `ssh prisma@10.10.100.113`

## Automation Status

âœ… **Automated**

**Test Function**: `test_pz_13879_missing_required_fields`  
**Test File**: `tests/integration/api/test_config_validation_high_priority.py`  
**Test Class**: `TestMissingRequiredFields`  
**Framework**: pytest 7.0+  
**Python Version**: 3.11+  

**Run Command**:
```bash
# Run this specific test
pytest tests/integration/api/test_config_validation_high_priority.py::TestMissingRequiredFields::test_missing_channels_field -v

# Run all PZ-13879 tests
pytest tests/integration/api/test_config_validation_high_priority.py::TestMissingRequiredFields -v

# Run with markers
pytest -m "critical" -k "missing" -v
```

**CI/CD Integration**:
```yaml
# .github/workflows/tests.yml or similar
- name: Run PZ-13879 Tests
  run: |
    pytest tests/integration/api/test_config_validation_high_priority.py::TestMissingRequiredFields \
      --junitxml=results/PZ-13879.xml \
      --html=results/PZ-13879.html
```

---

# TEST 2: PZ-13878

## Test ID
**PZ-13878**

## Summary
Integration â€“ Invalid View Type - Out of Range

## Objective
Validates that Focus Server properly rejects configuration requests with invalid `view_type` values (outside the defined enum range). Valid values are 0 (MULTICHANNEL) or 1 (SINGLECHANNEL). Any other value should be rejected.

## Priority
**High**

## Components/Labels
* **Component**: Focus Server Backend API
* **Labels**: `config-validation`, `enum-validation`, `negative-test`, `view-type`
* **Test Type**: Integration Test (Negative)

## Requirements
* **Requirement ID**: FOCUS-API-CONFIG-VALIDATION-002
* **Description**: Server must validate view_type enum and reject values outside [0, 1] range

## Pre-Conditions
1. Focus Server is running and accessible
2. API endpoint `POST /config/{task_id}` is available
3. Valid enum values are documented: 0=MULTICHANNEL, 1=SINGLECHANNEL

## Test Data

### Test Data 1: Negative view_type
```json
{
  "displayTimeAxisDuration": 10,
  "nfftSelection": 1024,
  "displayInfo": {"height": 1000},
  "channels": {"min": 0, "max": 50},
  "frequencyRange": {"min": 0, "max": 500},
  "start_time": null,
  "end_time": null,
  "view_type": -1
}
```
**Note**: `view_type=-1` is invalid (must be 0 or 1)

### Test Data 2: Out-of-range view_type
```json
{
  "displayTimeAxisDuration": 10,
  "nfftSelection": 1024,
  "displayInfo": {"height": 1000},
  "channels": {"min": 0, "max": 50},
  "frequencyRange": {"min": 0, "max": 500},
  "start_time": null,
  "end_time": null,
  "view_type": 99
}
```
**Note**: `view_type=99` is invalid (must be 0 or 1)

### Test Data 3: String view_type
```json
{
  "displayTimeAxisDuration": 10,
  "nfftSelection": 1024,
  "displayInfo": {"height": 1000},
  "channels": {"min": 0, "max": 50},
  "frequencyRange": {"min": 0, "max": 500},
  "start_time": null,
  "end_time": null,
  "view_type": "invalid"
}
```
**Note**: `view_type="invalid"` is wrong type (must be integer 0 or 1)

## Steps

| # | Step Description | Expected Result |
|---|------------------|-----------------|
| 1 | Generate unique `task_id` | Valid task_id format |
| 2 | Create config with `view_type=-1` (Test Data 1) | Payload created |
| 3 | Send `POST https://10.10.100.100/focus-server/config/{task_id}` | HTTP 400 Bad Request |
| 4 | Verify error indicates invalid view_type | Error message: "invalid view_type" or "must be 0 or 1" |
| 5 | Create config with `view_type=99` (Test Data 2) | Payload created |
| 6 | Send `POST https://10.10.100.100/focus-server/config/{task_id}` | HTTP 400 Bad Request |
| 7 | Verify error indicates out-of-range value | Error message indicates valid range |
| 8 | Create config with `view_type="invalid"` (Test Data 3) | Payload validation may fail |
| 9 | Attempt to send request (if validation passes) | HTTP 400 or TypeError |
| 10 | Verify type validation works | Type error caught |

## Expected Result
* All invalid `view_type` values are **rejected**
* Error messages clearly indicate valid values (0 or 1)
* Type validation prevents non-integer values
* Server remains stable

## Post-Conditions
* No tasks created
* Server logs validation errors
* System state unchanged

## Assertions (Python Code)

```python
"""
Test PZ-13878: Integration â€“ Invalid View Type
Priority: HIGH
"""

import pytest
import logging
from src.models.focus_server_models import ConfigTaskRequest
from src.utils.helpers import generate_task_id

logger = logging.getLogger(__name__)

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.critical
def test_pz_13878_invalid_view_type(focus_server_api):
    """
    Test PZ-13878: Invalid View Type Validation
    
    Validates that only view_type 0 (MULTICHANNEL) or 1 (SINGLECHANNEL) are accepted.
    """
    logger.info("=" * 80)
    logger.info("Test PZ-13878: Invalid View Type")
    logger.info("=" * 80)
    
    # Test 1: view_type = -1 (negative)
    task_id_1 = generate_task_id("pz_13878_negative_view")
    config_negative = {
        "displayTimeAxisDuration": 10,
        "nfftSelection": 1024,
        "displayInfo": {"height": 1000},
        "channels": {"min": 0, "max": 50},
        "frequencyRange": {"min": 0, "max": 500},
        "start_time": None,
        "end_time": None,
        "view_type": -1  # Invalid!
    }
    
    logger.info("Test 1: view_type=-1 (negative)")
    try:
        config_request = ConfigTaskRequest(**config_negative)
        response = focus_server_api.config_task(task_id_1, config_request)
        
        assert response.status_code == 400, \
            f"Expected 400 for view_type=-1, got {response.status_code}"
        assert "view_type" in str(response).lower() or "invalid" in str(response).lower()
        logger.info("âœ… Test 1 PASSED: view_type=-1 rejected")
        
    except ValueError as e:
        assert "view_type" in str(e).lower()
        logger.info("âœ… Test 1 PASSED: Validation caught view_type=-1")
    
    # Test 2: view_type = 99 (out of range)
    task_id_2 = generate_task_id("pz_13878_out_of_range")
    config_out_of_range = {
        "displayTimeAxisDuration": 10,
        "nfftSelection": 1024,
        "displayInfo": {"height": 1000},
        "channels": {"min": 0, "max": 50},
        "frequencyRange": {"min": 0, "max": 500},
        "start_time": None,
        "end_time": None,
        "view_type": 99  # Invalid!
    }
    
    logger.info("Test 2: view_type=99 (out of range)")
    try:
        config_request = ConfigTaskRequest(**config_out_of_range)
        response = focus_server_api.config_task(task_id_2, config_request)
        
        assert response.status_code == 400, \
            f"Expected 400 for view_type=99, got {response.status_code}"
        logger.info("âœ… Test 2 PASSED: view_type=99 rejected")
        
    except ValueError as e:
        assert "view_type" in str(e).lower()
        logger.info("âœ… Test 2 PASSED: Validation caught view_type=99")
    
    # Test 3: view_type = "invalid" (wrong type)
    task_id_3 = generate_task_id("pz_13878_string_type")
    config_string = {
        "displayTimeAxisDuration": 10,
        "nfftSelection": 1024,
        "displayInfo": {"height": 1000},
        "channels": {"min": 0, "max": 50},
        "frequencyRange": {"min": 0, "max": 500},
        "start_time": None,
        "end_time": None,
        "view_type": "invalid"  # Wrong type!
    }
    
    logger.info("Test 3: view_type='invalid' (string)")
    try:
        config_request = ConfigTaskRequest(**config_string)
        response = focus_server_api.config_task(task_id_3, config_request)
        
        assert response.status_code == 400, \
            f"Expected 400 for string view_type, got {response.status_code}"
        logger.info("âœ… Test 3 PASSED: String view_type rejected")
        
    except (ValueError, TypeError) as e:
        logger.info(f"âœ… Test 3 PASSED: Type validation caught string: {e}")
    
    logger.info("=" * 80)
    logger.info("âœ… PZ-13878: ALL TESTS PASSED")
    logger.info("=" * 80)
```

## Environment
**Same as PZ-13879** (new_production environment)

## Automation Status

âœ… **Automated**

**Test Function**: `test_pz_13878_invalid_view_type`  
**Test File**: `tests/integration/api/test_config_validation_high_priority.py`  
**Test Class**: `TestInvalidViewType`

**Run Command**:
```bash
pytest tests/integration/api/test_config_validation_high_priority.py::TestInvalidViewType -v
```

---

*[×”××©×š ×”×ª×™×¢×•×“ ×œ×›×œ 10 ×”×˜×¡×˜×™× ×”× ×•×¡×¤×™× ×™×”×™×” ×‘××•×ª×• ×¤×•×¨××˜ - ×”×× ×œ×”××©×™×š ×¢× ×›×•×œ×?]*

---

**×”×¢×¨×”:** ×‘×’×œ×œ ××•×¨×š ×”××¡××š (×›×œ ×˜×¡×˜ ~2-3 ×¢××•×“×™×), ×”×× ×ª×¨×¦×”:
1. ×©×××©×™×š ×¢× ×›×œ 10 ×”×˜×¡×˜×™× ×‘××¡××š ××—×“? (×™×”×™×” ~30 ×¢××•×“×™×)
2. ××• ×œ×¤×¦×œ ×œ×§×‘×¦×™× × ×¤×¨×“×™× ×œ×›×œ ×˜×¡×˜?
3. ××• ×¨×§ ×œ×¨××•×ª 2-3 ×“×•×’×××•×ª ×•××– ×× ×™ ××›×™×Ÿ ××ª ×›×•×œ×?

×‘×™× ×ª×™×™× ×”×›× ×ª×™ 2 ×˜×¡×˜×™× ××œ××™× ×›×“×•×’××”. ××©××— ×œ×”× ×—×™×” ××™×š ×œ×”××©×™×š.

