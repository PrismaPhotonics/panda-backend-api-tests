name: Tests - Simple (Local Runner with VPN)

on:
  workflow_dispatch:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: self-hosted  # ×–×” ×™×¨×•×¥ ×¢×œ ×”××—×©×‘ ×©×œ×š
    name: Run Tests (Local with VPN)
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        shell: powershell
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install dependencies in stages to avoid resolution conflicts
          # Stage 1: Core pytest packages
          pip install --no-cache-dir --prefer-binary pytest==8.2.0 pytest-asyncio==0.23.0 pytest-timeout==2.3.0 pytest-mock==3.14.0 pytest-html==4.1.1 pytest-cov==5.0.0 pytest-json-report==1.5.0 pytest-xdist==3.6.0
          # Stage 2: HTTP and data processing
          pip install --no-cache-dir --prefer-binary requests==2.32.3 httpx==0.27.0 beautifulsoup4==4.12.3 pydantic==2.9.0 pydantic-settings==2.5.0 orjson==3.10.0 pyyaml==6.0.1
          # Stage 3: Infrastructure and utilities
          pip install --no-cache-dir --prefer-binary kubernetes==30.1.0 pymongo==4.10.0 paramiko==3.5.0 pika==1.3.2 structlog==24.4.0 colorlog==6.8.2 python-dateutil==2.9.0 pytz==2024.1 psutil==5.9.8 python-dotenv==1.0.1 netaddr==0.10.1 jira==3.10.5
          # Stage 4: Browser automation (problematic packages)
          pip install --no-cache-dir --prefer-binary playwright==1.48.0 pytest-playwright==0.4.3; if ($LASTEXITCODE -ne 0) { Write-Host "pytest-playwright installation failed, continuing..." }
          # Stage 5: Reporting and optional packages
          pip install --no-cache-dir --prefer-binary allure-pytest==2.13.2 jinja2==3.1.4 asyncio-mqtt==0.16.2 aiofiles==24.1.0 pytest-xray==0.2.1; if ($LASTEXITCODE -ne 0) { Write-Host "Optional packages installation failed, continuing..." }
          # Stage 6: Development tools (optional, can fail)
          pip install --no-cache-dir --prefer-binary black==24.8.0 flake8==7.1.1 mypy==1.11.0 isort==5.13.2 cryptography==43.0.0 bandit==1.7.8 sphinx==8.1.3 sphinx-rtd-theme==3.0.2; if ($LASTEXITCODE -ne 0) { Write-Host "Dev tools installation failed, continuing..." }
      
      - name: Check Focus Server availability
        id: check_focus
        shell: powershell
        env:
          FOCUS_BASE_URL: ${{ secrets.FOCUS_BASE_URL }}
          FOCUS_API_PREFIX: ${{ secrets.FOCUS_API_PREFIX || '/focus-server' }}
        run: |
          if (-not $env:FOCUS_BASE_URL) {
            Write-Host "âš ï¸ FOCUS_BASE_URL secret not configured - tests requiring Focus Server will be skipped"
            Write-Host "â„¹ï¸  To enable Focus Server tests, configure FOCUS_BASE_URL secret in repository settings"
            echo "available=false" | Out-File -FilePath $env:GITHUB_OUTPUT -Append -Encoding utf8
          } else {
            $base = "$($env:FOCUS_BASE_URL.TrimEnd('/'))$($env:FOCUS_API_PREFIX)"
            Write-Host "Checking Focus Server at $base/ack (health check endpoint)"
            try {
              $response = Invoke-WebRequest -Uri "$base/ack" -Method Get -SkipCertificateCheck -TimeoutSec 10 -ErrorAction Stop
              if ($response.StatusCode -ge 200 -and $response.StatusCode -lt 500) {
                echo "available=true" | Out-File -FilePath $env:GITHUB_OUTPUT -Append -Encoding utf8
                Write-Host "âœ… Focus Server is reachable (HTTP $($response.StatusCode))"
                # Also check channels endpoint
                try {
                  $channelsResponse = Invoke-WebRequest -Uri "$base/channels" -Method Get -SkipCertificateCheck -TimeoutSec 10 -ErrorAction Stop
                  Write-Host "âœ… Focus Server channels endpoint is also accessible"
                } catch {
                  Write-Host "âš ï¸ Channels endpoint check failed (this is OK)"
                }
              } else {
                echo "available=false" | Out-File -FilePath $env:GITHUB_OUTPUT -Append -Encoding utf8
                Write-Host "âš ï¸ Focus Server returned unexpected status (HTTP $($response.StatusCode))"
              }
            } catch {
              echo "available=false" | Out-File -FilePath $env:GITHUB_OUTPUT -Append -Encoding utf8
              Write-Host "âš ï¸ Focus Server not reachable - tests requiring Focus Server will be skipped"
              Write-Host "â„¹ï¸  This is expected if Focus Server is not accessible"
            }
          }

      - name: Run tests
        id: run-tests
        shell: powershell
        working-directory: ${{ github.workspace }}
        env:
          PYTHONPATH: ${{ github.workspace }}
          # Set environment variable to indicate if Focus Server is available
          FOCUS_SERVER_AVAILABLE: ${{ steps.check_focus.outputs.available }}
          # Allow Focus Server URL override via secrets (if available)
          FOCUS_BASE_URL: ${{ secrets.FOCUS_BASE_URL }}
          FOCUS_API_PREFIX: ${{ secrets.FOCUS_API_PREFIX || '/focus-server' }}
          VERIFY_SSL: ${{ secrets.VERIFY_SSL || 'false' }}
        run: |
          New-Item -ItemType Directory -Force -Path reports, logs, screenshots | Out-Null
          $testExitCode = 0
          $env:PYTHONPATH = "$(Get-Location)"
          Write-Host "Current directory: $(Get-Location)"
          Write-Host "PYTHONPATH: $env:PYTHONPATH"
          Write-Host "Checking if mongodb_monitoring_agent exists:"
          Test-Path src\infrastructure\mongodb_monitoring_agent.py
          # Run tests excluding load/stress tests
          # Since this is a self-hosted runner with VPN, infrastructure tests should work
          # Override testpaths from pytest.ini to avoid conflicts
          pytest be_focus_server_tests/ `
            --env=local `
            --skip-health-check `
            --skip-sanity-check `
            --override-ini="testpaths=" `
            --ignore=be_focus_server_tests/load `
            --ignore=be_focus_server_tests/stress `
            --ignore-glob=**/integration/load `
            --ignore-glob=**/test_alert_generation_load.py `
            --ignore-glob=**/test_alert_generation_performance.py `
            -m "not load and not stress and not grpc" `
            -v `
            --tb=short `
            --junitxml=reports/junit.xml `
            --html=reports/report.html `
            --self-contained-html `
            --maxfail=10 `
            --continue-on-collection-errors
          if ($LASTEXITCODE -ne 0) { $testExitCode = $LASTEXITCODE }
          # Always continue (we'll upload results even if tests failed)
          exit $testExitCode
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_id }}
          path: |
            reports/
            logs/
            screenshots/
          retention-days: 30
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Parse JUnit XML to get test results
            let passed = 0;
            let failed = 0;
            let total = 0;
            
            try {
              const junitXml = fs.readFileSync('reports/junit.xml', 'utf8');
              const testsuites = junitXml.match(/testsuites[^>]*/);
              if (testsuites) {
                const failures = junitXml.match(/failures="(\d+)"/);
                const errors = junitXml.match(/errors="(\d+)"/);
                const tests = junitXml.match(/tests="(\d+)"/);
                
                failed = parseInt(failures?.[1] || 0) + parseInt(errors?.[1] || 0);
                total = parseInt(tests?.[1] || 0);
                passed = total - failed;
              }
            } catch (e) {
              console.log('Could not parse JUnit XML:', e.message);
            }
            
            const comment = `## ğŸ§ª Test Results\n\n### Results\n- âœ… **Passed:** ${passed}\n- âŒ **Failed:** ${failed}\n- ğŸ“Š **Total:** ${total}\n\n### Artifacts\n- ğŸ“ [Download Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n\n---\n*Note: Results are not uploaded to Xray. Upload manually if needed.*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail job if tests failed
        if: steps.run-tests.outcome == 'failure'
        shell: powershell
        run: |
          Write-Host "âŒ Tests failed - check artifacts for details"
          exit 1

