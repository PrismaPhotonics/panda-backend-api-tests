name: Tests - Simple (No Xray API)

on:
  workflow_dispatch:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    name: Run Tests
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install dependencies in stages to avoid resolution conflicts
          # Stage 1: Core pytest packages
          pip install --no-cache-dir --prefer-binary \
            pytest==8.2.0 \
            pytest-asyncio==0.23.0 \
            pytest-timeout==2.3.0 \
            pytest-mock==3.14.0 \
            pytest-html==4.1.1 \
            pytest-cov==5.0.0 \
            pytest-json-report==1.5.0 \
            pytest-xdist==3.6.0
          # Stage 2: HTTP and data processing
          pip install --no-cache-dir --prefer-binary \
            requests==2.32.3 \
            httpx==0.27.0 \
            beautifulsoup4==4.12.3 \
            pydantic==2.9.0 \
            pydantic-settings==2.5.0 \
            orjson==3.10.0 \
            pyyaml==6.0.1
          # Stage 3: Infrastructure and utilities
          pip install --no-cache-dir --prefer-binary \
            kubernetes==30.1.0 \
            pymongo==4.10.0 \
            paramiko==3.5.0 \
            pika==1.3.2 \
            structlog==24.4.0 \
            colorlog==6.8.2 \
            python-dateutil==2.9.0 \
            pytz==2024.1 \
            psutil==5.9.8 \
            python-dotenv==1.0.1 \
            netaddr==0.10.1 \
            jira==3.10.5
          # Stage 4: Browser automation (problematic packages)
          pip install --no-cache-dir --prefer-binary \
            playwright==1.48.0 \
            pytest-playwright==0.4.3 || true
          # Stage 5: Reporting and optional packages
          pip install --no-cache-dir --prefer-binary \
            allure-pytest==2.13.2 \
            jinja2==3.1.4 \
            asyncio-mqtt==0.16.2 \
            aiofiles==24.1.0 \
            pytest-xray==0.2.1 || true
          # Stage 6: Development tools (optional, can fail)
          pip install --no-cache-dir --prefer-binary \
            black==24.8.0 \
            flake8==7.1.1 \
            mypy==1.11.0 \
            isort==5.13.2 \
            cryptography==43.0.0 \
            bandit==1.7.8 \
            sphinx==8.1.3 \
            sphinx-rtd-theme==3.0.2 || true
      
      - name: Run tests
        id: run-tests
        run: |
          mkdir -p reports logs screenshots
          pytest be_focus_server_tests/ -v \
            --junitxml=reports/junit.xml \
            --html=reports/report.html \
            --self-contained-html \
            --tb=short \
            --override-ini="testpaths=" \
            || TEST_EXIT_CODE=$?
          # Always continue (we'll upload results even if tests failed)
          exit ${TEST_EXIT_CODE:-0}
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_id }}
          path: |
            reports/
            logs/
            screenshots/
          retention-days: 30
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Parse JUnit XML to get test results
            let passed = 0;
            let failed = 0;
            let total = 0;
            
            try {
              const junitXml = fs.readFileSync('reports/junit.xml', 'utf8');
              const testsuites = junitXml.match(/testsuites[^>]*/);
              if (testsuites) {
                const failures = junitXml.match(/failures="(\d+)"/);
                const errors = junitXml.match(/errors="(\d+)"/);
                const tests = junitXml.match(/tests="(\d+)"/);
                
                failed = parseInt(failures?.[1] || 0) + parseInt(errors?.[1] || 0);
                total = parseInt(tests?.[1] || 0);
                passed = total - failed;
              }
            } catch (e) {
              console.log('Could not parse JUnit XML:', e.message);
            }
            
            const comment = `## ğŸ§ª Test Results\n\n### Results\n- âœ… **Passed:** ${passed}\n- âŒ **Failed:** ${failed}\n- ğŸ“Š **Total:** ${total}\n\n### Artifacts\n- ğŸ“ [Download Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n\n---\n*Note: Results are not uploaded to Xray. Upload manually if needed.*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail job if tests failed
        if: steps.run-tests.outcome == 'failure'
        run: |
          echo "âŒ Tests failed - check artifacts for details"
          exit 1

