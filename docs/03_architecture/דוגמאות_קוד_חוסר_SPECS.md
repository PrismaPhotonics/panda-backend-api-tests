# ğŸ“Œ ×“×•×’×××•×ª ×§×•×“ - ×—×•×¡×¨ Specs ×‘××¢×¨×›×ª
## ×§×™×©×•×¨×™× ××“×•×™×§×™× ×œ×§×•×“ ×©××¨××™× ××ª ×”×‘×¢×™×•×ª

**×ª××¨×™×š:** 22 ××•×§×˜×•×‘×¨ 2025  
**××˜×¨×”:** ×“×•×’×××•×ª ×××©×™×•×ª ××”×§×•×“ ×œ×”×¦×’×” ×‘×¤×’×™×©×”  

---

## ğŸ”´ **1. ROI Change Limit - 50% Hardcoded**

### ğŸ“ **××™×§×•×:** `src/utils/validators.py:390-460`

```python
def validate_roi_change_safety(
    current_min: int,
    current_max: int,
    new_min: int,
    new_max: int,
    max_change_percent: float = 50.0  # âŒ HARDCODED - ××™×Ÿ specs!
) -> Dict[str, Any]:
    """
    Validate ROI change is safe (not too drastic).
    
    Large ROI changes can cause processing disruptions.
    """
```

**×”×‘×¢×™×”:**
- âœ… ×”×§×•×“: `max_change_percent: float = 50.0`
- â“ **××£ ××—×“ ×œ× ××™×©×¨ ×©×–×” × ×›×•×Ÿ!**
- â“ ××” ×× ×¦×¨×™×š 30%? ××• 70%?

**×”×©×¤×¢×”:**
- 6 ×˜×¡×˜×™× ××¡×ª××›×™× ×¢×œ ×”×¢×¨×š ×”×–×”
- ××™×Ÿ ××™×©×•×¨ ××”×¦×•×•×ª ×©×–×” ×”×¢×¨×š ×”× ×›×•×Ÿ

**×§×™×©×•×¨ ×œ×§×•×“:**
```
src/utils/validators.py
Line 395: max_change_percent: float = 50.0
```

---

## ğŸ”´ **2. Performance Thresholds - TODO Comments**

### ğŸ“ **××™×§×•×:** `tests/integration/performance/test_performance_high_priority.py:140-170`

```python
def test_p95_p99_latency_post_config(self, focus_server_api):
    """Test PZ-13770: P95/P99 latency for POST /config"""
    
    # ... test code ...
    
    # TODO: Update thresholds after specs meeting
    # For now, use reasonable defaults for high-performance API
    THRESHOLD_P95_MS = 500   # 500ms for P95  âŒ ××™×Ÿ specs!
    THRESHOLD_P99_MS = 1000  # 1000ms for P99  âŒ ××™×Ÿ specs!
    MAX_ERROR_RATE = 0.05    # 5% error rate     âŒ ××™×Ÿ specs!
    
    # Assertions
    error_rate = errors / num_requests
    assert error_rate <= MAX_ERROR_RATE
    
    # TODO: Uncomment after specs meeting
    # assert p95 < THRESHOLD_P95_MS   âŒ ××•×©×‘×ª!
    # assert p99 < THRESHOLD_P99_MS   âŒ ××•×©×‘×ª!
    
    # For now, just log warning if exceeds reasonable thresholds
    if p95 >= THRESHOLD_P95_MS:
        logger.warning(f"âš ï¸ P95 latency {p95:.2f}ms >= {THRESHOLD_P95_MS}ms (would fail if enforced)")
```

**×”×‘×¢×™×”:**
- âœ… ×”×˜×¡×˜ ×§×™×™×
- âŒ ×”-assertions **××•×©×‘×ª×•×ª** ×›×™ ××™×Ÿ specs!
- âŒ ×¨×§ ××–×”×™×¨×™× ×‘××§×•× ×œ×›×©×œ

**×”×©×¤×¢×”:**
- 28 performance tests ×œ×œ× thresholds
- ××™ ××¤×©×¨ ×œ×–×”×•×ª degradation

**×§×™×©×•×¨×™× ×œ×§×•×“:**
```
tests/integration/performance/test_performance_high_priority.py
Line 146: # TODO: Update thresholds after specs meeting
Line 148: THRESHOLD_P95_MS = 500   # âŒ No official spec
Line 149: THRESHOLD_P99_MS = 1000  # âŒ No official spec
Line 157: # TODO: Uncomment after specs meeting
Line 158-162: assertions commented out!
```

---

## ğŸ”´ **3. API Response Time - TODO Comments**

### ğŸ“ **××™×§×•×:** `tests/integration/api/test_api_endpoints_high_priority.py:135-147`

```python
def test_get_channels_endpoint_response_time(self, focus_server_api):
    """Test PZ-13419.1: GET /channels response time"""
    
    start_time = time.time()
    channels = focus_server_api.get_channels()
    end_time = time.time()
    
    response_time_ms = (end_time - start_time) * 1000
    
    logger.info(f"Response time: {response_time_ms:.2f}ms")
    
    # TODO: Update threshold after specs meeting
    # For now, use 1000ms as reasonable threshold
    MAX_RESPONSE_TIME_MS = 1000  # âŒ ××™×Ÿ specs!
    
    assert response_time_ms < MAX_RESPONSE_TIME_MS
```

**×”×‘×¢×™×”:**
- ×¢×¨×š "×¡×‘×™×¨" (`1000ms`) ××‘×œ ×œ× ××‘×•×¡×¡ spec
- ××” ×× ×”×¦×•×•×ª ×¨×•×¦×” 200ms? ××• 3000ms?

**×§×™×©×•×¨ ×œ×§×•×“:**
```
tests/integration/api/test_api_endpoints_high_priority.py
Line 140: # TODO: Update threshold after specs meeting
Line 142: MAX_RESPONSE_TIME_MS = 1000  # âŒ Arbitrary value
```

---

## ğŸ”´ **4. Frequency Range - ××§×‘×œ ×¢×¨×›×™× ×©×œ×™×œ×™×™×!**

### ğŸ“ **××™×§×•×:** `src/utils/validators.py:153-191`

```python
def validate_frequency_range(min_freq: int, max_freq: int, prr: float) -> bool:
    """Validate frequency range against pulse repetition rate."""
    
    if not isinstance(min_freq, int) or not isinstance(max_freq, int):
        raise ValidationError("Frequency values must be integers")
    
    if min_freq < 0 or max_freq < 0:
        raise ValidationError("Frequency values must be non-negative")
    
    # âœ… ×™×© check ×©×–×” ×œ× ×©×œ×™×œ×™
    # âŒ ××‘×œ ××™×Ÿ check ×œ××§×¡×™××•×!
    # âŒ ××™×Ÿ check ×œ×˜×•×•×— ××™× ×™××œ×™!
```

**××‘×œ ×‘×¤×•×¢×œ ×‘models:**
```python
# src/models/focus_server_models.py:46-57
class FrequencyRange(BaseModel):
    """Frequency range configuration."""
    min: int = Field(..., description="Minimum frequency required", ge=0)  # âœ… >= 0
    max: int = Field(..., description="Maximum frequency required", ge=0)  # âœ… >= 0
    
    @field_validator('max')
    @classmethod
    def validate_frequency_range(cls, v: int, info: ValidationInfo) -> int:
        if info.data.get('min') and v < info.data['min']:
            raise ValueError('max frequency must be >= min frequency')
        return v
    
    # âŒ ××™×Ÿ ×‘×“×™×§×” ×œ××§×¡×™××•× ××‘×¡×•×œ×•×˜×™!
    # âŒ ××™×Ÿ ×‘×“×™×§×” ×œ×˜×•×•×— ××™× ×™××œ×™!
```

**×”×‘×¢×™×”:**
- ××™×Ÿ ××§×¡×™××•× frequency ××•×’×“×¨
- ××™×Ÿ ×˜×•×•×— ××™× ×™××œ×™ ××•×’×“×¨
- ××” ×× ××™×©×”×• ×©×•×œ×— `{"min": 0, "max": 999999}`?

**×§×™×©×•×¨×™× ×œ×§×•×“:**
```
src/utils/validators.py
Line 174: if min_freq < 0 or max_freq < 0  # Check for negative
Line 177-180: if max_freq <= min_freq       # Check order
Line 182-189: Nyquist check                 # Check PRR
âŒ No absolute max check!
âŒ No minimum range check!

src/models/focus_server_models.py
Line 48: min: int = Field(..., ge=0)  # Only >= 0
Line 49: max: int = Field(..., ge=0)  # Only >= 0
âŒ No upper limit!
```

---

## ğŸ”´ **5. NFFT - ××§×‘×œ ×›×œ ×¢×¨×š!**

### ğŸ“ **××™×§×•×:** `src/utils/validators.py:194-227`

```python
def validate_nfft_value(nfft: int) -> bool:
    """Validate NFFT value (should be power of 2 for efficiency)."""
    
    if not isinstance(nfft, int):
        raise ValidationError("NFFT must be an integer")
    
    if nfft <= 0:
        raise ValidationError("NFFT must be positive")
    
    # Check if power of 2 (for efficiency)
    is_power_of_2 = (nfft & (nfft - 1)) == 0
    
    if not is_power_of_2:
        import warnings
        warnings.warn(
            f"NFFT={nfft} is not a power of 2. Performance may be suboptimal."
        )  # âŒ ×¨×§ ××–×”×¨×”! ×œ× ×“×•×—×”!
    
    return True  # âœ… ×ª××™×“ ××—×–×™×¨ True!
```

**×”×‘×¢×™×”:**
- âœ… ×‘×•×“×§ ×©×–×” ×—×™×•×‘×™
- âš ï¸ ××–×”×™×¨ ×× ×œ× power of 2
- âŒ **×œ× ×“×•×—×”** ×¢×¨×›×™× ×œ× ×—×•×§×™×™×!
- âŒ ××™×Ÿ ××§×¡×™××•×!
- âŒ ××™×Ÿ ×¨×©×™××” ×©×œ ×¢×¨×›×™× ×—×•×§×™×™×!

**×“×•×’××”:**
```python
validate_nfft_value(1000)     # âš ï¸ Warning, ××‘×œ ×¢×•×‘×¨!
validate_nfft_value(999999)   # âš ï¸ Warning, ××‘×œ ×¢×•×‘×¨!
validate_nfft_value(-100)     # âŒ × ×“×—×” (×©×œ×™×œ×™)
```

**××‘×œ ×‘config ×”××¢×¨×›×ª:**
```yaml
# config/environments.yaml (new_production)
nfft:
  default: 1024
  valid_values:
    - 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536
```

**×”×‘×¢×™×”:** ×”×§×•×“ ×œ× ××•×›×£ ××ª ×”×¨×©×™××”!

**×§×™×©×•×¨×™× ×œ×§×•×“:**
```
src/utils/validators.py
Line 213: if nfft <= 0  # Only checks positive
Line 217: is_power_of_2 = ...  # Soft check
Line 219-224: warnings.warn()  # âŒ Just warns, doesn't reject!

config/environments.yaml
Line 31-41: valid_values list exists
âŒ But code doesn't use it!
```

---

## ğŸ”´ **6. Sensor Range - ××™×Ÿ ×’×‘×•×œ ××§×¡×™××œ×™!**

### ğŸ“ **××™×§×•×:** `src/utils/validators.py:116-151`

```python
def validate_sensor_range(min_sensor: int, max_sensor: int, total_sensors: int) -> bool:
    """Validate sensor range against total available sensors."""
    
    if min_sensor < 0 or max_sensor < 0:
        raise ValidationError("Sensor indices must be non-negative")
    
    if max_sensor <= min_sensor:
        raise ValidationError(
            f"max_sensor ({max_sensor}) must be > min_sensor ({min_sensor})"
        )
    
    if max_sensor >= total_sensors:
        raise ValidationError(
            f"max_sensor ({max_sensor}) exceeds total sensors ({total_sensors})"
        )
    
    # âŒ ××™×Ÿ ×‘×“×™×§×” ×œ×˜×•×•×— ××™× ×™××œ×™!
    # âŒ ××” ×× sensors_min=0, sensors_max=1? (×¨×§ ×¡× ×¡×•×¨ ××—×“!)
    
    return True
```

**×”×‘×¢×™×”:**
- ××™×Ÿ ×˜×•×•×— ××™× ×™××œ×™ (×œ××©×œ: ×œ×¤×—×•×ª 10 sensors)
- ××™×Ÿ ×˜×•×•×— ××§×¡×™××œ×™ (×œ××©×œ: ××§×¡×™××•× 1000 sensors)

**×‘config ×”××¢×¨×›×ª:**
```yaml
# config/environments.yaml (new_production)
constraints:
  sensors:
    total_range: 2222           # ××§×¡×™××•× ××•×—×œ×˜
    default_start: 11           # ×‘×¨×™×¨×ª ××—×“×œ
    default_end: 109            # ×‘×¨×™×¨×ª ××—×“×œ
    # âŒ ××™×Ÿ min_roi_size
    # âŒ ××™×Ÿ max_roi_size
```

**×§×™×©×•×¨×™× ×œ×§×•×“:**
```
src/utils/validators.py
Line 137: if min_sensor < 0  # Check non-negative
Line 140-143: if max_sensor <= min_sensor  # Check order
Line 145-148: if max_sensor >= total_sensors  # Check total
âŒ No minimum ROI size check!
âŒ No maximum ROI size check!

config/environments.yaml
Line 24: total_range: 2222
âŒ No min_roi_size defined
âŒ No max_roi_size defined
```

---

## ğŸ”´ **7. Configuration Validation - TODO Comments**

### ğŸ“ **××™×§×•×:** `tests/integration/api/test_config_validation_high_priority.py:475-520`

```python
def test_frequency_range_equal_min_max(self, focus_server_api, valid_config_payload):
    """Test PZ-13876.1: frequency range where min == max."""
    
    task_id = generate_task_id("freq_range_equal")
    logger.info(f"Test PZ-13876.1: frequency min == max - {task_id}")
    
    # Set frequency range with min == max
    config_payload = valid_config_payload.copy()
    config_payload["frequencyRange"] = {"min": 100, "max": 100}  # Edge case
    
    try:
        config_request = ConfigTaskRequest(**config_payload)
        response = focus_server_api.config_task(task_id, config_request)
        
        # Behavior depends on specs - document what happens
        logger.info(f"Frequency range min==max: status_code={response.status_code}")
        
        # TODO: Update assertion after specs meeting
        # For now, just log the behavior  âŒ ××™×Ÿ assertion!
        
    except ValueError as e:
        logger.info(f"Validation rejects min==max: {e}")
```

**×”×‘×¢×™×”:**
- ×”×˜×¡×˜ ×¨×¥ ××‘×œ **×œ× ×‘×•×“×§ ×›×œ×•×**!
- ××™×Ÿ spec ×”×× `min==max` ×–×” ×—×•×§×™ ××• ×œ×

**×¢×•×“ ×“×•×’××” ×××•×ª×• ×§×•×‘×¥:**
```python
# Line 506-520
def test_channel_range_equal_min_max(self, focus_server_api, valid_config_payload):
    """Test PZ-13876.2: channels where min == max."""
    
    config_payload["channels"] = {"min": 7, "max": 7}  # Edge case
    
    # TODO: Update assertion after specs meeting  âŒ ××™×Ÿ assertion!
```

**×§×™×©×•×¨×™× ×œ×§×•×“:**
```
tests/integration/api/test_config_validation_high_priority.py
Line 481: # TODO: Update assertion after specs meeting
Line 517: # TODO: Update assertion after specs meeting
âŒ Tests exist but no assertions!
```

---

## ğŸ”´ **8. Polling - ××™×Ÿ timeout ××•×’×“×¨!**

### ğŸ“ **××™×§×•×:** `src/utils/helpers.py:474-504`

```python
def poll_until(
    condition_func,
    timeout_seconds: int = 60,      # âŒ Hardcoded default
    poll_interval: float = 1.0      # âŒ Hardcoded default
):
    """
    Poll a condition until it returns True or timeout occurs.
    """
    start_time = time.time()
    
    while True:
        if condition_func():
            return True
        
        elapsed = time.time() - start_time
        if elapsed > timeout_seconds:
            raise TimeoutError(f"Condition not met after {elapsed:.2f}s")
        
        time.sleep(poll_interval)
```

**×”×‘×¢×™×”:**
- `timeout_seconds = 60` - hardcoded, ××™×Ÿ spec!
- `poll_interval = 1.0` - hardcoded, ××™×Ÿ spec!
- ××” ×× ×¦×¨×™×š polling ××—×¨ ×œlive vs historic?

**×§×™×©×•×¨ ×œ×§×•×“:**
```
src/utils/helpers.py
Line 474: timeout_seconds: int = 60  # âŒ Hardcoded
Line 474: poll_interval: float = 1.0  # âŒ Hardcoded
âŒ No separate specs for live vs historic
```

---

## ğŸ”´ **9. Default Config Values - ××™×Ÿ specs!**

### ğŸ“ **××™×§×•×:** `src/utils/helpers.py:507-532`

```python
def generate_config_payload(
    sensors_min: int = 0,          # âŒ ××™×Ÿ spec!
    sensors_max: int = 100,        # âŒ ××™×Ÿ spec!
    freq_min: int = 0,             # âŒ ××™×Ÿ spec!
    freq_max: int = 500,           # âŒ ××™×Ÿ spec!
    nfft: int = 1024,              # âœ… ×™×© ×‘config
    canvas_height: int = 1000,     # âŒ ××™×Ÿ spec!
    live: bool = True,
    # ... more params ...
) -> Dict[str, Any]:
    """Generate test configuration payload with defaults."""
```

**×”×©×•×•××” ×œconfig ×”××¢×¨×›×ª:**
```yaml
# config/environments.yaml (new_production)
constraints:
  sensors:
    default_start: 11     # âŒ ×”×§×•×“ ××©×ª××© ×‘-0!
    default_end: 109      # âŒ ×”×§×•×“ ××©×ª××© ×‘-100!
  frequency:
    start_hz: 0           # âœ… ×ª×•××
    end_hz: 1000          # âŒ ×”×§×•×“ ××©×ª××© ×‘-500!

nfft:
  default: 1024           # âœ… ×ª×•××

defaults:
  waterfall:
    num_lines: 200        # âŒ ×”×§×•×“ ×œ× ××©×ª××© ×‘×–×”!
```

**×”×‘×¢×™×”:**
- ××™ ×”×ª×××” ×‘×™×Ÿ defaults ×‘×§×•×“ ×œconfig
- ×—×œ×§ ××”defaults ×œ× ××’×™×¢×™× ×specs

**×§×™×©×•×¨×™× ×œ×§×•×“:**
```
src/utils/helpers.py
Line 508: sensors_min: int = 0        # â‰  config (11)
Line 509: sensors_max: int = 100      # â‰  config (109)
Line 511: freq_max: int = 500         # â‰  config (1000)
Line 513: canvas_height: int = 1000   # âŒ No spec

config/environments.yaml
Line 25: default_start: 11
Line 26: default_end: 109
Line 19: end_hz: 1000
âŒ Code doesn't use config values!
```

---

## ğŸ”´ **10. MongoDB Outage - ××™×Ÿ spec ××” ×¦×¤×•×™!**

### ğŸ“ **××™×§×•×:** ×”×˜×¡×˜×™× × ×›×©×œ×™× ×›×™ ××™×Ÿ spec

**××”×ª×•×¦××•×ª:**
```
FAILED tests/integration/performance/test_mongodb_outage_resilience.py::
TestMongoDBOutageResilience::test_mongodb_scale_down_outage_returns_503

AssertionError: Response time 15.423s exceeds maximum 5.0s
```

**×©××œ×•×ª ×œ×œ× ×ª×©×•×‘×”:**
- ××” ×”×¡×˜×˜×•×¡ HTTP ×©×¦×¨×™×š ×œ×—×–×•×¨ ×›×©MongoDB down?
- ×›××” ×–××Ÿ ××§×¡×™××œ×™ ×”××¢×¨×›×ª ×™×›×•×œ×” ×œ×”×™×•×ª ×œ× responsive?
- ×”×× ×¦×¨×™×š ×œ×”××©×™×š ×œ×§×‘×œ live data?
- ×”×× ×¦×¨×™×š caching?

**××™×Ÿ spec ×‘×§×•×“!**

---

## ğŸ“Š **×¡×™×›×•×: ××™×§×•××™ ×”×‘×¢×™×•×ª ×‘×§×•×“**

### ×§×‘×¦×™ Core ×©×—×¡×¨×™× ×‘×”× Specs:

| ×§×•×‘×¥ | ×‘×¢×™×•×ª | ×©×•×¨×•×ª |
|------|-------|-------|
| `src/utils/validators.py` | ROI 50%, Frequency max, NFFT list, Sensor range | 395, 174, 213, 140 |
| `src/utils/helpers.py` | Polling timeouts, Default values | 474, 508-513 |
| `src/models/focus_server_models.py` | No max limits in validation | 48-49 |
| `tests/integration/performance/*.py` | 11 TODO comments | Multiple |
| `tests/integration/api/*.py` | Assertions disabled/missing | Multiple |

---

## ğŸ¯ **××™×š ×œ×”×©×ª××© ×‘××¡××š ×”×–×” ×‘×¤×’×™×©×”**

### ×‘slide/××¦×’×ª:
1. **×”×¨××” ××ª ×”×§×•×“** - ×”×¢×ª×§ ××ª ×”×“×•×’×××•×ª ×¢× ×”comments ×”××“×•××™×
2. **×”×¨××” ××ª ×”-TODO** - 11 ××§×•××•×ª ×¢× "TODO: Update after specs meeting"
3. **×”×¨××” ××ª ×”assertions ×”××•×©×‘×ª×•×ª** - Line 157-162 ×‘performance tests
4. **×”×¨××” ××ª ×”××™-×”×ª×××”** - Code defaults â‰  Config values

### ×‘×“×™×•×Ÿ:
- **×œ×›×œ spec ×—×¡×¨** - ×”×¨××” ××ª ×”×©×•×¨×” ×”××“×•×™×§×ª ×‘×§×•×“
- **×”×“×’×©** - ×–×” ×œ× theoretical, ×–×” ×‘×§×•×“ **×××© ×¢×›×©×™×•**!
- **×”×¡×‘×¨** - ×œ××” ×–×” blocking ××ª ×”××•×˜×•××¦×™×”

---

## ğŸ“‹ **Quick Reference: ××™×§×•××™× ××“×•×™×§×™×**

### 1ï¸âƒ£ ROI 50%:
```
src/utils/validators.py:395
max_change_percent: float = 50.0
```

### 2ï¸âƒ£ Performance thresholds:
```
tests/integration/performance/test_performance_high_priority.py:146-170
THRESHOLD_P95_MS = 500
THRESHOLD_P99_MS = 1000
# Assertions commented out!
```

### 3ï¸âƒ£ NFFT validation:
```
src/utils/validators.py:219-224
warnings.warn() # Only warns, doesn't reject!
```

### 4ï¸âƒ£ TODO comments:
```
grep -r "TODO.*spec" tests/
â†’ 11 matches!
```

### 5ï¸âƒ£ Frequency max:
```
src/models/focus_server_models.py:48-49
min: int = Field(..., ge=0)  # No max!
max: int = Field(..., ge=0)  # No max!
```

---

