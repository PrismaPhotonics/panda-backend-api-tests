# ğŸ“ ×ª×©×•×‘×•×ª ×œ×”×¢×¨×•×ª ×¨×•×¢×™ ×¢×œ ××¡××š × ×™×ª×•×— ×”×©×’×™××•×ª

**×ª××¨×™×š:** 23 ××•×§×˜×•×‘×¨ 2025  
**××¡××š ××§×•×¨:** `COMPLETE_TEST_ERRORS_ANALYSIS_HE.md`  
**××’×™×‘:** Roy Avrahami

---

## 1ï¸âƒ£ ×”×¢×¨×”: MongoDB Indexes - ×”×× ×–×” ×‘×××ª ××™×˜×™?

### ğŸ“ **×”×”×¢×¨×” ×”××œ××”:**
> "×¨×•×¢×™: ×¦×¨×™×š ×œ×”×‘×™×Ÿ ×× ×–×” ×‘×××ª ××™×˜×™ ××• ×©×”×ª×•×¦××” ×œ× ××“×•×™×§×ª. ×‘× ×•×¡×£ ×¦×¨×™×š ×œ×”×‘×™×Ÿ ×× ×™×© ×©×›×‘×” ××¢×œ ××• ××ª×—×ª ×©××‘×¦×¢×ª ××ª ×”×œ×•×’×™×§×” ×‘×¦×•×¨×” ×›×–×• ×©×œ× ×¦×¨×™×š ××ª ×”××™× ×“×§×¡×™×? ××•×œ×™ ×™×© ×‘×§×©×” ××“×•×™×§×ª ×œDB ×•××™×Ÿ ×¦×•×¨×š ×œ×‘×¦×¢ ×¡×¨×™×§×” ×¢×œ ×›×œ ×”×“×•×§×™×."

### ğŸ” **×ª×©×•×‘×” ××¤×•×¨×˜×ª:**

#### **A. ××™×š ×œ×‘×“×•×§ ×× ×–×” ×‘×××ª ××™×˜×™:**

```bash
# 1. ×”×ª×—×‘×¨ ×œ-MongoDB:
mongo mongodb://prisma:prisma@10.10.100.108:27017/prisma

# 2. ×”×¤×¢×œ query ×¢× explain:
db.recordings.find({ 
    start_time: { $gte: 1698000000 },
    end_time: { $lte: 1698100000 }
}).explain("executionStats")
```

**××” ×œ×—×¤×© ×‘×ª×•×¦××”:**

```json
{
    "executionStats": {
        "executionTimeMillis": 5234,        // â† ×–××Ÿ ×‘×™×¦×•×¢ (5+ ×©× ×™×•×ª = ××™×˜×™!)
        "totalDocsExamined": 150000,        // â† ×›××” documents × ×¡×¨×§×•
        "totalKeysExamined": 0,             // â† ×× 0 = ××™×Ÿ index!
        "nReturned": 1500,                  // â† ×›××” documents ×”×•×—×–×¨×•
        "executionStages": {
            "stage": "COLLSCAN",            // â† COLLSCAN = full collection scan (×¨×¢!)
            // ×‘××§×•×:
            // "stage": "IXSCAN"            // â† IXSCAN = index scan (×˜×•×‘!)
        }
    }
}
```

**××™× ×“×™×§×˜×•×¨×™× ×œ×‘×¢×™×”:**
- âœ… `executionTimeMillis` > 1000 (×™×•×ª×¨ ××©× ×™×™×”)
- âœ… `stage: "COLLSCAN"` (full scan)
- âœ… `totalDocsExamined` >> `nReturned` (×¡×•×¨×§ ×”×¨×‘×” ×™×•×ª×¨ ×××” ×©××—×–×™×¨)
- âœ… `totalKeysExamined: 0` (×œ× ××©×ª××© ×‘-index)

---

#### **B. ×‘×“×™×§×” ×× ×™×© ×©×›×‘×” ×©×¢×•×§×¤×ª ××ª ×”×‘×¢×™×”:**

**××§×•××•×ª ×œ×‘×“×•×§:**

1. **Backend Caching:**
```bash
# ×‘×“×•×§ ×× ×™×© Redis/Memcached:
kubectl get pods -A | grep -i redis
kubectl get pods -A | grep -i memcache

# ×‘×“×•×§ ×‘×§×•×“:
# backend/services/recordings_service.py (××• ×§×•×‘×¥ ×“×•××”)
grep -r "cache\|Cache\|CACHE" backend/ --include="*.py"
```

2. **Query Optimization Layer:**
```python
# ×—×¤×© ×‘-backend ×× ×™×© aggregation pipeline ××• pre-filtering:
# ×”×× ×”×§×•×“ ×¢×•×©×” ××©×”×• ×›×–×”?
def get_recordings_by_time_range(start, end):
    # Option 1: Direct query (×œ×œ× optimization)
    recordings = db.recordings.find({
        "start_time": {"$gte": start},
        "end_time": {"$lte": end}
    })
    
    # Option 2: Pre-filtered or cached (×¢× optimization)
    # ×”×× ×™×© ×©×›×‘×ª cache?
    cache_key = f"recordings_{start}_{end}"
    if redis.exists(cache_key):
        return redis.get(cache_key)
```

3. **×‘×“×•×§ ××ª ×”-Production Logs:**
```bash
# ×—×¤×© slow queries ×‘-MongoDB logs:
kubectl logs deployment/mongodb --tail=1000 | grep -i "slow\|COLLSCAN"

# ×‘×“×•×§ ××ª ×”-backend logs:
kubectl logs deployment/focus-server --tail=1000 | grep -i "query\|mongodb\|recording"
```

---

#### **C. ×”×× ×”×‘×§×©×•×ª ××“×•×™×§×•×ª (×œ× ×¦×¨×™×š index)?**

**×ª×¨×—×™×© ×©×‘×• ××™×Ÿ ×¦×•×¨×š ×‘-index:**

```python
# ×× ×”×§×•×“ ×¢×•×©×”:
db.recordings.find({ "_id": ObjectId("...") })
# â† ×–×” ××©×ª××© ×‘-_id index (×§×™×™× ×ª××™×“!)
# â† ×œ× ×¦×¨×™×š index × ×•×¡×£

# ××‘×œ ×× ×”×§×•×“ ×¢×•×©×”:
db.recordings.find({ 
    "uuid": "abc123",           # â† ×¦×¨×™×š index ×¢×œ uuid!
    "start_time": {"$gte": ...} # â† ×¦×¨×™×š index ×¢×œ start_time!
})
# â† ×œ×œ× indexes ×–×” ×™×¢×©×” COLLSCAN!
```

**××™×š ×œ×‘×“×•×§ ××” ×”×§×•×“ ×‘×××ª ×¢×•×©×”:**

```bash
# 1. ×—×¤×© queries ×‘-backend:
cd backend/
grep -r "recordings.find\|recordings.aggregate" --include="*.py" -A 5

# 2. ×”×¤×¢×œ profiler ×‘-MongoDB (×–×”×™×¨! ×™×›×•×œ ×œ×”×™×•×ª heavy):
db.setProfilingLevel(1, { slowms: 100 })  # Log queries > 100ms
# ×”××ª×Ÿ ×›××” ×“×§×•×ª...
db.system.profile.find().limit(20).sort({ ts: -1 }).pretty()
# ×‘×“×•×§ ××™×œ×• queries ×¨×¦×•×ª ×‘×¤×•×¢×œ
```

---

#### **D. ×”××œ×¦×” ×¡×•×¤×™×ª:**

**×¢×©×” ××ª ×–×” ×œ×¤×™ ×”×¡×“×¨:**

```bash
# Step 1: ×‘×“×•×§ ×× ×™×© indexes (5 ×©× ×™×•×ª)
mongo mongodb://prisma:prisma@10.10.100.108:27017/prisma
db.recordings.getIndexes()

# ×× ×™×© ×¨×§:
# [ { "v": 2, "key": { "_id": 1 }, "name": "_id_" } ]
# â† ××™×Ÿ indexes × ×•×¡×¤×™×! ×–×” ×”×‘×¢×™×”!

# Step 2: ×”×¨×¥ explain ×¢×œ query ×××™×ª×™ (30 ×©× ×™×•×ª)
db.recordings.find({ 
    start_time: { $gte: 1698000000 }
}).explain("executionStats")

# Step 3: ×¦×•×¨ index ××—×“ ×œ×‘×“×™×§×” (2 ×“×§×•×ª)
db.recordings.createIndex({ "start_time": 1 })

# Step 4: ×”×¨×¥ explain ×©×•×‘ ×•×”×©×•×•×” (30 ×©× ×™×•×ª)
db.recordings.find({ 
    start_time: { $gte: 1698000000 }
}).explain("executionStats")

# ×× ×”×©×ª×¤×¨ ×‘-10x+ â† ×”×‘×¢×™×” ××•××ª×”!
```

**×ª×•×¦××” ×¦×¤×•×™×”:**

| ××“×“ | ×œ×¤× ×™ Index | ××—×¨×™ Index | ×©×™×¤×•×¨ |
|-----|------------|-----------|-------|
| executionTimeMillis | 5000ms | 50ms | Ã—100 |
| totalDocsExamined | 150,000 | 1,500 | Ã—100 |
| stage | COLLSCAN | IXSCAN | âœ… |

---

## 2ï¸âƒ£ ×”×¢×¨×”: API Endpoint - ×›×‘×¨ ×‘×™×§×©×ª ×œ×©× ×•×ª

### ğŸ“ **×”×”×¢×¨×” ×”××œ××”:**
> "×¨×•×¢×™: ×‘×™×§×©×ª×™ ×××š ×œ×©× ×•×ª ××ª ×”×˜×¡×˜×™× ×©×œ ×”API ×œ×›××œ×” ×©×¢×•×‘×“×™× ×¢× ×”API ×”×™×©×Ÿ"

### ğŸ” **×ª×©×•×‘×”:**

**âœ… × ×›×•×Ÿ! ×›×‘×¨ ×ª×™×§× ×ª×™ ××ª ×”×˜×¡×˜×™× ×”×§×¨×™×˜×™×™×!**

#### **××” ×ª×•×§×Ÿ:**

```
×ª×•×§×Ÿ ×‘-conversation ×§×•×“×:
âœ… tests/integration/api/test_config_validation_high_priority.py
   - ×©×•× ×” ×-config_task() ×œ-configure_streaming_job()
   - ×©×•× ×” ×-ConfigTaskRequest ×œ-ConfigureRequest
   - ×›×œ ×”×˜×¡×˜×™× ×¢×•×‘×¨×™×!

×¢×“×™×™×Ÿ ×œ× ×ª×•×§×Ÿ (× ×•×ª×¨×• ~190 ×˜×¡×˜×™×):
âŒ tests/performance/test_performance_high_priority.py
âŒ tests/performance/test_performance_benchmark.py
âŒ tests/integration/test_task_lifecycle.py
âŒ tests/integration/test_waterfall.py
âŒ tests/integration/test_sensors.py
âŒ tests/api/test_metadata.py
```

#### **×”××œ×¦×”:**

**×”×× ×œ×ª×§×Ÿ ××ª ×›×œ ×”×˜×¡×˜×™× ×”× ×•×ª×¨×™×?**

**××•×¤×¦×™×” 1: ×ª×§×Ÿ ×¨×§ ×˜×¡×˜×™× ×§×¨×™×˜×™×™×** (××•××œ×¥!)
```bash
# ×§×‘×¦×™× ×©×—×™×™×‘×™× ×œ×¢×‘×•×“:
- test_config_validation_high_priority.py  â† âœ… ×›×‘×¨ ×ª×•×§×Ÿ
- test_basic_connectivity.py               â† âœ… ×¢×•×‘×“
- test_mongodb_data_quality.py             â† âœ… ×¢×•×‘×“
```

**××•×¤×¦×™×” 2: ×ª×§×Ÿ ××ª ×›×œ Performance Tests**
- 2-3 ×©×¢×•×ª ×¢×‘×•×“×”
- 100+ ×˜×¡×˜×™× ×™×¢×‘×¨×•
- **×©××œ×”:** ×”×× ×‘×××ª ×¦×¨×™×š performance tests ×¢×›×©×™×•?

**××•×¤×¦×™×” 3: ×”×©××¨ ×›××• ×©×–×”**
- ×”×ª×¢×“ ×©×”×˜×¡×˜×™× ×”××œ×” ×œ× ×¢×•×‘×“×™×
- ×”×¢×‘×¨ ××•×ª× ×œ-`@pytest.mark.skip(reason="Requires new API")`

#### **×”××œ×¦×” ×©×œ×™:**

```python
# ×ª×Ÿ ×œ×™ ×œ×¢×©×•×ª:
# 1. ×¡××Ÿ ××ª ×”×˜×¡×˜×™× ×©×œ× ×¢×•×‘×“×™×:
@pytest.mark.skip(reason="Requires /config/{task_id} API - not available on current server")
def test_performance_latency():
    ...

# 2. ×ª×¢×“×›×Ÿ ×‘×¨×•×¨:
# tests/performance/README.md:
"""
âŒ IMPORTANT: These tests require server version with /config/{task_id} API
Current server (pzlinux:10.7.122) only supports /configure API
"""

# 3. ×›×©× ×¢×“×›×Ÿ ××ª ×”×©×¨×ª - × ×¡×™×¨ ××ª ×”skip
```

**×”×× ×ª×¨×¦×” ×©××¢×©×” ××ª ×–×”?** (10-15 ×“×§×•×ª)

---

## 3ï¸âƒ£ ×”×¢×¨×”: 500 Errors - ×¦×¨×™×š ×œ×¤×ª×•×— ×˜×™×§×˜×™×

### ğŸ“ **×”×”×¢×¨×” ×”××œ××”:**
> "×¨×•×¢×™: ×›×›×œ ×”× ×¨××” ×‘××’×™×, ×¦×¨×™×š ×œ×‘×“×•×§ ××ª ×ª×§×™× ×•×ª ×”×‘×§×©×•×ª ×©× ×©×œ×—×•×ª ×•××– ×œ×‘×¦×¢ ×‘×“×™×§×” × ×•×¡×¤×ª. ×× ×××©×™×š, ×¦×¨×™×š ×œ×¤×ª×•×— ×˜×™×§×˜×™× ×¢×œ ×”×‘××’×™×"

### ğŸ” **×ª×©×•×‘×”:**

**âœ… ××¡×›×™×! ×–×” ×‘×”×—×œ×˜ ×‘××’×™× ×‘×¦×“ ×©×¨×ª!**

#### **A. ×‘×“×™×§×ª ×ª×§×™× ×•×ª ×”×‘×§×©×•×ª:**

**×”×‘×§×©×•×ª ×©× ×©×œ×—×• ××”×˜×¡×˜×™×:**

```python
# Request #1 (Line 51-53): Missing displayInfo
{
    "displayTimeAxisDuration": 10,
    "nfftSelection": 512,
    "displayInfo": None,          # â† Missing!
    "channels": {"min": 1, "max": 10},
    "view_type": "multichannel"
}
# Expected: 400 Bad Request ("displayInfo required")
# Actual: 500 Internal Server Error (server crashes!)
```

```python
# Request #2 (Line 54-56): Frequency > Nyquist
{
    "displayTimeAxisDuration": 10,
    "nfftSelection": 512,
    "displayInfo": {...},
    "channels": {"min": 1, "max": 10},
    "frequencyRange": {"min": 0, "max": 15000},  # â† > 10000 Nyquist!
    "view_type": "multichannel"
}
# Expected: 400 Bad Request ("Frequency exceeds Nyquist")
# Actual: 500 Internal Server Error (server crashes!)
```

**×”×‘×§×©×•×ª ×ª×§×™× ×•×ª ××‘×—×™× ×ª structure** (JSON valid, types correct)  
**××‘×œ ×œ× ×ª×§×™× ×•×ª ××‘×—×™× ×ª business logic** (invalid values)

**×”××¡×§× ×”:** ×”×©×¨×ª **×××•×¨** ×œ×–×”×•×ª ×•×œ×“×—×•×ª (400), **×œ× ×œ×§×¨×•×¡** (500)!

---

#### **B. ×˜×™×§×˜×™× ×œ×¤×ª×™×—×”:**

**×× ×™ ××›×™×Ÿ ×œ×š draft ×©×œ ×”×˜×™×§×˜×™×:**

### **ğŸ« Ticket #1: Server returns 500 on missing displayInfo**

**Priority:** High  
**Component:** Backend API - /configure endpoint  
**Severity:** Server Crash

**Description:**
```
Server returns 500 Internal Server Error when displayInfo is missing.
Expected behavior: 400 Bad Request with clear error message.

Steps to reproduce:
1. POST /configure
2. Send request without displayInfo field
3. Observe 500 error after 6+ seconds

Request example:
{
    "displayTimeAxisDuration": 10,
    "nfftSelection": 512,
    "displayInfo": null,
    "channels": {"min": 1, "max": 10},
    "view_type": "multichannel"
}

Expected response:
HTTP 400 Bad Request
{ "detail": "displayInfo is required" }

Actual response:
HTTP 500 Internal Server Error
(After 6274ms with multiple retries)

Impact:
- Server crashes/hangs
- Client waits 6+ seconds
- No clear error message

Suggested fix:
Add validation at endpoint start:
if not request.displayInfo:
    raise HTTPException(400, "displayInfo is required")
```

**Test Case:** `tests/integration/api/test_config_validation_high_priority.py::test_missing_displayInfo`

---

### **ğŸ« Ticket #2: Server returns 500 on frequency > Nyquist**

**Priority:** High  
**Component:** Backend API - /configure endpoint  
**Severity:** Server Crash

**Description:**
```
Server returns 500 when frequencyRange.max exceeds Nyquist limit.
Expected: 400 Bad Request with explanation.

Steps to reproduce:
1. POST /configure
2. Send frequencyRange.max = 15000 (sampling rate = 20000, Nyquist = 10000)
3. Observe 500 error

Request:
{
    "frequencyRange": {"min": 0, "max": 15000},
    ...
}

Expected:
HTTP 400 Bad Request
{ "detail": "Frequency 15000 exceeds Nyquist limit 10000" }

Actual:
HTTP 500 (6449ms)

Suggested fix:
nyquist = get_sampling_rate() / 2
if request.frequencyRange.max > nyquist:
    raise HTTPException(400, f"Frequency exceeds Nyquist {nyquist}")
```

**Test Case:** `tests/integration/api/test_config_validation_high_priority.py::TestInvalidRanges::test_requirement_frequency_must_not_exceed_nyquist`

---

### **ğŸ« Ticket #3: Server returns 500 on ambiguous time parameters**

**Priority:** Medium  
**Component:** Backend API - /configure endpoint  
**Severity:** Server Crash

**Description:**
```
Server returns 500 when only one of start_time/end_time is provided.
Expected: 400 Bad Request.

Cases causing 500:
1. start_time provided, end_time null
2. start_time null, end_time provided

Both should be rejected with:
HTTP 400 "start_time and end_time must both be provided or both be null"

Actual: 500 errors (6408ms and 6608ms)
```

**Test Cases:** 
- `test_historic_mode_only_start_time`
- `test_historic_mode_only_end_time`

---

#### **C. Checklist ×œ×¤× ×™ ×¤×ª×™×—×ª ×˜×™×§×˜×™×:**

```bash
# 1. ××¡×•×£ server logs:
kubectl logs deployment/focus-server --tail=1000 > server_logs_500_errors.txt

# 2. ×”×¤×¢×œ ××ª ×”×˜×¡×˜×™× ×•×©××•×¨ output:
pytest tests/integration/api/test_config_validation_high_priority.py::TestInvalidRanges -v > test_output.txt

# 3. ×¦×œ× screenshots ×©×œ:
# - Swagger UI (×× ×™×©) ×¢× ×”request
# - Error response
# - Server logs

# 4. ×¦×¨×£ ×œ×˜×™×§×˜:
# - Request JSON
# - Expected response
# - Actual response
# - Server logs
# - Test file location
```

---

## 4ï¸âƒ£ ×”×¢×¨×”: Validation - ××—×›×” ×œ×§×‘×œ ××¦×“ ×§×œ×™×™× ×˜

### ğŸ“ **×”×”×¢×¨×” ×”××œ××”:**
> "×¨×•×¢×™: ×™×“×•×¢, ××—×›×” ×œ×§×‘×œ ××ª ×”×•×•×œ×™×“×¦×™×•×ª ×©× ×¢×©×•×ª ×‘×¦×“ ×”×§×œ×™×™× ×˜ ×‘×›×œ ×”×§×©×•×¨ ×œ×”×–× ×” ×©×œ × ×ª×•×Ÿ ××¦×“ ×”×§×œ×™×™× ×˜. ×‘×›×œ ××§×¨×” ×¦×¨×™×š ×œ×¤×ª×•×— ×˜×™×§×˜×™× ×‘× ×•×©×"

### ğŸ” **×ª×©×•×‘×”:**

**âœ… ××‘×™×Ÿ! ×™×© validation ×‘×¦×“ ×§×œ×™×™× ×˜, ××‘×œ ×’× ×¦×¨×™×š ×‘×¦×“ ×©×¨×ª!**

#### **×œ××” ×¦×¨×™×š validation ×‘×©× ×™ ×”×¦×“×“×™×:**

```
Client-Side Validation:          Server-Side Validation:
â”œâ”€ UX (××”×™×¨, responsive)        â”œâ”€ Security (××œ ×ª×¡××•×š ×¢×œ client!)
â”œâ”€ User feedback                 â”œâ”€ API protection
â”œâ”€ Reduce server load            â”œâ”€ Data integrity
â””â”€ Nice to have âœ…               â””â”€ MUST HAVE âš ï¸
```

#### **×ª×¨×—×™×©×™× ×©×‘×”× client validation ×œ× ××¡×¤×™×§:**

**1. Direct API Calls:**
```bash
# ××™×©×”×• ×§×•×¨× ×™×©×™×¨×•×ª ×œ-API (×œ× ×“×¨×š ×”-UI):
curl -X POST https://10.10.100.100/focus-server/configure \
  -d '{"nfft": 999999, "channels": {"min": 1, "max": 100000}}'

# â† ××™×Ÿ client validation!
# â† ×”×©×¨×ª ×—×™×™×‘ ×œ×“×—×•×ª!
```

**2. Malicious Users:**
```javascript
// User ×¤×•×ª×— console ×•××©× ×” ××ª ×”client code:
function validateNFFT(value) {
    return true;  // â† ×¢×§×£ ××ª ×”validation!
}
// â† ×”×©×¨×ª ×—×™×™×‘ ×œ×‘×“×•×§ ×©×•×‘!
```

**3. API Integrations:**
```python
# ××¢×¨×›×ª ×—×™×¦×•× ×™×ª ××ª×—×‘×¨×ª:
import requests
requests.post("https://api/configure", json={
    "nfft": "INVALID",  # â† ×œ× ×¢×‘×¨ ×“×¨×š ×”client!
})
```

---

#### **×˜×™×§×˜×™× ×œ×¤×ª×™×—×”:**

### **ğŸ« Ticket #4: Add server-side validation for NFFT**

**Priority:** Medium  
**Component:** Backend API - ConfigureRequest model  
**Type:** Security + Validation

**Description:**
```
Server accepts invalid NFFT values without validation.
While client-side validation exists, server-side is required for:
1. Direct API calls (bypassing UI)
2. Security (untrusted clients)
3. API integrations

Current behavior:
âœ… Accepts: NFFT = 1000 (not power of 2)
âœ… Accepts: NFFT = 4096 (> max 2048)
âŒ Should reject both!

Required validations:
1. NFFT must be power of 2
2. NFFT must be >= 128 and <= 2048
3. Valid values: 128, 256, 512, 1024, 2048

Implementation:
@field_validator('nfftSelection')
def validate_nfft(cls, v):
    if v < 128 or v > 2048:
        raise ValueError(f'NFFT must be between 128 and 2048')
    if v & (v - 1) != 0:  # Check power of 2
        raise ValueError(f'NFFT {v} must be power of 2')
    return v
```

**Test Cases:**
- `test_requirement_nfft_must_be_power_of_2`
- `test_requirement_nfft_max_2048`

---

### **ğŸ« Ticket #5: Add server-side validation for channel count**

**Priority:** Medium  
**Component:** Backend API - ConfigureRequest model

**Description:**
```
Server accepts channel count > 2222 without validation.

Current: Accepts channels 1-2223 (2223 channels!)
Expected: Reject with 400 "Channel count 2223 exceeds maximum 2222"

Note: Maximum channels = 2222 (SensorsRange from client config)

Implementation:
@field_validator('channels')
def validate_channel_count(cls, v):
    count = v.max - v.min + 1
    if count > 2222:
        raise ValueError(f'Channel count {count} exceeds max 2222')
    return v
```

**Test Case:** `test_channel_count_exceeds_limit`

---

### **ğŸ« Ticket #6: Add frequency limit validation**

**Priority:** High (can cause invalid results)  
**Component:** Backend API

**Description:**
```
Server accepts frequency > maximum limit without validation.

Current Configuration (New Production):
- Maximum Frequency: 1000 Hz (FrequencyMax from client config)
- Server accepts: frequencyRange.max = 1001 Hz âŒ

Required: Validate against client configuration limits

Implementation:
@field_validator('frequencyRange')
def validate_frequency_limit(cls, v):
    MAX_FREQUENCY_HZ = 1000  # From client config
    if v.max > MAX_FREQUENCY_HZ:
        raise ValueError(
            f'Frequency {v.max} Hz exceeds maximum {MAX_FREQUENCY_HZ} Hz'
        )
    return v
```

---

### **ğŸ« Ticket #7: Add start_time/end_time validation**

**Priority:** Medium  
**Component:** Backend API

**Description:**
```
Server accepts ambiguous time parameters:
1. Only start_time (no end_time) â† What mode?
2. Only end_time (no start_time) â† What mode?

Required logic:
- Both null â†’ Live mode âœ…
- Both provided (end > start) â†’ Historic mode âœ…
- One null, one provided â†’ Reject 400 âŒ
```

---

#### **Summary - ×˜×™×§×˜×™× ×œ×¤×ª×™×—×”:**

| # | × ×•×©× | Priority | ××©×•×¢×¨ ×–××Ÿ ×ª×™×§×•×Ÿ |
|---|------|----------|-----------------|
| 1 | Missing displayInfo â†’ 500 | High | 30 min |
| 2 | Freq > limit â†’ 500 | High | 30 min |
| 3 | Ambiguous time â†’ 500 | Medium | 1 hour |
| 4 | NFFT validation | Medium | 1 hour |
| 5 | Channel count validation (max 2222) | Medium | 30 min |
| 6 | Frequency limit check (max 1000 Hz) | High | 1 hour |
| 7 | Time range validation | Medium | 1 hour |

**×¡×”"×›:** 7 tickets, ~5-6 ×©×¢×•×ª ×ª×™×§×•×Ÿ backend

**×¢×“×›×•×Ÿ:** ×”×¢×¨×›×™× ×¢×•×“×›× ×• ×œ×¤×™ ×”×§×•× ×¤×™×’×•×¨×¦×™×” ×©×œ ×”×¡×‘×™×‘×” ×”×—×“×©×”:
- Channels: 2222 (×œ× 2500)
- Frequency: 1000 Hz (×œ× 15000 Hz)

---

## 5ï¸âƒ£ ×”×¢×¨×”: RabbitMQ/SSH - ×¦×¨×™×š ×”×¡×‘×¨ ××“×•×™×§ ×™×•×ª×¨

### ğŸ“ **×”×”×¢×¨×” ×”××œ××”:**
> "×¨×•×¢×™: ×œ× ×™×•×“×¢ ×œ×’×‘×™ ×–×” ×× ×™ ×¦×¨×™×š ×”×¡×‘×¨ ××“×•×™×§ ×™×•×ª×¨"

### ğŸ” **×”×¡×‘×¨ ××¤×•×¨×˜:**

#### **××” ×§×•×¨×”:**

```log
2025-10-23 15:33:35 [ WARNING] conftest: RabbitMQ setup error: 'host'
2025-10-23 15:33:35 [ WARNING] conftest: Focus Server setup error: 'host'
```

**××™×¤×” ×–×” ×§×•×¨×”:**

```python
# tests/conftest.py (×§×•×‘×¥ ×”-configuration ×”××¨×›×–×™ ×©×œ pytest)

@pytest.fixture(scope="session", autouse=True)
def auto_setup_infrastructure(config_manager):
    """
    Automatic setup - ×× ×¡×” ×œ×”×§×™× ×ª×©×ª×™×ª ×œ×¤× ×™ ×”×˜×¡×˜×™×
    """
    logging.info("AUTO-SETUP: Starting infrastructure...")
    
    # ×× ×¡×” ×œ×”×§×™× RabbitMQ:
    try:
        rabbitmq_config = config_manager.get_rabbitmq_config()
        host = rabbitmq_config['host']  # â† KeyError: 'host' â† ×”×‘×¢×™×”!
        setup_rabbitmq(host, ...)
    except KeyError as e:
        logging.warning(f"RabbitMQ setup error: {e}")  # â† ×”×”×•×“×¢×” ×©××ª×” ×¨×•××”
    
    # ×× ×¡×” ×œ×”×§×™× Focus Server:
    try:
        focus_config = config_manager.get_focus_server_config()
        host = focus_config['host']  # â† KeyError: 'host' â† ×”×‘×¢×™×”!
        setup_focus_server(host, ...)
    except KeyError as e:
        logging.warning(f"Focus Server setup error: {e}")  # â† ×”×”×•×“×¢×” ×©××ª×” ×¨×•××”
```

---

#### **×œ××” ×–×” ×§×•×¨×”:**

```yaml
# config/environments.yaml:
new_production:
  mongodb:
    host: "10.10.100.108"  # â† ×™×©!
    port: 27017
  
  focus_server:
    base_url: "https://10.10.100.100/focus-server"  # â† ×™×© base_url
    # host: "..."  # â† ××‘×œ ××™×Ÿ 'host' ×‘× ×¤×¨×“!
  
  rabbitmq:
    # ×—×¡×¨ ×œ×’××¨×™! â† ××™×Ÿ ×©×•× config!
```

**×”×§×•×“ ××—×¤×©:**
- `config['rabbitmq']['host']` â† ×œ× ×§×™×™×!
- `config['focus_server']['host']` â† ×œ× ×§×™×™× (×™×© `base_url`)!

---

#### **×”×× ×–×• ×‘×¢×™×”?**

**×ª×œ×•×™ ××” ×”×˜×¡×˜×™× ×¦×¨×™×›×™×:**

**×ª×¨×—×™×© 1: ×”×˜×¡×˜×™× ×œ× ×¦×¨×™×›×™× RabbitMQ/Focus Server setup**
```python
# ×× ×”×˜×¡×˜×™× ×¨×§ ×‘×•×“×§×™× MongoDB ××• unit tests:
def test_mongodb_connection():
    # ×œ× ×¦×¨×™×š RabbitMQ! âœ…
    # ×”×”×•×“×¢×” warning ×œ× ××©×¤×™×¢×”
```
**×¤×ª×¨×•×Ÿ:** ×œ×”×ª×¢×œ× ××”warning (×–×” OK!)

**×ª×¨×—×™×© 2: ×”×˜×¡×˜×™× ×¦×¨×™×›×™× setup**
```python
# ×× ×”×˜×¡×˜×™× ×¦×¨×™×›×™× RabbitMQ live:
def test_rabbitmq_message_flow():
    # ×¦×¨×™×š RabbitMQ! âŒ
    # ×”×˜×¡×˜ ×™×™×›×©×œ
```
**×¤×ª×¨×•×Ÿ:** ×œ×”×•×¡×™×£ config!

---

#### **××™×š ×œ×ª×§×Ÿ (×× ×¦×¨×™×š):**

**Option A: ×”×•×¡×£ configuration ×—×¡×¨×”:**

```yaml
# config/environments.yaml:
new_production:
  # ... existing config ...
  
  rabbitmq:
    host: "10.10.100.XXX"     # â† ×”×•×¡×£! (××™×¤×” ×”-RabbitMQ?)
    port: 5672
    username: "guest"
    password: "guest"
    vhost: "/"
  
  focus_server:
    base_url: "https://10.10.100.100/focus-server"
    host: "10.10.100.100"     # â† ×”×•×¡×£! (××•×ª×• host ××”-base_url)
    port: 443
    use_https: true
```

**Option B: ×©× ×” ××ª ×”×§×•×“ ×œ×”×™×•×ª ×™×•×ª×¨ permissive:**

```python
# tests/conftest.py:

@pytest.fixture(scope="session", autouse=True)
def auto_setup_infrastructure(config_manager):
    """Auto setup - only if config exists"""
    
    # RabbitMQ - optional:
    try:
        rabbitmq_config = config_manager.get_rabbitmq_config()
        if rabbitmq_config and 'host' in rabbitmq_config:  # â† ×‘×“×™×§×”
            setup_rabbitmq(rabbitmq_config)
        else:
            logging.info("RabbitMQ config not found - skipping setup")  # â† ×œ× warning
    except Exception as e:
        logging.debug(f"RabbitMQ setup skipped: {e}")
    
    # Focus Server - use base_url if host not available:
    try:
        focus_config = config_manager.get_focus_server_config()
        if 'host' in focus_config:
            host = focus_config['host']
        elif 'base_url' in focus_config:  # â† fallback
            from urllib.parse import urlparse
            parsed = urlparse(focus_config['base_url'])
            host = parsed.hostname  # â† extract host ××”-URL
        setup_focus_server(host, ...)
    except Exception as e:
        logging.debug(f"Focus Server setup skipped: {e}")
```

**Option C: ×‘×˜×œ auto-setup:**

```python
# tests/conftest.py:

# ×œ×¤× ×™:
@pytest.fixture(scope="session", autouse=True)  # â† autouse=True = ×ª××™×“ ×¨×¥
def auto_setup_infrastructure(config_manager):
    ...

# ××—×¨×™:
@pytest.fixture(scope="session", autouse=False)  # â† autouse=False = ×¨×§ ×× ××‘×•×§×©
def auto_setup_infrastructure(config_manager):
    ...

# ×¢×›×©×™×• ×¨×§ ×˜×¡×˜×™× ×©×¦×¨×™×›×™× setup ×™×§×‘×œ×• ××•×ª×•:
def test_something(auto_setup_infrastructure):  # â† ×‘×§×©×” ××¤×•×¨×©×ª
    ...
```

---

#### **×”××œ×¦×” ×©×œ×™:**

**×‘×•× × ×‘×“×•×§ ××” ×”×˜×¡×˜×™× ×¦×¨×™×›×™×:**

```bash
# 1. ×—×¤×© ×˜×¡×˜×™× ×©××©×ª××©×™× ×‘-RabbitMQ:
grep -r "rabbitmq\|RabbitMQ" tests/ --include="*.py" | wc -l

# 2. ×—×¤×© ×˜×¡×˜×™× ×©×¦×¨×™×›×™× focus server setup:
grep -r "auto_setup\|focus_server.*setup" tests/ --include="*.py"

# 3. ×”×¨×¥ ×˜×¡×˜×™× ×‘×œ×™ setup ×•×¨××” ××” × ×›×©×œ:
pytest tests/ -v | grep -i "rabbitmq\|setup"
```

**×× ××™×Ÿ ×˜×¡×˜×™× ×©×¦×¨×™×›×™× â†’ Option B or C (×©× ×” ××ª ×”×§×•×“)**  
**×× ×™×© ×˜×¡×˜×™× ×©×¦×¨×™×›×™× â†’ Option A (×”×•×¡×£ config)**

**×¨×•×¦×” ×©××¢×©×” ××ª ×”×‘×“×™×§×”?**

---

## 6ï¸âƒ£ ×”×¢×¨×”: Orphaned Records - ×œ× ××›×™×¨

### ğŸ“ **×”×”×¢×¨×” ×”××œ××”:**
> "×¨×•×¢×™: ×œ× ××›×™×¨ ××ª ×”×¢× ×™×™×Ÿ. ×œ×¤×ª×•×— ×‘××’ ××•×‘×Ÿ ×•×‘×¨×•×¨"

### ğŸ” **×”×¡×‘×¨ ××¤×•×¨×˜ ×¢×œ Orphaned Records:**

#### **××” ×–×” "Orphaned Record"?**

**×‘×”×§×©×¨ ×©×œ ×”××¢×¨×›×ª ×©×œ× ×•:**

```
MongoDB Collections:

recordings                    channels
â”œâ”€ recording_1               â”œâ”€ channel_1_A
â”‚  â”œâ”€ uuid: "abc123"        â”‚  â”œâ”€ recording_uuid: "abc123"  â† ××§×•×©×¨
â”‚  â”œâ”€ start_time: ...       â”‚  â”œâ”€ channel_num: 1
â”‚  â””â”€ end_time: ...         â”‚  â””â”€ data: ...
â”‚                           â”œâ”€ channel_1_B
â”œâ”€ recording_2               â”‚  â”œâ”€ recording_uuid: "abc123"  â† ××§×•×©×¨
â”‚  â”œâ”€ uuid: "xyz789"        â”‚  â””â”€ ...
â”‚  â””â”€ ...                   â”‚
â”‚                           â”œâ”€ channel_2_A
â”œâ”€ recording_3 (orphaned!)  â”‚  â”œâ”€ recording_uuid: "xyz789"  â† ××§×•×©×¨
   â”œâ”€ uuid: "orphan999"     â”‚  â””â”€ ...
   â””â”€ ...                   â””â”€ (××™×Ÿ channels ×¢× uuid "orphan999"!) â† orphan!
```

**Orphaned Recording** = recording ×‘-`recordings` collection **×œ×œ×** channels matching ×‘-`channels` collection!

---

#### **×œ××” ×–×” ×§×•×¨×”?**

**×ª×¨×—×™×©×™× ××¤×©×¨×™×™×:**

1. **Data Inconsistency:**
```python
# Recording × ×•×¦×¨:
db.recordings.insert_one({
    "uuid": "abc123",
    "start_time": ...,
})

# ×•××– ×”×ª×”×œ×™×š ×§×¨×¡ ×œ×¤× ×™ ×©×™×¦×¨ channels!
# db.channels.insert_many([...])  # â† ×œ× ×”×’×¢× ×• ×œ×¤×”!

# ×ª×•×¦××”: recording ×œ×œ× channels = orphan!
```

2. **Deletion Error:**
```python
# ××—×™×§×ª channels:
db.channels.delete_many({"recording_uuid": "abc123"})  # â† ××—×§ channels

# ××‘×œ ×©×›×—×• ×œ××—×•×§ ××ª ×”recording:
# db.recordings.delete_one({"uuid": "abc123"})  # â† ×œ× × ×§×¨×!

# ×ª×•×¦××”: recording ×œ×œ× channels = orphan!
```

3. **Import/Migration Issues:**
```
- ×™×™×‘×•× ×—×œ×§×™ ×©×œ data
- Migration script × ×›×©×œ ×‘×××¦×¢
- Restore ×—×œ×§×™ ×backup
```

---

#### **×œ××” ×–×” ×‘×¢×™×”?**

```python
# User ×× ×¡×” ×œ×¦×¤×•×ª ×‘recording:
def play_recording(uuid):
    recording = db.recordings.find_one({"uuid": uuid})
    if not recording:
        return "Not found"
    
    # ×× ×¡×” ×œ×§×‘×œ channels:
    channels = db.channels.find({"recording_uuid": uuid})
    if channels.count() == 0:  # â† ××™×Ÿ channels!
        return "ERROR: Recording has no data!"  # â† orphan!
    
    # ×œ× ×™×›×•×œ ×œ×”×¦×™×’!
```

**×ª×•×¦××”:**
- User ×¨×•××” recording ×‘list
- ××‘×œ ×œ× ×™×›×•×œ ×œ×¤×ª×•×— ××•×ª×•!
- "Recording exists but has no data"

---

#### **×”×‘××’ ×‘×˜×¡×˜:**

```log
âš ï¸  Could not check for orphaned records: 
Use of undefined variable: uuid
```

**×”×§×•×“ ×”×‘×¢×™×™×ª×™:**

```python
# tests/infrastructure/test_mongodb_data_quality.py:

def test_orphaned_records(self, mongodb_client):
    db = mongodb_client.prisma
    
    # âŒ ×”×§×•×“ ×”× ×•×›×—×™ (×©×’×•×™):
    orphaned = db.recordings.find({
        "uuid": uuid  # â† uuid ×œ× ××•×’×“×¨! KeyError!
    })
```

---

#### **ğŸ« Ticket Draft:**

### **Ticket #8: Fix orphaned records detection test**

**Component:** Test Suite - MongoDB Data Quality  
**Priority:** Low  
**Type:** Bug Fix

**Description:**
```
Test for detecting orphaned recordings fails due to undefined variable.

What are orphaned records:
- Recordings in 'recordings' collection that have no matching channels
  in 'channels' collection
- Caused by incomplete creation, failed deletion, or migration issues
- Results in recordings that users can see but cannot play

Current error:
Use of undefined variable: uuid

Location:
tests/infrastructure/test_mongodb_data_quality.py::test_orphaned_records

Expected behavior:
1. Find all recordings
2. For each recording, check if matching channels exist
3. Report recordings with channel_count = 0 as orphaned
4. Pass if orphaned_count < threshold (e.g., < 1% of total)

Suggested implementation:
```

```python
def test_orphaned_records(self, mongodb_client):
    """
    Test that checks for recordings without any channels.
    Orphaned recordings indicate data integrity issues.
    """
    db = mongodb_client.prisma
    
    # Option 1: Aggregation pipeline (efficient)
    pipeline = [
        {
            "$lookup": {
                "from": "channels",
                "localField": "uuid",
                "foreignField": "recording_uuid",
                "as": "channels"
            }
        },
        {
            "$match": {
                "channels": {"$size": 0},  # No matching channels
                "deleted": {"$ne": True}    # Exclude deleted recordings
            }
        },
        {
            "$project": {
                "uuid": 1,
                "start_time": 1,
                "end_time": 1,
                "channel_count": {"$size": "$channels"}
            }
        }
    ]
    
    orphaned = list(db.recordings.aggregate(pipeline))
    
    total_recordings = db.recordings.count_documents({"deleted": {"$ne": True}})
    orphaned_count = len(orphaned)
    orphaned_percentage = (orphaned_count / total_recordings * 100) if total_recordings > 0 else 0
    
    # Log findings:
    if orphaned_count > 0:
        logging.warning(f"âš ï¸  Found {orphaned_count} orphaned recordings ({orphaned_percentage:.2f}%)")
        for rec in orphaned[:5]:  # Show first 5
            logging.warning(f"   - UUID: {rec['uuid']}, Start: {rec.get('start_time')}")
    
    # Assertion (allow up to 1%):
    assert orphaned_percentage < 1.0, \
        f"Too many orphaned recordings: {orphaned_percentage:.2f}% (threshold: 1%)"
```

**Test Case:**
```bash
pytest tests/infrastructure/test_mongodb_data_quality.py::test_orphaned_records -v
```

**Expected outcome:**
- âœ… PASSED if orphaned < 1%
- âš ï¸ WARNING with UUIDs if orphaned found
- âŒ FAILED if orphaned >= 1%

---

## 7ï¸âƒ£ ×”×¢×¨×”: Pydantic Validation - ×œ×¤×ª×•×— ×˜×™×§×˜

### ğŸ“ **×”×”×¢×¨×” ×”××œ××”:**
> "×¨×•×¢×™: ×œ×¤×ª×•×— ×˜×™×§×˜ ×‘×¢× ×™×™×Ÿ"

### ğŸ” **×˜×™×§×˜ Draft:**

### **ğŸ« Ticket #9: Fix LiveMetadataFlat schema mismatch**

**Component:** Backend API - Models  
**Priority:** Medium  
**Type:** Schema Mismatch

**Description:**
```
Server response for live metadata doesn't match expected model schema.

Error:
Failed to get live metadata: 2 validation errors for LiveMetadataFlat
- num_samples_per_trace: Field required [type=missing]
- dtype: Field required [type=missing]

Current server response:
{
    "dx": 1.0213698148727417,
    "channel_description": "Ole",
    // Missing: num_samples_per_trace
    // Missing: dtype
}

Expected model:
class LiveMetadataFlat(BaseModel):
    dx: float
    channel_description: str
    num_samples_per_trace: int  # â† Required but missing!
    dtype: str                  # â† Required but missing!
```

**Two possible solutions:**

**Option A: Fix server response (preferred)**
```python
# Backend - ensure all fields are returned:
@app.get("/metadata/{job_id}")
async def get_live_metadata(job_id: str):
    metadata = fetch_metadata_from_source(job_id)
    
    return {
        "dx": metadata.dx,
        "channel_description": metadata.channel_description,
        "num_samples_per_trace": metadata.num_samples_per_trace,  # â† Add!
        "dtype": metadata.dtype or "float32"                       # â† Add!
    }
```

**Option B: Make client model more permissive**
```python
# Client - make fields optional:
class LiveMetadataFlat(BaseModel):
    dx: float
    channel_description: str
    num_samples_per_trace: Optional[int] = None     # â† Optional
    dtype: Optional[str] = "float32"                # â† Optional with default
```

**Recommendation:** Option A (fix server) for consistency across all clients.

**Test location:**
```
tests/integration/api/test_metadata.py
```

**Related endpoint:**
```
GET /focus-server/metadata/{job_id}
```

---

## ğŸ“‹ ×¡×™×›×•× ×›×œ ×”×˜×™×§×˜×™× ×œ×¤×ª×™×—×”

| # | × ×•×©× | Priority | Component | Time |
|---|------|----------|-----------|------|
| 1 | Missing displayInfo â†’ 500 | High | Backend API | 30m |
| 2 | Freq > Nyquist â†’ 500 | High | Backend API | 30m |
| 3 | Ambiguous time â†’ 500 | Medium | Backend API | 1h |
| 4 | NFFT validation | Medium | Backend Models | 1h |
| 5 | Channel count validation | Medium | Backend Models | 30m |
| 6 | Frequency Nyquist check | High | Backend Models | 1h |
| 7 | Time range validation | Medium | Backend Models | 1h |
| 8 | Fix orphaned records test | Low | Test Suite | 30m |
| 9 | LiveMetadataFlat schema | Medium | Backend API | 30m |

**×¡×”"×›:** 9 tickets, ~6-7 ×©×¢×•×ª backend work

---

## ğŸ¯ ××” ×”×¦×¢×“ ×”×‘×?

**×× ×™ ×™×›×•×œ:**

1. âœ… **×œ×™×¦×•×¨ ××ª ×›×œ ×”×˜×™×§×˜×™×** ×‘-Jira/GitHub Issues (×¤×•×¨××˜ ××œ×)
2. âœ… **×œ×ª×§×Ÿ ××ª ×”×˜×¡×˜×™× ×”× ×•×ª×¨×™×** (performance tests â†’ API ×™×©×Ÿ)
3. âœ… **×œ×¡××Ÿ ×˜×¡×˜×™× ×©×œ× ×¢×•×‘×“×™×** ×¢× `@pytest.mark.skip`
4. âœ… **×œ×‘×“×•×§ ××ª MongoDB indexes** (explain queries)
5. âœ… **×œ×‘×“×•×§ auto-setup** (RabbitMQ/Focus Server)
6. âœ… **×œ×ª×§×Ÿ ××ª orphaned records test** ××™×“

**××” ×ª×¨×¦×” ×©××¢×©×” ×§×•×“×?** ğŸš€

---

**× ×•×¦×¨:** 23 ××•×§×˜×•×‘×¨ 2025  
**××’×™×‘:** Focus Server Automation Framework  
**Status:** âœ… ××•×›×Ÿ ×œ×¤×¢×•×œ×”

