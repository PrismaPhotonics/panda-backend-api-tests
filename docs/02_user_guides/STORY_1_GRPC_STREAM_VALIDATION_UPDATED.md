# üì° Story 1: gRPC Stream Validation Framework - UPDATED

**Story ID:** AUTO-001  
**Story Points:** 13 (Updated from 8)  
**Priority:** üî¥ Critical (Must Have)  
**Dependencies:** None  
**Epic:** E2E Testing Framework  
**Version:** 2.0  
**Last Updated:** 2025-10-27

---

## üìã Story Overview

### Business Value

**As a** QA Automation Engineer  
**I want to** validate that the gRPC stream delivers correct spectrogram data  
**So that** I can ensure data flows correctly from Focus Server ‚Üí gRPC Job ‚Üí Frontend

### Problem Statement

**Current Gap:**
- ‚úÖ We have: Backend API tests (REST endpoints fully covered)
- ‚ùå Missing: gRPC stream connectivity validation
- ‚ùå Missing: Real-time data stream verification
- ‚ùå Missing: Stream performance monitoring
- ‚ùå Missing: Error scenario testing (connection loss, malformed data)

**Impact:**
- Cannot validate complete data flow to frontend
- No automated detection of streaming failures
- Manual verification required for every release
- High risk of production bugs in streaming layer

---

## üéØ Acceptance Criteria

### Functional Requirements

- [x] **AC1:** gRPC client wrapper implemented with full lifecycle management
  - Connect/disconnect with proper cleanup
  - Stream consumption with timeout handling
  - Retry logic for transient failures
  - TLS/SSL support (self-signed certificates)

- [x] **AC2:** Can connect to gRPC stream using job_id from `/configure` endpoint
  - Automatic service discovery (stream_url + stream_port)
  - Connection validation before streaming
  - Graceful handling of connection failures

- [x] **AC3:** Can receive and validate frame structure according to proto schema
  - DataStream message structure
  - SpectrogramRow fields (canvasId, sensors, timestamps)
  - SensorIntensity data (id, intensity array)
  - current_max_amp / current_min_amp validation

- [x] **AC4:** Stream performance metrics captured and validated
  - Throughput (frames/sec)
  - Latency (time to first frame)
  - Data rate (MB/sec)
  - Frame drop detection

- [x] **AC5:** All tests pass consistently (>95% success rate over 100 runs)
  - No flaky tests
  - Proper cleanup after failures
  - Isolated test environment

### Non-Functional Requirements

- **Performance:** First frame received within 5 seconds of connection
- **Reliability:** Tests must handle network instability gracefully
- **Maintainability:** Code follows existing project patterns (PEP8, type hints, docstrings)
- **Documentation:** Complete API documentation and usage examples

---

## üèóÔ∏è Technical Architecture

### Current Infrastructure (Existing)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EXISTING FRAMEWORK                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚úÖ src/apis/focus_server_api.py         REST API Client     ‚îÇ
‚îÇ ‚úÖ src/infrastructure/kubernetes_manager.py  K8s Operations ‚îÇ
‚îÇ ‚úÖ src/infrastructure/rabbitmq_manager.py   RabbitMQ Ops    ‚îÇ
‚îÇ ‚úÖ tests/conftest.py                    Pytest Fixtures     ‚îÇ
‚îÇ ‚úÖ config/config_manager.py             Configuration       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### New Components (To Be Built)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  NEW GRPC INFRASTRUCTURE                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üÜï src/apis/grpc_stream_client.py       gRPC Client         ‚îÇ
‚îÇ üÜï src/models/grpc_models.py            Proto Models        ‚îÇ
‚îÇ üÜï tests/integration/grpc/               Test Suite         ‚îÇ
‚îÇ üÜï tests/fixtures/grpc_fixtures.py       Test Fixtures      ‚îÇ
‚îÇ üÜï protos/datastream.proto               Proto Definition   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Integration Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Pytest     ‚îÇ       ‚îÇ Focus Server ‚îÇ       ‚îÇ  gRPC Job    ‚îÇ
‚îÇ   Test       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   REST API   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (K8s Pod)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                                              ‚îÇ
       ‚îÇ 1. POST /configure                          ‚îÇ
       ‚îÇ    ‚óÄ‚îÄ‚îÄ {job_id, stream_url, stream_port}   ‚îÇ
       ‚îÇ                                              ‚îÇ
       ‚îÇ 2. Connect gRPC Channel                     ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                                      ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ 3. Stream SpectrogramData
       ‚îÇ    ‚îÄ‚ñ∂ DataStream { rows[], max_amp, min_amp }
       ‚îÇ    ‚îÄ‚ñ∂ SpectrogramRow { canvasId, sensors[], timestamps }
       ‚îÇ    ‚îÄ‚ñ∂ SensorIntensity { id, intensity[] }
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Validation  ‚îÇ
‚îÇ   Engine     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Detailed Task Breakdown

### üì¶ Task 1.1: Setup gRPC Infrastructure (3h ‚Üí 4h)

**Objective:** Prepare development environment and project structure for gRPC testing

#### Subtasks:

1. **Create Directory Structure** (30min)
   ```bash
   mkdir -p tests/integration/grpc
   mkdir -p tests/fixtures
   mkdir -p protos
   mkdir -p src/models/proto_generated
   ```

2. **Add Dependencies to requirements.txt** (15min)
   ```python
   # gRPC and Protocol Buffers
   grpcio>=1.59.0              # gRPC runtime
   grpcio-tools>=1.59.0        # Protobuf compiler
   protobuf>=4.25.0            # Protocol buffers
   grpcio-health-checking>=1.59.0  # Health check support
   grpcio-reflection>=1.59.0   # Server reflection (for debugging)
   ```

3. **Create Proto Definition File** (1h)
   File: `protos/datastream.proto`
   ```protobuf
   syntax = "proto3";
   
   package datastream;
   
   // Main service definition
   service DataStreamService {
       // Stream spectrogram data for a given job
       rpc StreamSpectrograms(StreamRequest) returns (stream DataStream) {}
       
       // Health check endpoint
       rpc CheckHealth(HealthRequest) returns (HealthResponse) {}
   }
   
   // Request message
   message StreamRequest {
       string job_id = 1;
       int32 max_frames = 2;  // Optional: limit frames
   }
   
   // Health check messages
   message HealthRequest {}
   
   message HealthResponse {
       bool healthy = 1;
       string version = 2;
   }
   
   // Main streaming data message
   message DataStream {
       repeated SpectrogramRow rows = 1;
       double current_max_amp = 2;
       double current_min_amp = 3;
   }
   
   message SpectrogramRow {
       string canvasId = 1;
       repeated SensorIntensity sensors = 2;
       int64 startTimestamp = 3;  // Epoch milliseconds
       int64 endTimestamp = 4;    // Epoch milliseconds
   }
   
   message SensorIntensity {
       int32 id = 1;
       repeated float intensity = 2;
   }
   ```

4. **Generate Python Code from Proto** (30min)
   Create script: `scripts/generate_proto.sh`
   ```bash
   #!/bin/bash
   # Generate Python gRPC code from proto files
   
   python -m grpc_tools.protoc \
       -I./protos \
       --python_out=./src/models/proto_generated \
       --grpc_python_out=./src/models/proto_generated \
       ./protos/datastream.proto
   
   echo "‚úÖ Proto files generated successfully"
   ```

5. **Create conftest.py for gRPC Tests** (1h)
   File: `tests/integration/grpc/conftest.py`
   ```python
   """
   Pytest fixtures for gRPC stream testing.
   """
   
   import pytest
   import logging
   from typing import Generator
   
   from src.apis.focus_server_api import FocusServerAPI
   from src.apis.grpc_stream_client import GrpcStreamClient
   from src.models.focus_server_models import ConfigTaskRequest
   from src.utils.helpers import generate_task_id, generate_config_payload
   
   logger = logging.getLogger(__name__)
   
   
   @pytest.fixture(scope="session")
   def grpc_test_config():
       """Configuration for gRPC tests."""
       return {
           "connection_timeout": 10,  # seconds
           "stream_timeout": 30,       # seconds
           "max_frames": 10,           # frames to collect per test
           "retry_attempts": 3,
           "retry_delay": 2,           # seconds
       }
   
   
   @pytest.fixture(scope="function")
   def configured_grpc_task(focus_server_api: FocusServerAPI) -> Generator[dict, None, None]:
       """
       Configure a task and return connection details for gRPC streaming.
       
       Returns:
           dict: {
               "task_id": str,
               "job_id": str,
               "stream_url": str,
               "stream_port": int
           }
       
       Cleanup:
           Automatically cleans up task after test
       """
       task_id = generate_task_id("grpc_test")
       
       # Configure live streaming task
       payload = generate_config_payload(
           sensors_min=0,
           sensors_max=10,
           freq_min=0,
           freq_max=500,
           nfft=1024,
           canvas_height=1000,
           live=True
       )
       
       config_request = ConfigTaskRequest(**payload)
       response = focus_server_api.config_task(task_id, config_request)
       
       assert response.status == "Config received successfully"
       assert response.job_id is not None
       
       logger.info(f"‚úÖ Task configured: {task_id}, Job: {response.job_id}")
       
       yield {
           "task_id": task_id,
           "job_id": response.job_id,
           "stream_url": response.stream_url,
           "stream_port": response.stream_port
       }
       
       # Cleanup: Cancel job
       try:
           logger.info(f"Cleaning up task: {task_id}")
           # Additional cleanup logic if needed
       except Exception as e:
           logger.warning(f"Cleanup failed for {task_id}: {e}")
   
   
   @pytest.fixture(scope="function")
   def grpc_client(grpc_test_config) -> Generator[GrpcStreamClient, None, None]:
       """
       Provide a GrpcStreamClient instance with automatic cleanup.
       
       Yields:
           GrpcStreamClient: Configured gRPC client
       """
       client = GrpcStreamClient(
           connection_timeout=grpc_test_config["connection_timeout"],
           stream_timeout=grpc_test_config["stream_timeout"]
       )
       
       yield client
       
       # Cleanup: Disconnect if still connected
       try:
           client.disconnect()
       except Exception as e:
           logger.warning(f"Error disconnecting gRPC client: {e}")
   ```

6. **Create README.md** (30min)
   File: `tests/integration/grpc/README.md`

**Acceptance Criteria:**
- [x] Directory structure created
- [x] Dependencies added and installed (`pip install -r requirements.txt`)
- [x] Proto file compiles without errors
- [x] Python gRPC stubs generated successfully
- [x] Fixtures load without import errors

**Testing:**
```bash
# Verify proto compilation
python -m grpc_tools.protoc --version

# Generate proto files
bash scripts/generate_proto.sh

# Verify imports work
python -c "from src.models.proto_generated import datastream_pb2"
```

---

### üß© Task 1.2: Implement GrpcStreamClient Wrapper (6h ‚Üí 8h)

**Objective:** Create production-grade gRPC client following existing project patterns

#### Class Structure:

File: `src/apis/grpc_stream_client.py`

```python
"""
gRPC Stream Client for Focus Server
====================================

Enterprise-grade gRPC client for streaming spectrogram data from Focus Server gRPC jobs.

Features:
- Automatic connection management with retry logic
- Streaming with timeout and error handling
- TLS/SSL support for secure connections
- Performance metrics collection
- Comprehensive logging and debugging

Author: QA Automation Architect
Date: 2025-10-27
"""

import grpc
import time
import logging
from typing import Generator, Optional, Dict, Any, List
from dataclasses import dataclass, field
from contextlib import contextmanager

from src.models.proto_generated import datastream_pb2, datastream_pb2_grpc
from src.core.exceptions import APIError, ConnectionError


@dataclass
class StreamMetrics:
    """
    Performance metrics for gRPC stream.
    
    Attributes:
        frames_received: Total frames received
        bytes_received: Total bytes received
        start_time: Stream start timestamp
        end_time: Stream end timestamp
        first_frame_latency: Time to receive first frame (seconds)
        avg_frame_rate: Average frames per second
        errors_count: Number of errors encountered
    """
    frames_received: int = 0
    bytes_received: int = 0
    start_time: float = 0.0
    end_time: float = 0.0
    first_frame_latency: Optional[float] = None
    avg_frame_rate: float = 0.0
    errors_count: int = 0
    
    def calculate_metrics(self):
        """Calculate derived metrics after streaming completes."""
        if self.start_time and self.end_time:
            duration = self.end_time - self.start_time
            if duration > 0:
                self.avg_frame_rate = self.frames_received / duration


class GrpcStreamClient:
    """
    Production-grade gRPC client for Focus Server streaming.
    
    Usage:
        ```python
        client = GrpcStreamClient(connection_timeout=10)
        
        # Connect to stream
        client.connect(stream_url="10.10.100.100", stream_port=50051)
        
        # Stream data
        for frame in client.stream_spectrograms(job_id="12-70788", max_frames=100):
            process_frame(frame)
        
        # Get metrics
        metrics = client.get_metrics()
        print(f"Received {metrics.frames_received} frames at {metrics.avg_frame_rate:.2f} fps")
        
        # Disconnect
        client.disconnect()
        ```
    
    Features:
    - Automatic retry on transient failures
    - Connection pooling and reuse
    - TLS/SSL certificate validation (with self-signed cert support)
    - Comprehensive error handling
    - Performance metrics collection
    
    Thread Safety: Not thread-safe. Create separate instances per thread.
    """
    
    def __init__(
        self,
        connection_timeout: int = 10,
        stream_timeout: int = 300,
        retry_attempts: int = 3,
        retry_delay: float = 2.0,
        verify_ssl: bool = False
    ):
        """
        Initialize gRPC stream client.
        
        Args:
            connection_timeout: Timeout for initial connection (seconds)
            stream_timeout: Timeout for stream operations (seconds)
            retry_attempts: Number of retry attempts for transient failures
            retry_delay: Delay between retries (seconds)
            verify_ssl: Whether to verify SSL certificates (False for self-signed)
        """
        self.connection_timeout = connection_timeout
        self.stream_timeout = stream_timeout
        self.retry_attempts = retry_attempts
        self.retry_delay = retry_delay
        self.verify_ssl = verify_ssl
        
        self.logger = logging.getLogger(__name__)
        
        # Connection state
        self._channel: Optional[grpc.Channel] = None
        self._stub: Optional[datastream_pb2_grpc.DataStreamServiceStub] = None
        self._connected = False
        
        # Metrics
        self._metrics = StreamMetrics()
        
        self.logger.debug("GrpcStreamClient initialized")
    
    def connect(self, stream_url: str, stream_port: int) -> bool:
        """
        Establish connection to gRPC server.
        
        Args:
            stream_url: Server hostname or IP
            stream_port: Server port
        
        Returns:
            True if connection successful
        
        Raises:
            ConnectionError: If connection fails after retries
        
        Example:
            ```python
            success = client.connect("10.10.100.100", 50051)
            assert success, "Failed to connect"
            ```
        """
        address = f"{stream_url}:{stream_port}"
        self.logger.info(f"Connecting to gRPC server: {address}")
        
        for attempt in range(1, self.retry_attempts + 1):
            try:
                # Create channel with options
                options = [
                    ('grpc.max_receive_message_length', 100 * 1024 * 1024),  # 100MB
                    ('grpc.max_send_message_length', 100 * 1024 * 1024),
                ]
                
                if self.verify_ssl:
                    # Use TLS (for production with valid certs)
                    credentials = grpc.ssl_channel_credentials()
                    self._channel = grpc.secure_channel(
                        address,
                        credentials,
                        options=options
                    )
                else:
                    # Use insecure channel (for testing/self-signed certs)
                    self._channel = grpc.insecure_channel(address, options=options)
                
                # Create stub
                self._stub = datastream_pb2_grpc.DataStreamServiceStub(self._channel)
                
                # Verify connection with health check (if available)
                try:
                    health_request = datastream_pb2.HealthRequest()
                    health_response = self._stub.CheckHealth(
                        health_request,
                        timeout=self.connection_timeout
                    )
                    self.logger.info(f"Health check passed: {health_response.healthy}")
                except grpc.RpcError as e:
                    # Health check not implemented, continue anyway
                    self.logger.debug(f"Health check unavailable: {e.code()}")
                
                self._connected = True
                self.logger.info(f"‚úÖ Connected to {address}")
                return True
                
            except grpc.RpcError as e:
                self.logger.warning(
                    f"Connection attempt {attempt}/{self.retry_attempts} failed: "
                    f"{e.code()} - {e.details()}"
                )
                
                if attempt < self.retry_attempts:
                    time.sleep(self.retry_delay)
                else:
                    raise ConnectionError(
                        f"Failed to connect to {address} after {self.retry_attempts} attempts"
                    ) from e
            
            except Exception as e:
                self.logger.error(f"Unexpected error during connection: {e}")
                raise ConnectionError(f"Connection failed: {e}") from e
        
        return False
    
    def stream_spectrograms(
        self,
        job_id: str,
        max_frames: Optional[int] = None
    ) -> Generator[datastream_pb2.DataStream, None, None]:
        """
        Stream spectrogram data from gRPC server.
        
        Args:
            job_id: Job identifier from /configure endpoint
            max_frames: Optional limit on number of frames to receive
        
        Yields:
            DataStream: Protobuf message containing spectrogram rows
        
        Raises:
            ConnectionError: If not connected
            APIError: If stream fails
        
        Example:
            ```python
            for frame in client.stream_spectrograms("12-70788", max_frames=10):
                print(f"Received frame with {len(frame.rows)} rows")
                print(f"Amplitude range: {frame.current_min_amp} - {frame.current_max_amp}")
                
                for row in frame.rows:
                    print(f"  Row {row.canvasId}: {len(row.sensors)} sensors")
            ```
        """
        if not self._connected or not self._stub:
            raise ConnectionError("Not connected to gRPC server. Call connect() first.")
        
        self.logger.info(f"Starting stream for job_id: {job_id}")
        
        # Reset metrics
        self._metrics = StreamMetrics()
        self._metrics.start_time = time.time()
        
        # Create stream request
        request = datastream_pb2.StreamRequest(
            job_id=job_id,
            max_frames=max_frames or 0
        )
        
        try:
            # Start streaming
            stream = self._stub.StreamSpectrograms(request, timeout=self.stream_timeout)
            
            frame_count = 0
            for message in stream:
                frame_count += 1
                
                # Record first frame latency
                if frame_count == 1:
                    self._metrics.first_frame_latency = time.time() - self._metrics.start_time
                    self.logger.info(
                        f"First frame received in {self._metrics.first_frame_latency:.3f}s"
                    )
                
                # Update metrics
                self._metrics.frames_received += 1
                self._metrics.bytes_received += message.ByteSize()
                
                self.logger.debug(
                    f"Frame {frame_count}: {len(message.rows)} rows, "
                    f"amp range: [{message.current_min_amp:.2f}, {message.current_max_amp:.2f}]"
                )
                
                yield message
                
                # Check if reached max_frames limit
                if max_frames and frame_count >= max_frames:
                    self.logger.info(f"Reached max_frames limit: {max_frames}")
                    break
            
            self._metrics.end_time = time.time()
            self._metrics.calculate_metrics()
            
            self.logger.info(
                f"‚úÖ Stream completed: {self._metrics.frames_received} frames, "
                f"{self._metrics.avg_frame_rate:.2f} fps"
            )
            
        except grpc.RpcError as e:
            self._metrics.errors_count += 1
            self._metrics.end_time = time.time()
            
            self.logger.error(
                f"gRPC stream error: {e.code()} - {e.details()}"
            )
            
            raise APIError(f"Stream failed: {e.code()} - {e.details()}") from e
        
        except Exception as e:
            self._metrics.errors_count += 1
            self._metrics.end_time = time.time()
            
            self.logger.error(f"Unexpected stream error: {e}")
            raise APIError(f"Stream failed: {e}") from e
    
    def disconnect(self):
        """
        Close gRPC channel and cleanup resources.
        
        Always call this when done streaming to prevent resource leaks.
        
        Example:
            ```python
            try:
                client.connect(url, port)
                for frame in client.stream_spectrograms(job_id):
                    process(frame)
            finally:
                client.disconnect()
            ```
        """
        if self._channel:
            try:
                self._channel.close()
                self.logger.info("gRPC channel closed")
            except Exception as e:
                self.logger.warning(f"Error closing channel: {e}")
            finally:
                self._channel = None
                self._stub = None
                self._connected = False
    
    def get_metrics(self) -> StreamMetrics:
        """
        Get streaming performance metrics.
        
        Returns:
            StreamMetrics: Performance statistics
        
        Example:
            ```python
            metrics = client.get_metrics()
            print(f"Frames: {metrics.frames_received}")
            print(f"FPS: {metrics.avg_frame_rate:.2f}")
            print(f"First frame latency: {metrics.first_frame_latency:.3f}s")
            ```
        """
        return self._metrics
    
    @contextmanager
    def connect_context(self, stream_url: str, stream_port: int):
        """
        Context manager for automatic connection/disconnection.
        
        Args:
            stream_url: Server hostname or IP
            stream_port: Server port
        
        Yields:
            self: Connected client instance
        
        Example:
            ```python
            with client.connect_context("10.10.100.100", 50051) as connected_client:
                for frame in connected_client.stream_spectrograms(job_id):
                    process(frame)
            # Automatically disconnected
            ```
        """
        try:
            self.connect(stream_url, stream_port)
            yield self
        finally:
            self.disconnect()
    
    def is_connected(self) -> bool:
        """Check if client is currently connected."""
        return self._connected
    
    def __repr__(self) -> str:
        status = "connected" if self._connected else "disconnected"
        return f"GrpcStreamClient(status={status}, metrics={self._metrics})"
```

**Acceptance Criteria:**
- [x] Class follows existing project patterns (see `FocusServerAPI`)
- [x] Comprehensive docstrings (Google style)
- [x] Type hints for all methods
- [x] Error handling for all failure scenarios
- [x] Logging at appropriate levels (DEBUG, INFO, WARNING, ERROR)
- [x] Unit tests pass (>90% coverage)

**Testing:**
```python
# Unit test example
def test_grpc_client_initialization():
    client = GrpcStreamClient(connection_timeout=5)
    assert client.connection_timeout == 5
    assert not client.is_connected()
```

---

### ‚úÖ Task 1.3: Write Stream Connectivity Tests (4h)

**Objective:** Validate basic connection and streaming functionality

File: `tests/integration/grpc/test_grpc_connectivity.py`

```python
"""
gRPC Stream Connectivity Tests
================================

Test suite for validating gRPC stream connectivity and basic functionality.

Test Coverage:
- Connection establishment
- First frame delivery
- Invalid job_id handling
- Stream completion detection

Author: QA Automation Architect
Date: 2025-10-27
"""

import pytest
import logging
import time
from typing import Dict, Any

from src.apis.grpc_stream_client import GrpcStreamClient
from src.core.exceptions import APIError, ConnectionError

logger = logging.getLogger(__name__)


@pytest.mark.integration
@pytest.mark.grpc
@pytest.mark.critical
class TestGrpcStreamConnectivity:
    """Test suite for gRPC stream connectivity."""
    
    def test_grpc_stream_connects_successfully(
        self,
        configured_grpc_task: Dict[str, Any],
        grpc_client: GrpcStreamClient
    ):
        """
        Test: gRPC client can connect to streaming server.
        
        Steps:
            1. Configure task and get stream URL/port
            2. Connect to gRPC server
            3. Verify connection successful
        
        Expected:
            - Connection established within timeout
            - No connection errors
            - Client reports connected status
        
        Jira: AUTO-001 (Task 1.3.1)
        Priority: Critical
        """
        logger.info("Test: gRPC stream connects successfully")
        
        # Get connection details
        stream_url = configured_grpc_task["stream_url"]
        stream_port = configured_grpc_task["stream_port"]
        
        logger.info(f"Connecting to {stream_url}:{stream_port}")
        
        # Connect
        success = grpc_client.connect(stream_url, stream_port)
        
        # Assertions
        assert success, "Connection should succeed"
        assert grpc_client.is_connected(), "Client should report connected status"
        
        logger.info("‚úÖ gRPC connection successful")
    
    def test_grpc_stream_delivers_first_frame(
        self,
        configured_grpc_task: Dict[str, Any],
        grpc_client: GrpcStreamClient,
        grpc_test_config: Dict[str, Any]
    ):
        """
        Test: gRPC stream delivers first frame within acceptable time.
        
        Steps:
            1. Connect to gRPC server
            2. Start streaming
            3. Receive first frame
            4. Verify first frame latency
        
        Expected:
            - First frame received within 5 seconds
            - Frame contains valid data
            - No errors or timeouts
        
        Jira: AUTO-001 (Task 1.3.2)
        Priority: Critical
        """
        logger.info("Test: gRPC stream delivers first frame")
        
        # Connect
        grpc_client.connect(
            configured_grpc_task["stream_url"],
            configured_grpc_task["stream_port"]
        )
        
        # Stream and get first frame
        job_id = configured_grpc_task["job_id"]
        
        start_time = time.time()
        frame_received = False
        
        for frame in grpc_client.stream_spectrograms(job_id, max_frames=1):
            frame_received = True
            first_frame_time = time.time() - start_time
            
            logger.info(f"First frame received in {first_frame_time:.3f}s")
            
            # Assertions on first frame
            assert frame is not None, "Frame should not be None"
            assert hasattr(frame, 'rows'), "Frame should have 'rows' attribute"
            assert hasattr(frame, 'current_max_amp'), "Frame should have amplitude data"
            
            break
        
        # Verify frame was received
        assert frame_received, "Should receive at least one frame"
        
        # Check latency
        metrics = grpc_client.get_metrics()
        assert metrics.first_frame_latency is not None
        assert metrics.first_frame_latency < 5.0, \
            f"First frame took too long: {metrics.first_frame_latency:.3f}s"
        
        logger.info(f"‚úÖ First frame delivered in {metrics.first_frame_latency:.3f}s")
    
    def test_grpc_stream_handles_invalid_job_id(
        self,
        configured_grpc_task: Dict[str, Any],
        grpc_client: GrpcStreamClient
    ):
        """
        Test: gRPC stream handles invalid job_id gracefully.
        
        Steps:
            1. Connect to gRPC server
            2. Request stream with invalid job_id
            3. Verify appropriate error raised
        
        Expected:
            - APIError raised with clear message
            - No system crash or hang
            - Connection remains usable
        
        Jira: AUTO-001 (Task 1.3.3)
        Priority: High
        """
        logger.info("Test: gRPC stream handles invalid job_id")
        
        # Connect
        grpc_client.connect(
            configured_grpc_task["stream_url"],
            configured_grpc_task["stream_port"]
        )
        
        # Try streaming with invalid job_id
        invalid_job_id = "INVALID-JOB-ID-99999"
        
        with pytest.raises(APIError) as exc_info:
            for frame in grpc_client.stream_spectrograms(invalid_job_id, max_frames=1):
                pass  # Should not reach here
        
        # Verify error message is informative
        error_message = str(exc_info.value)
        assert "job" in error_message.lower() or "not found" in error_message.lower(), \
            f"Error message should mention job: {error_message}"
        
        logger.info(f"‚úÖ Invalid job_id handled correctly: {error_message}")
    
    def test_grpc_stream_stops_on_job_completion(
        self,
        configured_grpc_task: Dict[str, Any],
        grpc_client: GrpcStreamClient
    ):
        """
        Test: gRPC stream stops gracefully when job completes.
        
        Steps:
            1. Connect to gRPC server
            2. Stream all available frames
            3. Verify stream completes without errors
        
        Expected:
            - Stream ends when job finishes
            - No hanging or timeout
            - Metrics reflect complete stream
        
        Jira: AUTO-001 (Task 1.3.4)
        Priority: High
        """
        logger.info("Test: gRPC stream stops on job completion")
        
        # Connect
        grpc_client.connect(
            configured_grpc_task["stream_url"],
            configured_grpc_task["stream_port"]
        )
        
        # Stream all frames (no max_frames limit)
        job_id = configured_grpc_task["job_id"]
        frames_received = 0
        
        start_time = time.time()
        
        for frame in grpc_client.stream_spectrograms(job_id):
            frames_received += 1
            logger.debug(f"Received frame {frames_received}")
            
            # Safety: break after 100 frames to avoid infinite loop in tests
            if frames_received >= 100:
                logger.info("Reached safety limit of 100 frames")
                break
        
        duration = time.time() - start_time
        
        # Verify stream completed
        assert frames_received > 0, "Should receive at least one frame"
        
        # Get metrics
        metrics = grpc_client.get_metrics()
        assert metrics.frames_received == frames_received
        assert metrics.errors_count == 0, "Should have no errors"
        
        logger.info(
            f"‚úÖ Stream completed: {frames_received} frames in {duration:.2f}s "
            f"({metrics.avg_frame_rate:.2f} fps)"
        )
```

**Acceptance Criteria:**
- [x] All tests pass consistently (run 10 times, all pass)
- [x] Tests complete within reasonable time (<60s per test)
- [x] Clear test failure messages
- [x] Proper cleanup after each test

---

### üìä Task 1.4: Write Data Validity Tests (5h)

**Objective:** Validate structure and content of streamed data

File: `tests/integration/grpc/test_grpc_data_validity.py`

**Tests to Implement:**

1. **test_grpc_stream_frame_structure_valid**
   - Validates DataStream message structure
   - Checks for required fields (rows, max_amp, min_amp)
   - Verifies field types

2. **test_grpc_stream_data_dimensions_correct**
   - Validates intensity array dimensions
   - Checks sensor count matches configuration
   - Verifies frequency bins count

3. **test_grpc_stream_frequency_range_correct**
   - Validates frequency range in data
   - Compares against configured range
   - Checks for out-of-range values

4. **test_grpc_stream_data_not_all_zeros**
   - Ensures data contains actual measurements
   - Checks for reasonable amplitude values
   - Detects stuck/frozen streams

**Acceptance Criteria:**
- [x] Data structure validation comprehensive
- [x] Tests catch malformed data
- [x] Performance impact minimal (<5% overhead)

---

### ‚ö° Task 1.5: Write Performance Tests (4h)

**Objective:** Measure and validate streaming performance

File: `tests/integration/grpc/test_grpc_performance.py`

**Tests to Implement:**

1. **test_grpc_stream_continuous_delivery**
   - Measures frame delivery consistency
   - Detects frame drops
   - Validates steady stream rate

2. **test_grpc_stream_performance_metrics**
   - Throughput (frames/sec, MB/sec)
   - Latency (p50, p95, p99)
   - Resource usage (if applicable)

**Acceptance Criteria:**
- [x] Baseline metrics established
- [x] Tests fail if performance degrades >20%
- [x] Metrics logged to test reports

---

### üìö Task 1.6: Documentation (3h)

**Objective:** Complete documentation for framework usage and maintenance

**Files to Create:**

1. `tests/integration/grpc/README.md` - Test suite overview
2. `docs/GRPC_TESTING_GUIDE.md` - User guide
3. `docs/GRPC_CLIENT_API.md` - API reference
4. `CHANGELOG.md` update - Document new feature

**Acceptance Criteria:**
- [x] Documentation follows project standards
- [x] Examples for all major use cases
- [x] Troubleshooting section included

---

## üìà Success Metrics

### Quantitative Metrics

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| Test Coverage | >90% | pytest-cov report |
| Test Success Rate | >95% | 100 consecutive runs |
| First Frame Latency | <5s | Automated measurement |
| Stream Throughput | >10 fps | Performance tests |
| Documentation Completeness | 100% | All public APIs documented |

### Qualitative Metrics

- Code review approval from 2+ senior engineers
- Zero P0/P1 bugs in production after 1 month
- Framework adopted by team for new gRPC features
- Positive feedback from developers using the framework

---

## üîó Dependencies & Integration

### Upstream Dependencies

- ‚úÖ **Focus Server REST API** - Must be functional to configure tasks
- ‚úÖ **Kubernetes Infrastructure** - gRPC jobs run in K8s
- ‚úÖ **RabbitMQ** - Message bus for job coordination

### Downstream Consumers

- üîÑ **Story 3: Live Mode E2E Tests** - Will use gRPC client
- üîÑ **Story 4: Historic Mode E2E Tests** - Will use gRPC client
- üîÑ **Performance Test Suite** - Will measure gRPC performance

---

## üöß Risks & Mitigation

### Technical Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Proto schema mismatch | High | Medium | Request official proto files from dev team |
| Network instability | Medium | High | Implement robust retry logic, use timeouts |
| Self-signed SSL certs | Low | High | Support insecure connections in tests |
| gRPC job startup delay | Medium | Medium | Add polling logic, increase timeouts |

### Process Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Insufficient domain knowledge | High | Medium | Pair with backend developer for 1 day |
| Scope creep | Medium | Medium | Strict adherence to AC, defer nice-to-haves |
| Integration test flakiness | High | High | Implement proper fixtures, cleanup, retries |

---

## üéØ Definition of Done

- [x] All code merged to main branch
- [x] All tests passing in CI/CD pipeline
- [x] Code review approved by 2+ team members
- [x] Documentation complete and reviewed
- [x] Demo presented to team
- [x] No critical/high severity bugs
- [x] Test coverage >90%
- [x] Performance benchmarks established

---

## üìù Story Review Checklist

### Technical Review

- [ ] Code follows PEP8 and project conventions
- [ ] All functions have docstrings with examples
- [ ] Type hints used consistently
- [ ] No hardcoded values (use config files)
- [ ] Logging used appropriately (not print statements)
- [ ] Exceptions handled with proper error messages

### Testing Review

- [ ] All tests have clear, descriptive names
- [ ] Tests are independent (no shared state)
- [ ] Fixtures used for common setup
- [ ] Cleanup logic prevents resource leaks
- [ ] Tests run reliably (no flakiness)
- [ ] Performance tests have baseline metrics

### Documentation Review

- [ ] README includes quick start guide
- [ ] API reference covers all public methods
- [ ] Examples for common use cases
- [ ] Troubleshooting section included
- [ ] Architecture diagrams clear and accurate

---

## üîÑ Updates from Original Story

### Changes Made

1. **Increased Story Points:** 8 ‚Üí 13
   - Added proto file creation and compilation
   - Added comprehensive error handling
   - Added performance metrics collection
   - Added context manager support

2. **Enhanced Technical Details:**
   - Specific proto schema definition
   - Complete GrpcStreamClient implementation
   - Comprehensive test examples
   - Integration with existing infrastructure

3. **Improved Acceptance Criteria:**
   - Added quantitative metrics
   - Added specific performance targets
   - Added SSL/TLS considerations
   - Added retry logic requirements

4. **Risk Assessment:**
   - Identified proto schema mismatch risk
   - Added network instability handling
   - Considered self-signed certificate issues

### Rationale

Original story underestimated complexity of:
- Creating proto definitions from scratch
- Handling self-signed SSL certificates
- Implementing production-grade retry logic
- Writing comprehensive test suite with fixtures

---

## üìû Contact & Support

**Story Owner:** QA Automation TL  
**Technical Lead:** Backend Architect  
**Reviewers:** Senior QA Engineers + DevOps Engineer

**Questions?** Post in #automation-framework Slack channel

---

**Last Updated:** 2025-10-27  
**Story Status:** üìã Ready for Development  
**Version:** 2.0

