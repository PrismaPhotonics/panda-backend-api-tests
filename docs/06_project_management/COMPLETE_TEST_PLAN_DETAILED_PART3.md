# ×ª×•×›× ×™×ª ×‘×“×™×§×•×ª Focus Server - ××¤×•×¨×˜×ª ×‘××™×•×—×“ - ×—×œ×§ 3
## Historic Playback, Dynamic ROI, E2E Tests

---

## ğŸ¯ HISTORIC PLAYBACK TESTS - ×¡×§×™×¨×”

Historic Playback ×”×•× **×ª×›×•× ×” ×§×¨×™×˜×™×ª** ×©×××¤×©×¨×ª ×œ× ×ª×— **× ×ª×•× ×™× ××ª×™×¢×•×“**.

**××” ×–×” Historic Playback?**
- × ×™×’×•×Ÿ × ×ª×•× ×™× ×©× ×¨×©××• ×‘×¢×‘×¨
- `start_time` ×•-`end_time` ××•×’×“×¨×™× (×œ× null)
- ×§×¨×™××” ×-MongoDB ×•-storage
- ×¢×™×‘×•×“ ×•×©×œ×™×—×” ×›××™×œ×• ×–×” real-time

**×œ××” ×–×” ×—×©×•×‘?**
- × ×™×ª×•×— ××™×¨×•×¢×™× ×©×§×¨×• ×‘×¢×‘×¨
- debugging ×©×œ ×‘×¢×™×•×ª
- ×”×©×•×•××•×ª ×œ××•×¨×š ×–××Ÿ
- ××—×§×¨ ×•×¤×™×ª×•×—

---

## ğŸ¯ TEST #23: Historic Playback - Standard 5-Minute Range

**Jira ID**: PZ-13863  
**Priority**: High  
**Type**: Integration Test (Happy Path)  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©×”×©×¨×ª ××˜×¤×œ × ×›×•×Ÿ ×‘-**historic playback** ×¡×˜× ×“×¨×˜×™ ×©×œ 5 ×“×§×•×ª.

**××” ×–×” ××•××¨?**
1. ××’×“×™×¨×™× time range (5 ×“×§×•×ª ××—×•×¨×” ××¢×›×©×™×•)
2. ×©×•×œ×—×™× POST /config ×¢× `start_time` ×•-`end_time`
3. polling ×œ-`GET /waterfall` ×¢×“ ×©×”× ×ª×•× ×™× ××’×™×¢×™×
4. ×‘×“×™×§×” ×©×›×œ ×”× ×ª×•× ×™× ××”×˜×•×•×— ×”××‘×•×§×© ×”×ª×§×‘×œ×•
5. ×”××ª× ×” ×œ-status 208 (completion)

### × ×ª×•× ×™ ×”×‘×“×™×§×”

**Time Range Calculation:**
```python
# × ×§×•×“×ª ×¡×™×•×: ×¢×›×©×™×•
end_time_dt = datetime.now()

# × ×§×•×“×ª ×”×ª×—×œ×”: ×œ×¤× ×™ 5 ×“×§×•×ª
start_time_dt = end_time_dt - timedelta(minutes=5)

# ×”××¨×” ×œ×¤×•×¨××˜ Focus Server
start_time = datetime_to_yymmddHHMMSS(start_time_dt)
# "251027143000" (2025-10-27 14:30:00)

end_time = datetime_to_yymmddHHMMSS(end_time_dt)
# "251027143500" (2025-10-27 14:35:00)
```

**××” ×–×” `yymmddHHMMSS`?**
- ×¤×•×¨××˜ ×–××Ÿ ×©×œ Focus Server
- yy = year (25 = 2025)
- mm = month (10 = ××•×§×˜×•×‘×¨)
- dd = day (27)
- HH = hour (14 = 2PM)
- MM = minute (30)
- SS = second (00)

**Payload:**
```json
{
  "displayTimeAxisDuration": 10,
  "nfftSelection": 1024,
  "displayInfo": {"height": 1000},
  "channels": {"min": 0, "max": 50},
  "frequencyRange": {"min": 0, "max": 500},
  "start_time": "251027143000",
  "end_time": "251027143500",
  "view_type": 0
}
```

### ×ª×”×œ×™×š ×”×‘×“×™×§×” (Detailed Flow)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: Configuration                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Calculate time range (5 minutes)                  â”‚
â”‚ 2. Convert to yymmddHHMMSS format                    â”‚
â”‚ 3. Create config payload with start/end times        â”‚
â”‚ 4. POST /config/{task_id}                            â”‚
â”‚ 5. Expect: HTTP 200 "Config received successfully"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: Initial Polling (Waiting for Data)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. GET /waterfall/{task_id}/10                       â”‚
â”‚ 7. Status: 200 (no data yet)                         â”‚
â”‚ 8. Wait 2 seconds                                    â”‚
â”‚ 9. Poll again â†’ Status: 200 or 201                   â”‚
â”‚ 10. Repeat until status 201 received                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: Data Collection                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 11. GET /waterfall â†’ Status 201 (data available)    â”‚
â”‚ 12. Parse data blocks                                â”‚
â”‚ 13. Extract rows with timestamps and sensor data     â”‚
â”‚ 14. Collect to list                                  â”‚
â”‚ 15. Continue polling every 2 seconds                 â”‚
â”‚ 16. Status remains 201 while data flows              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4: Completion                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 17. GET /waterfall â†’ Status 208 (analyzer exited)   â”‚
â”‚ 18. Playback complete - no more data                 â”‚
â”‚ 19. Verify total data blocks > 0                     â”‚
â”‚ 20. Verify timestamps within range                   â”‚
â”‚ 21. Verify timestamps sequential                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Status Codes (×”×¡×‘×¨ ××¤×•×¨×˜)

| Status | ××©××¢×•×ª | ×¤×¢×•×œ×” |
|--------|--------|-------|
| **200** | No data yet | ×”××©×š polling - Baby Analyzer ×¢×“×™×™×Ÿ ××›×™×Ÿ |
| **201** | Data available | ×§×¨× data, ×”××©×š polling |
| **208** | Already Reported | **Playback ×”×¡×ª×™×™×** - ××™×Ÿ ×¢×•×“ data |
| **400** | Bad request | ×©×’×™××” ×‘parameters |
| **404** | Consumer not found | Task ×œ× ×§×™×™× |

### ×¦×¢×“×™ ×”×‘×“×™×§×” (Step-by-Step)

| # | ×¦×¢×“ | ×ª×•×¦××” | ×§×•×“ | ×–××Ÿ |
|---|-----|-------|-----|-----|
| 1 | ×—×™×©×•×‘ time range | 5 ×“×§×•×ª | `end - timedelta(minutes=5)` | - |
| 2 | ×”××¨×” ×œ×¤×•×¨××˜ | yymmddHHMMSS | `datetime_to_yymmddHHMMSS()` | - |
| 3 | ×•×™×“×•× ×¤×•×¨××˜ | 12 digits | `assert len(time_str) == 12` | - |
| 4 | POST /config | HTTP 200 | request × ×©×œ×— | ~0.5s |
| 5 | GET /waterfall (×¨××©×•×Ÿ) | 200 ××• 201 | polling ××ª×—×™×œ | ~0.5s |
| 6 | Polling loop | 200â†’201â†’208 | continue ×¢×“ 208 | 30-120s |
| 7 | ××™×¡×•×£ data blocks | > 0 blocks | collect ××”responses | - |
| 8 | ×§×‘×œ×ª status 208 | playback done | ×¡×™×•× | - |
| 9 | ×•×™×“×•× data > 0 | ×œ×¤×—×•×ª × ×ª×•×Ÿ ××—×“ | `assert len(all_data) > 0` | - |
| 10 | ×•×™×“×•× timestamps | ×‘×˜×•×•×— | `start <= ts <= end` | - |
| 11 | ×•×™×“×•× sequential | ×¢×•×œ×™× | `ts[i] < ts[i+1]` | - |

### ×ª×•×¦××” ×¦×¤×•×™×”

**Configuration Response:**
```http
HTTP/1.1 200 OK
{
  "status": "Config received successfully"
}
```

**Waterfall Responses (Status Progression):**

```
Poll 1:  HTTP 200 â†’ {"message": "No data yet"}
Poll 2:  HTTP 200 â†’ {"message": "No data yet"}
Poll 3:  HTTP 201 â†’ {"data": [...]}  â† Data starts!
Poll 4:  HTTP 201 â†’ {"data": [...]}
Poll 5:  HTTP 201 â†’ {"data": [...]}
...
Poll 45: HTTP 201 â†’ {"data": [...]}
Poll 46: HTTP 208 â†’ {}  â† Playback complete!
Poll 47: HTTP 208 â†’ {}
```

### ×™×™×©×•× ×‘×§×•×“

```python
def test_configure_historic_task_success(self, focus_server_api):
    """
    Test PZ-13863: Historic Playback - Standard 5-Minute Range
    
    Complete historic playback flow.
    """
    task_id = generate_task_id("historic_5min")
    logger.info(f"Test PZ-13863: Historic 5-minute playback - {task_id}")
    
    # PHASE 1: Calculate time range
    end_time_dt = datetime.now()
    start_time_dt = end_time_dt - timedelta(minutes=5)
    
    start_time = datetime_to_yymmddHHMMSS(start_time_dt)
    end_time = datetime_to_yymmddHHMMSS(end_time_dt)
    
    logger.info(f"Time range: {start_time} to {end_time}")
    
    # Validate time format
    assert validate_time_format_yymmddHHMMSS(start_time)
    assert validate_time_format_yymmddHHMMSS(end_time)
    
    # PHASE 2: Configure task
    historic_config_payload = {
        "displayTimeAxisDuration": 10,
        "nfftSelection": 1024,
        "displayInfo": {"height": 1000},
        "channels": {"min": 0, "max": 50},
        "frequencyRange": {"min": 0, "max": 500},
        "start_time": start_time,
        "end_time": end_time,
        "view_type": 0
    }
    
    config_request = ConfigTaskRequest(**historic_config_payload)
    response = focus_server_api.config_task(task_id, config_request)
    
    assert response.status == "Config received successfully"
    logger.info("âœ“ Historic task configured")
    
    # PHASE 3: Poll until completion
    status_transitions = []
    data_blocks_received = 0
    max_poll_attempts = 100
    poll_interval = 2.0
    
    for attempt in range(max_poll_attempts):
        waterfall_response = focus_server_api.get_waterfall(task_id, 10)
        
        # Track status transitions
        if not status_transitions or \
           status_transitions[-1] != waterfall_response.status_code:
            status_transitions.append(waterfall_response.status_code)
            logger.info(f"Status transition: {waterfall_response.status_code}")
        
        # Handle status codes
        if waterfall_response.status_code == 201:
            # Data available
            if waterfall_response.data:
                data_blocks_received += len(waterfall_response.data)
                logger.debug(f"Poll {attempt}: received data block")
        
        elif waterfall_response.status_code == 208:
            # Playback complete!
            logger.info(f"âœ“ Playback completed after {attempt + 1} polls")
            logger.info(f"âœ“ Total data blocks received: {data_blocks_received}")
            
            # Verify we got data
            assert data_blocks_received > 0, \
                "No data blocks received during playback"
            
            logger.info("âœ… Test PZ-13863 PASSED")
            return  # Test complete!
        
        # Wait before next poll
        time.sleep(poll_interval)
    
    # If we got here, polling timed out
    pytest.fail(f"Playback did not complete after {max_poll_attempts} polls")
```

**×–××Ÿ ×¨×™×¦×”**: 30-120 ×©× ×™×•×ª (×ª×œ×•×™ ×‘× ×ª×•× ×™×)

---

## ğŸ¯ TEST #24: Historic Playback - Status 208 Completion

**Jira ID**: PZ-13868  
**Priority**: High  
**Type**: Integration Test (Flow)  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©×”×©×¨×ª **××¡×™×™× × ×›×•×Ÿ** historic playback ×¢× **HTTP 208**.

**××” ×–×” Status 208?**
- HTTP 208 = "Already Reported"
- ××©××¢×•×ª: **×›×œ ×”× ×ª×•× ×™× × ×©×œ×—×•, playback ×”×¡×ª×™×™×**
- ××™×Ÿ ×¢×•×“ data ×–××™×Ÿ
- Baby Analyzer ×™×¦× (exited)

**×œ××” ×–×” ×§×¨×™×˜×™?**
- ×”×œ×§×•×— ×¦×¨×™×š ×œ×“×¢×ª **××ª×™ ×œ×¢×¦×•×¨ polling**
- ×‘×œ×™ 208, ×”×œ×§×•×— ×™××©×™×š ×œ×©×œ×•×— requests ×œ× ×¦×—
- ×‘×–×‘×•×– ××©××‘×™×, ×¡×¨×‘×•×œ ×¨×©×ª

### ×ª×”×œ×™×š ×”×‘×“×™×§×”

**1-Minute Historic Range** (×œ×‘×“×™×§×” ××”×™×¨×”):

```python
# Time range: 1 minute, 2 hours ago (ensure data exists)
base_time = datetime.now() - timedelta(hours=2)
start_time_dt = base_time
end_time_dt = base_time + timedelta(minutes=1)

start_time = "251027123000"  # Example
end_time = "251027123100"    # 1 minute later
```

### ×¦×¢×“×™ ×”×‘×“×™×§×”

| # | ×¦×¢×“ | ×ª×•×¦××” | ×—×©×™×‘×•×ª |
|---|-----|-------|---------|
| 1 | ×—×™×©×•×‘ 1-minute range | start/end | ×˜×•×•×— ×§×¦×¨ ×œ×‘×“×™×§×” ××”×™×¨×” |
| 2 | ×”××¨×” ×œ×¤×•×¨××˜ | yymmddHHMMSS | 12 digits |
| 3 | task_id | ID ×™×™×—×•×“×™ | ×–×™×”×•×™ |
| 4 | POST /config | HTTP 200 | ×”×ª×—×œ×” |
| 5 | Poll /waterfall | 200 initially | ×”××ª× ×” ×œdata |
| 6 | Continue polling | 200â†’201 | status progression |
| 7 | Track status codes | [200, 201, 208] | ×¨×™×©×•× transitions |
| 8 | Collect data | multiple blocks | ××™×¡×•×£ × ×ª×•× ×™× |
| 9 | **Receive 208** | playback done | **×”-completion signal** |
| 10 | ×‘×“×™×§×ª no data | data=null ×‘-208 | ××™×Ÿ data ×—×“×© |
| 11 | Poll 5 more times | ×¢×“×™×™×Ÿ 208 | consistency |
| 12 | ×‘×“×™×§×ª no 201 after 208 | ×œ× ×—×•×–×¨ 201 | ×œ× data × ×•×¡×£ |
| 13 | ××“×™×“×ª ×–××Ÿ | < 60s | ×‘×™×¦×•×¢×™× |

### ×ª×•×¦××” ×¦×¤×•×™×”

**Status Progression:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Time  â”‚ Poll # â”‚ Status â”‚ Meaning           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0s    â”‚ 1      â”‚ 200    â”‚ No data yet       â”‚
â”‚ 2s    â”‚ 2      â”‚ 200    â”‚ Still preparing   â”‚
â”‚ 4s    â”‚ 3      â”‚ 200    â”‚ Still preparing   â”‚
â”‚ 6s    â”‚ 4      â”‚ 201    â”‚ ğŸ‰ Data starts!   â”‚
â”‚ 8s    â”‚ 5      â”‚ 201    â”‚ Data flowing      â”‚
â”‚ 10s   â”‚ 6      â”‚ 201    â”‚ Data flowing      â”‚
â”‚ ...   â”‚ ...    â”‚ 201    â”‚ Data flowing      â”‚
â”‚ 50s   â”‚ 25     â”‚ 201    â”‚ Data flowing      â”‚
â”‚ 52s   â”‚ 26     â”‚ 208    â”‚ âœ… Complete!      â”‚
â”‚ 54s   â”‚ 27     â”‚ 208    â”‚ Still complete    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ×™×™×©×•× ×‘×§×•×“

```python
def test_historic_status_208_completion(self, focus_server_api):
    """
    Test PZ-13868: Historic Playback - Status 208 Completion
    
    Validates that historic playback properly completes with status 208.
    """
    task_id = generate_task_id("historic_208")
    logger.info(f"Test PZ-13868: Status 208 completion - {task_id}")
    
    # Configure 1-minute historic range (2 hours ago)
    base_time = datetime.now() - timedelta(hours=2)
    start_time = datetime_to_yymmddHHMMSS(base_time)
    end_time = datetime_to_yymmddHHMMSS(base_time + timedelta(minutes=1))
    
    payload = {
        "displayTimeAxisDuration": 10,
        "nfftSelection": 1024,
        "displayInfo": {"height": 1000},
        "channels": {"min": 0, "max": 50},
        "frequencyRange": {"min": 0, "max": 500},
        "start_time": start_time,
        "end_time": end_time,
        "view_type": 0
    }
    
    # Configure
    response = focus_server_api.config_task(task_id, ConfigTaskRequest(**payload))
    assert response.status == "Config received successfully"
    logger.info(f"âœ“ Task configured for time range: {start_time} - {end_time}")
    
    # Poll until status 208
    status_seen = []
    data_blocks_count = 0
    max_polls = 60
    
    for poll_num in range(max_polls):
        waterfall_response = focus_server_api.get_waterfall(task_id, 10)
        status = waterfall_response.status_code
        
        # Track status transitions
        if not status_seen or status_seen[-1] != status:
            status_seen.append(status)
            logger.info(f"Status transition at poll {poll_num}: {status}")
        
        if status == 200:
            # No data yet - continue
            pass
        
        elif status == 201:
            # Data available
            if waterfall_response.data:
                data_blocks_count += len(waterfall_response.data)
            logger.debug(f"Poll {poll_num}: Data block (total: {data_blocks_count})")
        
        elif status == 208:
            # âœ… Completion!
            logger.info(f"âœ… Status 208 received at poll {poll_num}")
            logger.info(f"âœ… Status progression: {status_seen}")
            logger.info(f"âœ… Total data blocks: {data_blocks_count}")
            
            # Verify data was received
            assert data_blocks_count > 0, "Should have received some data"
            
            # Verify no data in 208 response
            assert waterfall_response.data is None or \
                   len(waterfall_response.data) == 0, \
                   "Status 208 should have no data"
            
            # Poll 5 more times to verify consistency
            for extra_poll in range(5):
                response_again = focus_server_api.get_waterfall(task_id, 10)
                assert response_again.status_code in [208, 404, 400], \
                    f"After 208, should stay 208/404/400, got {response_again.status_code}"
            
            logger.info("âœ“ Status 208 is stable (no new data appears)")
            logger.info("âœ… Test PZ-13868 PASSED")
            return
        
        time.sleep(1.0)
    
    pytest.fail(f"Status 208 not received after {max_polls} polls. Status seen: {status_seen}")
```

**×–××Ÿ ×¨×™×¦×”**: 30-60 ×©× ×™×•×ª

---

## ğŸ¯ TEST #25: Historic - Invalid Time Range (End Before Start)

**Jira ID**: PZ-13869  
**Priority**: High  
**Type**: Integration Test (Negative)  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©×”×©×¨×ª **×“×•×—×”** ×‘×§×©×•×ª historic ×©×‘×”×Ÿ `end_time < start_time`.

**×œ××” ×–×” ×—×©×•×‘?**
- ×˜×•×•×— ×–××Ÿ ×”×¤×•×š ×”×•× **×œ× ××¤×©×¨×™**
- ×œ× × ×™×ª×Ÿ ×œ× ×’×Ÿ "×-14:00 ×¢×“ 13:00" - ×–×” ×”×¤×•×š!
- MongoDB query ×¢× ×–×× ×™× ×”×¤×•×›×™× â†’ ×ª×•×¦××•×ª ×¨×™×§×•×ª ××• ×©×’×™××•×ª

**×“×•×’××” ×œ×‘×¢×™×”:**
```
start_time = "251027140000" (14:00:00)
end_time   = "251027130000" (13:00:00)

×–×” ××•××¨: "×ª×Ÿ ×œ×™ × ×ª×•× ×™× ×©×”×ª×—×™×œ×• ×‘-14:00 ×•×”×¡×ª×™×™××• ×‘-13:00"
×–×” ×‘×œ×ª×™ ××¤×©×¨×™!
```

### × ×ª×•× ×™ ×”×‘×“×™×§×”

```python
# Create INVALID time range (end before start)
start_time_dt = datetime.now()
end_time_dt = datetime.now() - timedelta(minutes=10)  # 10 minutes BEFORE start!

start_time = "251027140000"  # 14:00
end_time = "251027135000"    # 13:50 â† Earlier!
```

**Payload:**
```json
{
  "start_time": "251027140000",
  "end_time": "251027135000"
}
```

### ×ª×•×¦××” ×¦×¤×•×™×”

```http
HTTP/1.1 400 Bad Request
{
  "error": "Invalid Time Range",
  "message": "start_time must be before end_time",
  "provided": {
    "start_time": "251027140000",
    "end_time": "251027135000"
  },
  "constraint": "start_time < end_time"
}
```

### ×™×™×©×•×

```python
def test_historic_invalid_time_range_end_before_start(self, focus_server_api):
    """
    Test PZ-13869: Historic - Invalid Time Range (End Before Start)
    """
    task_id = generate_task_id("historic_invalid_range")
    logger.info(f"Test PZ-13869: End before start - {task_id}")
    
    # Create invalid time range
    start_time_dt = datetime.now()
    end_time_dt = datetime.now() - timedelta(minutes=10)
    
    start_time = datetime_to_yymmddHHMMSS(start_time_dt)
    end_time = datetime_to_yymmddHHMMSS(end_time_dt)
    
    logger.info(f"Invalid range: {start_time} (start) to {end_time} (end)")
    logger.info(f"  End is {10} minutes BEFORE start (invalid!)")
    
    payload = generate_config_payload(live=False)
    payload['start_time'] = start_time
    payload['end_time'] = end_time
    
    # Expect rejection
    with pytest.raises(Exception) as exc_info:
        config_request = ConfigTaskRequest(**payload)
        focus_server_api.config_task(task_id, config_request)
    
    error_msg = str(exc_info.value).lower()
    assert "time" in error_msg or "range" in error_msg or "invalid" in error_msg
    logger.info(f"âœ… Invalid time range properly rejected")
    
    # Verify no task created
    waterfall_response = focus_server_api.get_waterfall(task_id, 10)
    assert waterfall_response.status_code == 404
```

---

## ğŸ¯ DYNAMIC ROI TESTS - ×¡×§×™×¨×”

Dynamic ROI = ×©×™× ×•×™ **Region of Interest** ×ª×•×š ×›×“×™ ×¨×™×¦×” (**×œ×œ× ×”×¤×¡×§×”**).

**××” ×–×” ROI?**
- ROI = ×˜×•×•×— ×”-sensors ×©×¨×•×¦×™× ×œ×¨××•×ª
- ×“×•×’××”: sensors 0-100

**××” ×–×” Dynamic ROI?**
- ×©×™× ×•×™ ×”-ROI **×‘×–××Ÿ ×××ª** ×‘×œ×™ ×œ×¢×¦×•×¨ ××ª ×”-task
- ×©×œ×™×—×ª ×¤×§×•×“×” ×“×¨×š **RabbitMQ**
- Baby Analyzer ××ª××ª×—×œ ×¢× ROI ×—×“×©

**×œ××” ×–×” ×—×©×•×‘?**
- **×’××™×©×•×ª** - ×”××©×ª××© ×™×›×•×œ ×œ×¢×‘×•×¨ ×‘×™×Ÿ ××–×•×¨×™×
- **×‘×™×¦×•×¢×™×** - ×œ× ×¦×¨×™×š task ×—×“×©
- **UX ×˜×•×‘** - ×©×™× ×•×™ ××”×™×¨ ×œ×œ× ×”×¤×¡×§×”

---

## ğŸ¯ TEST #26: Send ROI Change Command via RabbitMQ

**Jira ID**: PZ-13784  
**Priority**: High  
**Type**: Integration Test  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©×©×œ×™×—×ª **×¤×§×•×“×ª ROI** ×“×¨×š RabbitMQ ×¢×•×‘×“×ª ×œ×œ× ×©×’×™××•×ª.

**××” ×”×ª×”×œ×™×š?**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TEST CODE                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Create BabyAnalyzerMQClient                     â”‚
â”‚ 2. Connect to RabbitMQ (10.10.100.107:5672)        â”‚
â”‚ 3. Create RegionOfInterestCommand                  â”‚
â”‚ 4. Publish to baby_analyzer exchange               â”‚
â”‚ 5. Verify ACK received                             â”‚
â”‚ 6. Disconnect                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ AMQP Protocol
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RABBITMQ (10.10.100.107)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Exchange: baby_analyzer                            â”‚
â”‚ Routing Key: roi                                    â”‚
â”‚ Queue: baby_analyzer_commands                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BABY ANALYZER (Kubernetes Pod)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Receive ROI command from queue                  â”‚
â”‚ 2. Parse command: start=50, end=150                â”‚
â”‚ 3. Stop current processing                         â”‚
â”‚ 4. Reinitialize with new ROI                       â”‚
â”‚ 5. Start processing new sensor range               â”‚
â”‚ 6. Send data for sensors 50-150 only               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RabbitMQ Connection Details

**Connection Parameters:**
```python
rabbitmq_config = {
    "host": "10.10.100.107",
    "port": 5672,
    "username": "prisma",
    "password": "prisma",
    "vhost": "/"
}
```

**Exchange Details:**
- Name: `baby_analyzer`
- Type: `topic` ××• `direct`
- Durable: `True`

**Routing Keys:**
- ROI: `roi`
- CAxis: `caxis`
- Colormap: `colormap`

### ×¤×§×•×“×ª ROI

**Structure:**
```json
{
  "command_type": "RegionOfInterestCommand",
  "start": 50,
  "end": 150,
  "routing_key": "roi"
}
```

**Serialization:**
```python
import json

command = {
    "command_type": "RegionOfInterestCommand",
    "start": 50,
    "end": 150
}

message_body = json.dumps(command)
# '{"command_type": "RegionOfInterestCommand", "start": 50, "end": 150}'
```

### ×¦×¢×“×™ ×”×‘×“×™×§×”

| # | ×¦×¢×“ | ×ª×•×¦××” | ×¤×™×¨×•×˜ |
|---|-----|-------|-------|
| 1 | ×—×™×‘×•×¨ ×œ-RabbitMQ | Connected | `client.connect()` |
| 2 | ×•×™×“×•× ×—×™×‘×•×¨ | is_connected=True | `assert client.is_connected()` |
| 3 | ×‘×“×™×§×ª exchange | ×§×™×™× | optional |
| 4 | ×™×¦×™×¨×ª ROI command | dict | `{"start": 50, "end": 150}` |
| 5 | Publish | message sent | `client.send_roi_change()` |
| 6 | ×‘×“×™×§×ª ACK | acknowledged | RabbitMQ ×××©×¨ |
| 7 | ×•×™×“×•× no exceptions | ×œ× ×©×’×™××•×ª | ×”×¤×§×•×“×” ×¢×‘×¨×” |
| 8 | Disconnect | closed cleanly | `client.disconnect()` |

### ×™×™×©×•× ×‘×§×•×“ (×§×™×™×!)

**×§×•×‘×¥**: `tests/integration/api/test_dynamic_roi_adjustment.py`  
**Function**: `test_send_roi_change_command`

```python
import pytest
import logging
from src.infrastructure.baby_analyzer_mq_client import BabyAnalyzerMQClient

logger = logging.getLogger(__name__)

def test_send_roi_change_command(self, baby_analyzer_mq_client):
    """
    Test PZ-13784: Send ROI Change Command via RabbitMQ
    
    Validates successful ROI command publication to RabbitMQ.
    """
    logger.info("Test PZ-13784: Send ROI command via RabbitMQ")
    
    # Verify connection
    assert baby_analyzer_mq_client.is_connected()
    logger.info("âœ“ Connected to RabbitMQ")
    
    # Define new ROI
    new_start = 50
    new_end = 150
    logger.info(f"Sending ROI change: [{new_start}, {new_end}]")
    
    # Send command
    baby_analyzer_mq_client.send_roi_change(
        start=new_start,
        end=new_end,
        routing_key="roi"
    )
    
    logger.info("âœ“ ROI command sent successfully")
    logger.info("âœ… Test PZ-13784 PASSED")
```

**×”×¤×•× ×§×¦×™×” `send_roi_change`** (×‘-`BabyAnalyzerMQClient`):

```python
class BabyAnalyzerMQClient:
    """RabbitMQ client for Baby Analyzer commands."""
    
    def send_roi_change(self, start: int, end: int, routing_key: str = "roi"):
        """
        Send ROI (Region of Interest) change command.
        
        Args:
            start: Start sensor index
            end: End sensor index
            routing_key: RabbitMQ routing key (default: "roi")
        """
        if not self.is_connected():
            raise ConnectionError("Not connected to RabbitMQ")
        
        # Create command payload
        command = {
            "command_type": "RegionOfInterestCommand",
            "start": start,
            "end": end
        }
        
        # Serialize to JSON
        message_body = json.dumps(command)
        
        # Publish to exchange
        self.channel.basic_publish(
            exchange='baby_analyzer',
            routing_key=routing_key,
            body=message_body,
            properties=pika.BasicProperties(
                delivery_mode=2,  # Make message persistent
                content_type='application/json'
            )
        )
        
        self.logger.info(f"ROI command published: [{start}, {end}]")
```

---

## ğŸ¯ TEST #27: ROI Change with Safety Validation

**Jira ID**: PZ-13785  
**Priority**: Critical  
**Type**: Integration Test  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©**Safety Validation** ×¢×•×‘×“ ×œ×¤× ×™ ×©×œ×™×—×ª ×¤×§×•×“×ª ROI.

**××” ×–×” Safety Validation?**
×× ×’× ×•×Ÿ ×©×‘×•×“×§ ×©-ROI ×”×—×“×© **×œ× ××¡×•×›×Ÿ**:
- ×œ× ×©×™× ×•×™ ×’×“×•×œ ××“×™ (> 50%)
- ×œ× ×§×¤×™×¦×” ×’×“×•×œ×” (low overlap)
- ×œ× ×¢×¨×›×™× ×œ× ×ª×§×¤×™×

**×œ××” ×–×” × ×—×•×¥?**
- **×× ×™×¢×ª ×˜×¢×•×™×•×ª** - ××©×ª××© ×œ× ××©× ×” ×‘×˜×¢×•×ª ×œ-ROI ×œ× ×¨×œ×•×•× ×˜×™
- **×”×’× ×” ×¢×œ ×‘×™×¦×•×¢×™×** - ×©×™× ×•×™ ×’×“×•×œ ××“×™ ×™×›×•×œ ×œ×”×¢××™×¡
- **UX ×˜×•×‘** - ××–×”×¨×•×ª ×¢×œ ×©×™× ×•×™×™× ×“×¨×¡×˜×™×™×

### Safety Rules

**×›×œ×œ×™ ×‘×˜×™×—×•×ª:**
```python
safety_rules = {
    "max_change_percent": 50.0,     # ×©×™× ×•×™ ×’×•×“×œ ××§×¡×™××œ×™: 50%
    "min_overlap_percent": 30.0,    # overlap ××™× ×™××œ×™: 30%
    "allow_negative_values": False,  # ×¢×¨×›×™× ×©×œ×™×œ×™×™×: ×œ×
    "max_sensor_id": 10000          # sensor ××§×¡×™××œ×™
}
```

### ×—×™×©×•×‘×™ Safety

**×—×™×©×•×‘ 1: Size Change**
```python
current_size = current_max - current_min
new_size = new_max - new_min
size_change_percent = abs(new_size - current_size) / current_size * 100

# Example:
current: [0, 100] â†’ size = 100
new: [0, 120] â†’ size = 120
change = (120 - 100) / 100 * 100 = 20%  â† OK (< 50%)
```

**×—×™×©×•×‘ 2: Overlap**
```python
overlap_start = max(current_min, new_min)
overlap_end = min(current_max, new_max)
overlap_size = max(0, overlap_end - overlap_start)
overlap_percent = (overlap_size / current_size) * 100

# Example:
current: [0, 100]
new: [20, 120]
overlap: [20, 100] â†’ size = 80
overlap% = 80 / 100 * 100 = 80%  â† Good (> 30%)
```

### ×ª×¨×—×™×©: Safe Change

**Current ROI**: [0, 100]  
**New ROI**: [20, 120]

**Calculations:**
```
Current size: 100
New size: 120
Size change: 20% â† OK (< 50%)

Overlap: [20, 100] = 80 sensors
Overlap%: 80% â† Excellent (> 30%)

Result: âœ… SAFE
```

### ×™×™×©×•×

```python
def test_roi_change_with_validation(self, baby_analyzer_mq_client):
    """
    Test PZ-13785: ROI Change with Safety Validation
    """
    logger.info("Test PZ-13785: ROI with safety validation")
    
    # Current ROI
    current_min = 0
    current_max = 100
    
    # New ROI
    new_min = 20
    new_max = 120
    
    # VALIDATE SAFETY
    safety_result = validate_roi_change_safety(
        current_min=current_min,
        current_max=current_max,
        new_min=new_min,
        new_max=new_max,
        max_change_percent=50.0
    )
    
    logger.info(f"Safety validation result:")
    logger.info(f"  Is safe: {safety_result['is_safe']}")
    logger.info(f"  Size change: {safety_result['size_change_percent']:.1f}%")
    logger.info(f"  Overlap: {safety_result['overlap_percent']:.1f}%")
    logger.info(f"  Warnings: {safety_result['warnings']}")
    
    # Verify safe
    assert safety_result['is_safe'] == True
    assert len(safety_result['warnings']) == 0
    assert safety_result['overlap_percent'] >= 30.0
    
    # Send command (only if safe!)
    if safety_result['is_safe']:
        baby_analyzer_mq_client.send_roi_change(
            start=new_min,
            end=new_max
        )
        logger.info("âœ“ ROI command sent (passed safety validation)")
    else:
        logger.warning("âœ— ROI command NOT sent (failed safety validation)")
    
    logger.info("âœ… Test PZ-13785 PASSED")
```

**×¤×•× ×§×¦×™×™×ª ×”-Validation** (`src/utils/validators.py`):

```python
def validate_roi_change_safety(
    current_min: int,
    current_max: int,
    new_min: int,
    new_max: int,
    max_change_percent: float = 50.0,
    min_overlap_percent: float = 30.0
) -> Dict[str, Any]:
    """
    Validate safety of ROI change to prevent unsafe transitions.
    
    Args:
        current_min: Current ROI minimum sensor
        current_max: Current ROI maximum sensor
        new_min: New ROI minimum sensor
        new_max: New ROI maximum sensor
        max_change_percent: Maximum allowed size change (%)
        min_overlap_percent: Minimum required overlap (%)
        
    Returns:
        Dict with:
            - is_safe: bool
            - size_change_percent: float
            - overlap_percent: float
            - warnings: list
    """
    warnings = []
    
    # VALIDATION 1: Check for reversed range
    if new_min > new_max:
        warnings.append(f"Reversed range: min ({new_min}) > max ({new_max})")
        return {
            'is_safe': False,
            'size_change_percent': 0,
            'overlap_percent': 0,
            'warnings': warnings
        }
    
    # VALIDATION 2: Check for negative values
    if new_min < 0 or new_max < 0:
        warnings.append(f"Negative sensor indices not allowed")
        return {
            'is_safe': False,
            'size_change_percent': 0,
            'overlap_percent': 0,
            'warnings': warnings
        }
    
    # VALIDATION 3: Check for zero size
    new_size = new_max - new_min
    if new_size == 0:
        warnings.append(f"Zero-size ROI (min == max)")
        return {
            'is_safe': False,
            'size_change_percent': 0,
            'overlap_percent': 0,
            'warnings': warnings
        }
    
    # CALCULATION 1: Size change
    current_size = current_max - current_min
    size_change_percent = abs(new_size - current_size) / current_size * 100
    
    if size_change_percent > max_change_percent:
        warnings.append(
            f"Size change ({size_change_percent:.1f}%) exceeds "
            f"maximum ({max_change_percent}%)"
        )
    
    # CALCULATION 2: Overlap
    overlap_start = max(current_min, new_min)
    overlap_end = min(current_max, new_max)
    overlap_size = max(0, overlap_end - overlap_start)
    overlap_percent = (overlap_size / current_size) * 100 if current_size > 0 else 0
    
    if overlap_percent < min_overlap_percent:
        warnings.append(
            f"Low overlap ({overlap_percent:.1f}%) - "
            f"minimum recommended is {min_overlap_percent}%"
        )
    
    # DETERMINATION: Is it safe?
    is_safe = len(warnings) == 0
    
    return {
        'is_safe': is_safe,
        'size_change_percent': size_change_percent,
        'overlap_percent': overlap_percent,
        'current_size': current_size,
        'new_size': new_size,
        'overlap_sensors': overlap_size,
        'warnings': warnings
    }
```

---

## ğŸ¯ TEST #28: Unsafe ROI Change (Large Jump)

**Jira ID**: PZ-13797  
**Priority**: Critical  
**Type**: Integration Test (Negative)  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©-Safety Validation **××–×”×”** ×©×™× ×•×™×™ ROI **××¡×•×›× ×™×** (×§×¤×™×¦×•×ª ×’×“×•×œ×•×ª).

**××” ×–×” Large Jump?**
×©×™× ×•×™ ROI ×©**××™×Ÿ ×œ×• overlap** ×¢× ×”-ROI ×”× ×•×›×—×™.

**×“×•×’××”:**
```
Current ROI: [0, 100]
New ROI: [200, 300]

Overlap: ZERO!
Size change: 0% (××•×ª×• ×’×•×“×œ)
Position shift: +200 sensors

×–×” ××¡×•×›×Ÿ ×›×™: ×”××©×ª××© ×§×¤×¥ ×œ××–×•×¨ ×œ×’××¨×™ ××—×¨!
```

### × ×ª×•× ×™ ×”×‘×“×™×§×”

```python
current_min = 0
current_max = 100

new_min = 200
new_max = 300

# This is unsafe because:
# - No overlap (0%)
# - Large position shift (+200)
```

### ×ª×•×¦××” ×¦×¤×•×™×”

```python
safety_result = {
    'is_safe': False,  # âŒ NOT SAFE
    'size_change_percent': 0.0,  # Same size
    'overlap_percent': 0.0,  # âŒ NO OVERLAP!
    'warnings': [
        "Low overlap (0.0%) - minimum recommended is 30.0%"
    ]
}
```

### ×™×™×©×•×

```python
def test_unsafe_roi_change(self, baby_analyzer_mq_client):
    """
    Test PZ-13797: Unsafe ROI Change (Large Jump)
    
    Validates detection of unsafe ROI changes.
    """
    logger.info("Test PZ-13797: Unsafe ROI change detection")
    
    current_min = 0
    current_max = 100
    new_min = 200  # Large jump!
    new_max = 300
    
    # Run safety validation
    safety_result = validate_roi_change_safety(
        current_min=current_min,
        current_max=current_max,
        new_min=new_min,
        new_max=new_max,
        max_change_percent=50.0
    )
    
    logger.info(f"Unsafe change detection:")
    logger.info(f"  Is safe: {safety_result['is_safe']}")
    logger.info(f"  Overlap: {safety_result['overlap_percent']:.1f}%")
    logger.info(f"  Warnings: {safety_result['warnings']}")
    
    # Verify detected as unsafe
    assert safety_result['is_safe'] == False, \
        "Large jump should be detected as unsafe"
    
    assert safety_result['overlap_percent'] == 0, \
        "No overlap expected for large jump"
    
    assert len(safety_result['warnings']) > 0, \
        "Warnings should be generated for unsafe changes"
    
    logger.info("âœ… Unsafe ROI change correctly detected")
    
    # In production: would NOT send this command
    # Or would send with explicit user confirmation
```

---

## ğŸ¯ TEST #29: Unsafe ROI - Size Change > 50%

**Jira ID**: PZ-13798  
**Priority**: High  
**Type**: Integration Test (Negative)  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©-Safety Validation **××–×”×”** ×©×™× ×•×™×™ **×’×•×“×œ ×’×“×•×œ×™×** (> 50%).

**×“×•×’××”:**
```
Current ROI: [0, 100] â†’ size = 100
New ROI: [0, 250] â†’ size = 250

Size change: (250 - 100) / 100 * 100 = 150%  â† Unsafe!
```

**×œ××” ×–×” ××¡×•×›×Ÿ?**
- ×©×™× ×•×™ ×’×•×“×œ ×’×“×•×œ â†’ ×¢×•××¡ ××©×ª× ×” ×“×¨×¡×˜×™×ª
- CPU/Memory jump
- ×¢×œ×•×œ ×œ×”×¢××™×¡ ×¢×œ ×”××¢×¨×›×ª

### ×™×™×©×•×

```python
def test_unsafe_roi_range_change(self):
    """Test PZ-13798: Size change > 50%"""
    
    current_size = 100
    new_size = 250
    size_change_percent = ((new_size - current_size) / current_size) * 100
    
    # Verify calculation
    assert size_change_percent == 150, f"Expected 150%, got {size_change_percent}%"
    logger.info(f"Size change: {size_change_percent}% (> 50% threshold)")
    
    # Run validation
    safety_result = validate_roi_change_safety(
        current_min=0,
        current_max=100,
        new_min=0,
        new_max=250,
        max_change_percent=50.0
    )
    
    # Verify detected as unsafe
    assert safety_result['is_safe'] == False
    assert safety_result['size_change_percent'] > 50
    logger.info("âœ… Unsafe size change detected")
```

---

## ğŸ¯ TEST #30-32: ROI Edge Cases

### TEST #30: ROI with Reversed Range

**Jira ID**: PZ-13791  
**××˜×¨×”**: ×“×—×™×™×ª ROI ×”×¤×•×š (start > end)

```python
start = 150
end = 50  # Earlier than start!

safety_result = validate_roi_change_safety(
    current_min=0,
    current_max=100,
    new_min=start,
    new_max=end
)

assert safety_result['is_safe'] == False
assert "reversed" in safety_result['warnings'][0].lower()
```

---

### TEST #31: ROI with Equal Start/End

**Jira ID**: PZ-13790  
**××˜×¨×”**: ×“×—×™×™×ª ROI ×‘×’×•×“×œ ××¤×¡

```python
start = 50
end = 50  # Same!

# Zero size = invalid
assert (end - start) == 0

safety_result = validate_roi_change_safety(...)
assert safety_result['is_safe'] == False
```

---

### TEST #32: ROI with Negative Values

**Jira IDs**: PZ-13792, PZ-13793  
**××˜×¨×”**: ×“×—×™×™×ª sensors ×©×œ×™×œ×™×™×

```python
# Negative start
start = -10
end = 50
assert start < 0  # Invalid

# Negative end  
start = 10
end = -50
assert end < 0  # Invalid
```

---

## ğŸ¯ TEST #33-35: ROI Size Variations

### TEST #33: Small Range

**Jira ID**: PZ-13794  
**××˜×¨×”**: edge case - ROI ×§×˜×Ÿ ×××•×“ (2 sensors)

```python
start = 50
end = 52
size = 2  # Very small but valid

# May generate warning but should be allowed
```

---

### TEST #34: Large Range

**Jira ID**: PZ-13795  
**××˜×¨×”**: edge case - ROI ××§×¡×™××œ×™ (×›×œ ×”-sensors)

```python
start = 0
end = 512  # All sensors
size = 512  # Maximum

# Should be allowed but may impact performance
```

---

### TEST #35: ROI Starting at Zero

**Jira ID**: PZ-13796  
**××˜×¨×”**: boundary - ROI ××ª×—×™×œ ×‘-0

```python
start = 0  # Boundary!
end = 50

# Verify no off-by-one errors
```

---

## ğŸ¯ TEST #36: CAxis Adjustment

**Jira ID**: PZ-13801  
**Priority**: Medium  
**Type**: Integration Test  
**Status**: âœ… **×××•××©!**

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×‘×•×“×§×™× ×©× ×™×ª×Ÿ ×œ×©× ×•×ª **CAxis** (Color Axis) ×“×¨×š RabbitMQ.

**××” ×–×” CAxis?**
- CAxis = ×˜×•×•×— ×”×¦×‘×¢×™× (colormap range)
- ×§×•×‘×¢ ××™×–×” ×¢×¨×›×™ amplitude ×××•×¤×™× ×œ××™×œ×• ×¦×‘×¢×™×
- ×“×•×’××”: [-80, -20] dB

**×œ××” ×–×” ×©×™××•×©×™?**
- ×”×ª×××ª contrast ×œ×”×¦×’×”
- ×”×“×’×©×ª ××•×ª×•×ª ×—×œ×©×™× ××• ×—×–×§×™×
- ×©×™×¤×•×¨ UX

### ×“×•×’××”

**Before:**
```
CAxis: [-100, 0] dB
Colormap: jet
â†’ ××•×ª×•×ª ×—×œ×©×™× (-80 dB) × ×¨××™× ×›×—×•×œ×™×
â†’ ××•×ª×•×ª ×—×–×§×™× (-20 dB) × ×¨××™× ××“×•××™×
```

**After (CAxis Adjustment):**
```
CAxis: [-80, -20] dB
Colormap: jet (same)
â†’ focus ×¢×œ ×˜×•×•×— ×¡×¤×¦×™×¤×™
â†’ better contrast
```

### Command Structure

```json
{
  "command_type": "CAxisAdjustmentCommand",
  "caxis_min": -80,
  "caxis_max": -20,
  "routing_key": "caxis"
}
```

### ×•×œ×™×“×¦×™×”

**Valid CAxis:**
```python
caxis_min = -80
caxis_max = -20

# Verify valid
assert caxis_min < caxis_max  # âœ… Valid range
```

**Invalid CAxis (reversed):**
```python
caxis_min = -20
caxis_max = -80  # Reversed!

assert caxis_min > caxis_max  # âŒ Invalid
```

### ×™×™×©×•×

```python
def test_caxis_adjustment(self, baby_analyzer_mq_client):
    """Test PZ-13801: CAxis Adjustment Command"""
    
    caxis_min = -80
    caxis_max = -20
    
    # Validate range
    assert caxis_min < caxis_max, "CAxis range must be valid"
    logger.info(f"CAxis range: [{caxis_min}, {caxis_max}] dB")
    
    # Send command
    baby_analyzer_mq_client.send_caxis_adjustment(
        caxis_min=caxis_min,
        caxis_max=caxis_max,
        routing_key="caxis"
    )
    
    logger.info("âœ… CAxis command sent successfully")
```

---

## ğŸ¯ E2E TEST: Configure â†’ Metadata â†’ gRPC

**Jira ID**: PZ-13570  
**Priority**: High  
**Type**: E2E Test  
**Status**: ×—×œ×§×™

### ××˜×¨×ª ×”×˜×¡×˜

**××” ×‘×•×“×§×™×?**
×ª×”×œ×™×š **××œ×** ×-×' ×¢×“ ×ª':
1. POST /configure
2. GET /metadata
3. ×—×™×‘×•×¨ ×œ-gRPC stream
4. ×§×‘×œ×ª data frames

**×œ××” ×–×” E2E?**
- ×‘×•×“×§ ××ª **×›×œ ×”×¨×›×™×‘×™× ×‘×™×—×“**
- ××•×•×“× ×©×”×–×¨×™××” ×”××œ××” ×¢×•×‘×“×ª
- ××××ª ×©-data contract × ×©××¨

### ×ª×”×œ×™×š ××œ×

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Configuration                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ POST /configure                          â”‚
â”‚ Response: {job_id, stream_url, stream_port} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Metadata Retrieval               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GET /metadata/{job_id}                   â”‚
â”‚ Response: configuration details          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: gRPC Connection                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Connect to stream_url:stream_port        â”‚
â”‚ Open gRPC stream                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Data Streaming                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Receive DataStream messages              â”‚
â”‚ Verify: timestamps, spectrograms, shapes â”‚
â”‚ No corruption or connection errors       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Contract

**gRPC Message Expected Fields:**
```protobuf
message DataStream {
  repeated SpectrogramRow rows = 1;
  double current_max_amp = 2;
  double current_min_amp = 3;
}

message SpectrogramRow {
  string canvasId = 1;
  repeated SensorIntensity sensors = 2;
  int64 startTimestamp = 3;
  int64 endTimestamp = 4;
}

message SensorIntensity {
  int32 id = 1;
  repeated float intensity = 2;
}
```

### ×™×™×©×•× (×—×œ×§×™)

```python
def test_e2e_grpc_mock_flow(self, focus_server_api):
    """
    Test PZ-13570: E2E - Configure â†’ Metadata â†’ gRPC
    
    Full integration test with gRPC streaming.
    """
    logger.info("Test PZ-13570: E2E gRPC flow")
    
    # STEP 1: Configure
    payload = {...}  # Standard config
    config_request = ConfigureRequest(**payload)
    response = focus_server_api.configure_streaming_job(config_request)
    
    assert response.job_id
    job_id = response.job_id
    stream_url = response.stream_url
    stream_port = response.stream_port
    
    logger.info(f"âœ“ Configured: {job_id}")
    logger.info(f"âœ“ Stream: {stream_url}:{stream_port}")
    
    # STEP 2: Get metadata
    metadata = focus_server_api.get_job_metadata(job_id)
    assert metadata is not None
    logger.info("âœ“ Metadata retrieved")
    
    # STEP 3: Connect to gRPC (requires grpc library)
    # import grpc
    # channel = grpc.insecure_channel(f"{stream_url}:{stream_port}")
    # stub = DataStreamStub(channel)
    
    # STEP 4: Stream data
    # stream = stub.GetDataStream(request)
    # for message in stream:
    #     verify_data_fields(message)
    
    logger.info("âœ… Test PZ-13570 (partial)")
```

**×”×¢×¨×”**: gRPC streaming ×“×•×¨×© ×¡×¤×¨×™×•×ª × ×•×¡×¤×•×ª ×•×”×’×“×¨×ª proto files.

---

## ğŸ¯ PERFORMANCE TESTS

### TEST #37: /configure Latency p95

**Jira ID**: PZ-13571  
**Priority**: Low-Medium  
**Type**: Performance Test  
**Status**: ×—×œ×§×™

**××˜×¨×”**: ×œ×•×•×“× ×©-95% ××”-requests ×œ-`/configure` ×¢×•× ×•×ª ×ª×•×š < 2 ×©× ×™×•×ª.

**××” ×–×” p95?**
- p95 = Percentile 95
- 95% ××”×‘×§×©×•×ª ××ª×—×ª ×œ×¢×¨×š ×–×”
- × ×•×ª×Ÿ ×ª××•× ×” ×©×œ ×‘×™×¦×•×¢×™× ×˜×™×¤×•×¡×™×™× (×œ× ×¨×§ ×××•×¦×¢)

**×ª×”×œ×™×š:**
```python
# Send 50 requests
latencies = []
for i in range(50):
    start = time.time()
    response = api.configure_streaming_job(request)
    latency = time.time() - start
    latencies.append(latency)

# Calculate p95
latencies_sorted = sorted(latencies)
p95_index = int(len(latencies) * 0.95)
p95_latency = latencies_sorted[p95_index]

# Verify SLA
assert p95_latency < 2.0, f"p95 latency ({p95_latency:.2f}s) exceeds 2.0s"
```

---

## ğŸ“Š ×¡×™×›×•× ×›×œ ×”×˜×¡×˜×™×

### Integration Tests (44 total)

| ID | ×©× | Priority | Status | ×–××Ÿ |
|----|-----|----------|--------|-----|
| PZ-13909 | Historic Missing end_time | High | TODO | 1s |
| PZ-13907 | Historic Missing start_time | High | TODO | 1s |
| PZ-13906 | Low Throughput | Medium | âœ… | 2-3s |
| PZ-13904 | Resource Estimation | High | âœ… | 1-2s |
| PZ-13903 | Nyquist Limit | **CRITICAL** | âœ… | 2-3s |
| PZ-13901 | NFFT Variations | High | âœ… | 5-10s |
| PZ-13897 | GET /sensors | High | âœ… | 1-2s |
| PZ-13879 | Missing Required Fields | High | âœ… | 3-5s |
| PZ-13878 | Invalid View Type | High | âœ… | 1s |
| PZ-13877 | Invalid Freq Range | High | âœ… | 1s |
| PZ-13876 | Invalid Channel Range | High | âœ… | 1s |
| PZ-13873 | Valid Configuration | High | âœ… | 3-5s |
| PZ-13872 | Historic E2E | High | âœ… | 60-120s |
| PZ-13871 | Timestamp Ordering | High | âœ… | 20-40s |
| PZ-13870 | Future Timestamps | Medium | âœ… | 10-20s |
| PZ-13869 | Invalid Time Range | High | âœ… | 1s |
| PZ-13868 | Status 208 | High | âœ… | 30-60s |
| PZ-13865 | Short Duration (1 min) | Medium | âœ… | 20-30s |
| PZ-13863 | Standard 5-min Range | High | âœ… | 30-120s |

### SingleChannel Tests (15 tests)

| ID | ×©× | Status | ×ª×™××•×¨ |
|----|-----|--------|-------|
| PZ-13862 | SingleChannel E2E | âœ… | ×ª×”×œ×™×š ××œ× |
| PZ-13861 | Stream Mapping | âœ… | ×•×œ×™×“×¦×™×™×ª mapping |
| PZ-13860 | Metadata Consistency | âœ… | ×¢×§×‘×™×•×ª metadata |
| PZ-13859 | Polling Stability | âœ… | 100 polls |
| PZ-13858 | Rapid Reconfig | âœ… | 5 reconfigurations |
| PZ-13857 | NFFT Validation | âœ… | NFFT ×©×•× ×™× |
| PZ-13855 | Canvas Height | âœ… | ×’×‘×”×™× ×©×•× ×™× |
| PZ-13854 | Frequency Range | âœ… | ×˜×•×•×—×™× ×©×•× ×™× |
| PZ-13853 | Data Consistency | âœ… | reproducibility |
| PZ-13852 | Min > Max | âœ… | negative test |
| PZ-13837 | Negative Channel | âœ… | channel < 0 |
| PZ-13835 | Out of Range High | âœ… | channel > max |
| PZ-13834 | Middle Channel | âœ… | ×××¦×¢×™ |
| PZ-13833 | Maximum Channel | âœ… | ××—×¨×•×Ÿ |
| PZ-13832 | Minimum Channel (0) | âœ… | ×¨××©×•×Ÿ |

### Dynamic ROI Tests (13 tests)

| ID | ×©× | Status |
|----|-----|--------|
| PZ-13784 | Send ROI Command | âœ… |
| PZ-13785 | ROI with Safety | âœ… |
| PZ-13786 | Multiple ROI Changes | âœ… |
| PZ-13787 | ROI Expansion | âœ… |
| PZ-13788 | ROI Shrinking | âœ… |
| PZ-13789 | ROI Shift | âœ… |
| PZ-13790 | ROI Equal Start/End | âœ… |
| PZ-13791 | ROI Reversed | âœ… |
| PZ-13792 | ROI Negative Start | âœ… |
| PZ-13793 | ROI Negative End | âœ… |
| PZ-13794 | ROI Small Range | âœ… |
| PZ-13795 | ROI Large Range | âœ… |
| PZ-13796 | ROI at Zero | âœ… |

---

**×”××©×š ×‘×—×œ×§ 4 - Infrastructure, Security, Data Quality...**

