# Interrogator Discovery Meeting - Agenda
## פגישת גילוי וידע עם צוות האינטגרטור

**תאריך:** _____________  
**משתתפים:** Roy Avrahami (QA), ענבר (Interrogator TL), [שמות נוספים]  
**מטרה:** איסוף מידע לתכנון אוטומציה פונקציונלית

---

## 1. לוגיקה עסקית וליבת המוצר 🎯

| # | שאלה | תשובה / הערות |
|---|------|---------------|
| 1.1 | מהן, מבחינתכם, חתיכות ה**'לוגיקה העסקית' הקריטיות ביותר** ב־Interrogator? | |
| 1.2 | אילו **כללי זיהוי / תרחישי דיגום** נחשבים אצלכם "אסור לשבור בשום מצב" בשטח? | |
| 1.3 | איך אתם היום מגדירים ומוודאים **חומרת התראה** (Critical / Major / Minor) ו**סיווג אירוע** (סוגי אירועים)? | |
| 1.4 | האם קיימים אצלכם **כללים מתועדים לקורלציה ול־De-duplication** של אירועים (איך כמה דיטקשנים גולמיים הופכים לאירוע אחד)? | |
| 1.5 | האם יש **מדיניות שונה לכל ורטיקל** (Power / Flow / Security / אחרים) – למשל ספים שונים, פילטרים שונים, או לוגיקה אחרת? | |

---

## 2. בדיקות קיימות וכיסוי אוטומציה 🔬

| # | שאלה | תשובה / הערות |
|---|------|---------------|
| 2.1 | אילו **סוגי בדיקות אוטומטיות** קיימות היום ל־Interrogator (Unit / Integration / System / E2E)? | |
| 2.2 | אילו **חלקים במערכת כבר מכוסים** באוטומציה, ואילו חלקים עדיין נבדקים רק ידנית? | |
| 2.3 | האם קיים **מיפוי** כלשהו בין בדיקות הרגרסיה הידניות לבין הטסטים האוטומטיים? | |
| 2.4 | האם יש אזורים במערכת שאתם יודעים שהם **"Blind Spots"** – פונקציונליות שאף פעם לא נבדקת אלא אם צץ באג? | |
| 2.5 | עד כמה הטסטים האוטומטיים הקיימים נחשבים **אמינים**? אתם חווים הרבה **Flaky Tests** או אזעקות שווא? | |

---

## 3. בדיקות ידניות וידע שבעל־פה 📋

| # | שאלה | תשובה / הערות |
|---|------|---------------|
| 3.1 | אילו **זרימות קריטיות** נבדקות כיום רק ידנית לפני שחרור? | |
| 3.2 | האם יש תרחישים או רכיבים ש**רק אנשים ספציפיים** יודעים לבדוק אותם "כמו שצריך"? | |
| 3.3 | האם קיימים **Playbooks / Checklists** כתובים לבדיקה בשטח או לפני שחרור? | |
| 3.4 | אם **מהנדס חדש** היה מצטרף היום לצוות שלכם – איך הייתם מלמדים אותו לוודא ש־Interrogator עובד נכון מקצה לקצה? | |

---

## 4. תרחישי כשל והתאוששות (Resilience) 💥

| # | שאלה | תשובה / הערות |
|---|------|---------------|
| 4.1 | האם יש לכם כיום **טסטים אוטומטיים או תרחישים חוזרים** שמדמים כשלים אמיתיים בשטח (רשת, חשמל, אחסון)? | |
| 4.2 | אילו מתרחישי הכשל כבר נבדקים בצורה **מובנית**, ואילו נבדקים רק **אד־הוק** במעבדה (או לא נבדקים)? | |
| 4.3 | כשהמערכת **מתאוששת מכשל** (חזרת רשת, חזרת חשמל, שחרור מקום בדיסק) – מה ההתנהגות שאתם מצפים לה שנחשבת **"תקינה"**? | |
| 4.4 | האם קיימים אצלכם **RTO** (Recovery Time Objective) מוגדרים, או גבולות ברורים של **Data Loss מותר** לתרחישים האלה? | |

---

## 5. סביבות בדיקה ונתוני בדיקה 🖥️

| # | שאלה | תשובה / הערות |
|---|------|---------------|
| 5.1 | אילו **סביבות** כיום משמשות אתכם לבדיקת Interrogator (מעבדה, Staging, Pre-Production, מתקנים שדומים ללקוח)? | |
| 5.2 | מי ה**בעלים של הסביבות** האלה היום – תשתיות / פיתוח / צוות אחר? מי שולט בפרוביז'נינג וקונפיגורציה? | |
| 5.3 | האם יש לכם **סט נתוני בדיקה / הקלטות סיגנלים יציבים** שניתן לעשות בהם שימוש חוזר בבדיקות אוטומטיות פונקציונליות? | |
| 5.4 | באיזו **תדירות הסביבות משתנות** או מתעדכנות, וכמה שליטה תהיה לצוות ה־QA על הסביבות האלה? | |

---

## 6. ממשקים, APIs ויכולת בדיקה (Testability) 🔌

| # | שאלה | תשובה / הערות |
|---|------|---------------|
| 6.1 | אילו **APIs, Endpoints** (REST/gRPC/RPC) או כלים פנימיים אתם משתמשים בהם היום כדי לשלוט ב־Interrogator ולצפות במה שהוא עושה? | |
| 6.2 | האם קיימים **סקריפטים פנימיים** שמדמים סיגנלים, אירועים או תנאי רשת בעייתיים? | |
| 6.3 | האם קיימים **לוגים / Telemetry / מטריקות** שמאותתים בצורה ברורה מתי מתרחשים אירועים חשובים (זיהוי, יצירת התראה, כשל ב־Pipeline וכו') שאפשר להישען עליהם באוטומציה? | |

---

## סיכום ופעולות המשך 📝

| נושא | פעולה נדרשת | אחראי | תאריך יעד |
|------|-------------|-------|-----------|
| | | | |
| | | | |
| | | | |

---

## הערות נוספות מהפגישה

```
[מקום לרשום הערות חופשיות במהלך הפגישה]




```

---

**נוצר על ידי:** Roy Avrahami  
**תאריך יצירה:** December 2024

