# ×˜×¡×˜ 2: Performance â€“ Concurrent Task Limit
## PZ-13896 - × ×™×ª×•×— ××§×™×£ ×•××¢××™×§

---

## ğŸ“‹ ×ª×§×¦×™×¨ ××”×™×¨ ×œ×¤×’×™×©×” (Quick Brief)

| **×©×“×”** | **×¢×¨×š** |
|---------|---------|
| **Jira ID** | PZ-13896 |
| **×©× ×”×˜×¡×˜** | Performance â€“ Concurrent Task Limit |
| **×¢×“×™×¤×•×ª** | ğŸ”´ **HIGH** |
| **×¡×•×’** | Performance / Load Test / Stress Test |
| **×¡×˜×˜×•×¡ ××•×˜×•××¦×™×”** | âœ… **Automated** |
| **××©×š ×¨×™×¦×” ×¦×¤×•×™** | ~2-5 ×“×§×•×ª |
| **××•×¨×›×‘×•×ª ××™××•×©** | ğŸŸ  **×’×‘×•×”×”** |
| **×§×•×‘×¥ ×˜×¡×˜** | `tests/integration/performance/test_performance_high_priority.py` |
| **Test Class** | `TestConcurrentTaskLimit` |
| **×©×•×¨×•×ª** | 198-421 |
| **×ª×œ×•×™×•×ª** | Focus Server API, MongoDB, RabbitMQ, ThreadPoolExecutor |

---

## ğŸ¯ ××” ×”××˜×¨×” ×©×œ ×”×˜×¡×˜? (Test Objectives)

### ××˜×¨×” ××¡×˜×¨×˜×’×™×ª (Strategic Goal):
×œ×§×‘×•×¢ **×›××” ××©×™××•×ª (tasks) ×‘××§×‘×™×œ** ×”××¢×¨×›×ª ×™×›×•×œ×” ×œ×˜×¤×œ ×‘××•×¤×Ÿ ×××™×Ÿ **××‘×œ×™ ×œ×”×ª×“×¨×“×¨, ×œ×§×¨×•×¡ ××• ×œ×ª×ª ×©×’×™××•×ª**.

### ××˜×¨×•×ª ×¡×¤×¦×™×¤×™×•×ª (Specific Goals):
1. **×§×‘×™×¢×ª ×§×™×‘×•×œ×ª ××§×¡×™××œ×™×ª** (Capacity Planning)
   - ×›××” concurrent tasks ×”××¢×¨×›×ª ×ª×•××›×ª ×‘×”×¦×œ×—×” ×©×œ 90%+?
   - ×›××” concurrent tasks ×”××¢×¨×›×ª ×ª×•××›×ª ×‘×”×¦×œ×—×” ×©×œ 80%+?
   - ××” × ×§×•×“×ª ×”×©×‘×™×¨×” (breaking point)?

2. **×•×™×“×•× ×”×ª× ×”×’×•×ª graceful degradation**
   - ×›×©×—×•×¦×™× ××ª ×”×’×‘×•×œ â†’ ×”××¢×¨×›×ª ×œ× ×§×•×¨×¡×ª
   - ×©×’×™××•×ª ×‘×¨×•×¨×•×ª: "System at capacity"
   - ×œ× exhaustion ×©×œ ××©××‘×™×

3. **×–×™×”×•×™ bottlenecks**
   - ××” ×”××©××‘ ×”××’×‘×™×œ: CPU? Memory? MongoDB connections? RabbitMQ queues?

4. **×ª×™×¢×•×“ ×œ×ª×›× ×•×Ÿ ×§×™×‘×•×œ×ª**
   - ×›××” ××©×ª××©×™× ×™×›×•×œ×™× ×œ×¢×‘×•×“ ×‘××§×‘×™×œ?
   - ×”×× ×¦×¨×™×š scaling?

---

## ğŸ§ª ××” ×× ×™ ×¨×•×¦×” ×œ×‘×“×•×§? (What We're Testing)

### ×”×¡×¦× ×¨×™×• ×©×× ×—× ×• ×‘×•×“×§×™×:

**Scenario 1**: ××¡×¤×¨ ××©×ª××©×™× ×™×•×¦×¨×™× tasks **×‘×•-×–×× ×™×ª** (concurrently).

#### ××” ×–×” Concurrent Tasks?

**×“×•×’××” ×¤×©×•×˜×”**:
```
Time: 10:00:00 - User A creates Task 1
Time: 10:00:00 - User B creates Task 2 (same second!)
Time: 10:00:01 - User C creates Task 3
Time: 10:00:01 - User D creates Task 4
Time: 10:00:01 - User E creates Task 5 (all at the same second!)

Total: 5 concurrent tasks within 1-2 seconds
```

**×œ××” ×–×” ×§×•×¨×” ×‘×™×™×¦×•×¨?**
- 10 ×× ×©×™× ×¤×•×ª×—×™× ××ª ×”××¤×œ×™×§×¦×™×” **×‘×•-×–×× ×™×ª** (morning rush)
- Automated scripts ×©×¨×¦×™× ×‘×œ×•×œ××”
- Load balancer ×©××¤×–×¨ ×‘×§×©×•×ª ×××©×ª××©×™× ×¨×‘×™×

---

### ×ª×¨×—×™×©×™ ×”×‘×“×™×§×”:

×”×˜×¡×˜ ×‘×•×“×§ **5 ×¨××•×ª** ×©×œ concurrency:

| Level | Concurrent Tasks | Goal | Expected Success Rate |
|-------|-----------------|------|---------------------|
| **Level 1** | 10 tasks | Baseline capacity | â‰¥ 90% |
| **Level 2** | 20 tasks | Normal load | â‰¥ 90% |
| **Level 3** | 30 tasks | High load | â‰¥ 80% |
| **Level 4** | 40 tasks | Near breaking point | â‰¥ 70% (optional) |
| **Level 5** | 50 tasks | Stress test | Find breaking point |

**×× success rate < 80% â†’ ×¢×¦×¨× ×• (×œ××“× ×• ××ª ×”×’×‘×•×œ!)**

---

## ğŸ”¥ ××” ×”× ×—×™×¦×•×ª ×©×œ ×”×˜×¡×˜? (Why Is This Critical?)

### ×¡×™×›×•× ×™× ×× ×œ× ×‘×•×“×§×™×:

#### 1ï¸âƒ£ **×§×¨×™×¡×” ××¡×™×‘×™×ª ×‘×™×™×¦×•×¨** (Production Outage)
**×ª×¨×—×™×©**:  
50 ××©×ª××©×™× × ×›× ×¡×™× ×‘×•-×–×× ×™×ª (09:00 AM - start of workday).  
×”××¢×¨×›×ª ×œ× ××•×›× ×” ×œ-50 concurrent tasks â†’ **×§×¨×™×¡×” ××•×—×œ×˜×ª**!

**×”×©×¤×¢×”**:
- ×›×œ ×”××©×ª××©×™× ×¨×•××™× errors
- ×”××¢×¨×›×ª ×œ× ××’×™×‘×”
- Pods ×‘-Kubernetes ××ª×™× ×•-restarts
- ××•×‘×“×Ÿ ×××•×Ÿ ×©×œ ×”××©×ª××©×™×

---

#### 2ï¸âƒ£ **Resource Exhaustion** (×× exhaustion ×©×œ ××©××‘×™×)
**×ª×¨×—×™×©**:  
×›×œ task ×¤×•×ª×—:
- 1 MongoDB connection
- 1 RabbitMQ channel
- X MB memory
- Y% CPU

×× 100 tasks ×‘××§×‘×™×œ â†’ **MongoDB connection pool ××ª××œ×** â†’ ×‘×§×©×•×ª ×—×“×©×•×ª × ×›×©×œ×•×ª!

**×ª×•×¦××”**:
- "Too many connections" errors
- Database lockups
- Memory leaks
- System becomes unresponsive

---

#### 3ï¸âƒ£ **Uneven Load Distribution** (×—×œ×•×§×ª ×¢×•××¡ ×œ× ×©×•×•×”)
**×ª×¨×—×™×©**:  
×”××¢×¨×›×ª ××˜×¤×œ×ª ×‘-5 concurrent tasks ×‘×§×œ×•×ª, ××‘×œ ×‘-11 tasks â†’ failure.

**×œ××”?**  
×›×™ ×™×© **connection pool limit** ×©×œ 10 connections!

**×ª×•×¦××”**: ×œ× ×™×“×¢× ×• ×¢×œ ×”×’×‘×•×œ â†’ surprise ×‘×™×™×¦×•×¨!

---

#### 4ï¸âƒ£ **Cascading Failures** (×›×©×œ×™× ××ª×¤×©×˜×™×)
**×ª×¨×—×™×©**:  
20 concurrent tasks â†’ MongoDB ×¢××•×¡ â†’ slow queries â†’ RabbitMQ timeouts â†’ Redis cache misses â†’ **××¤×§×˜ ×“×•××™× ×•**!

**×ª×•×¦××”**: ×›×œ ×”××¢×¨×›×ª ×§×•×¨×¡×ª, ×œ× ×¨×§ ×”-API.

---

## ğŸ› ï¸ ××™×š ×× ×™ ×××© ××•×ª×• ×‘×§×•×“? (Code Implementation)

### ×§×•×‘×¥ ×”×˜×¡×˜:
**Path**: `tests/integration/performance/test_performance_high_priority.py`  
**Test Class**: `TestConcurrentTaskLimit`  
**Lines**: 198-421

---

### ××‘× ×” ×”××—×œ×§×”:

```python
@pytest.mark.integration
@pytest.mark.performance
@pytest.mark.critical
@pytest.mark.slow
class TestConcurrentTaskLimit:
    """
    Test suite for PZ-13896: Performance â€“ Concurrent Task Limit
    Priority: HIGH
    
    Validates system behavior under concurrent task load and determines
    maximum supported concurrent tasks.
    
    This class contains 3 test methods:
    1. test_concurrent_task_creation - Create tasks concurrently
    2. test_concurrent_task_polling - Poll tasks concurrently
    3. test_concurrent_task_max_limit - Find maximum capacity
    """
```

---

### ×˜×¡×˜ 1: `test_concurrent_task_creation`

**××˜×¨×”**: ×œ×™×¦×•×¨ 20 tasks ×‘××§×‘×™×œ ×•×œ×•×•×“× success rate â‰¥ 90%.

#### ×§×•×“ ××œ× ×¢× ×”×¡×‘×¨×™×:

```python
def test_concurrent_task_creation(self, focus_server_api, performance_config_payload):
    """
    Test PZ-13896.1: Create multiple concurrent tasks.
    
    Steps:
        1. Create 20 tasks concurrently using ThreadPoolExecutor
        2. Measure success rate
        3. Verify system stability
    
    Expected:
        - At least 90% success rate
        - System remains stable
        - No crashes or errors
    
    Jira: PZ-13896
    Priority: HIGH
    """
    logger.info("Test PZ-13896.1: Concurrent task creation")
    
    # =====================================================
    # Configuration
    # =====================================================
    num_concurrent = 20        # How many concurrent tasks to create
    max_workers = 10           # Thread pool size (parallel workers)
    
    logger.info(f"Creating {num_concurrent} tasks with {max_workers} workers...")
    
    # =====================================================
    # Define worker function
    # =====================================================
    def create_task(task_num: int) -> Dict[str, Any]:
        """
        Create a single task and return result.
        
        Args:
            task_num: Task number (for logging)
        
        Returns:
            Dictionary with:
            - job_id: Created job ID (or None if failed)
            - task_num: Task number
            - success: Boolean indicating success
            - latency_ms: Request latency in milliseconds
            - error: Error message (or None)
        
        Time Complexity: O(1) - single HTTP request
        Space Complexity: O(1) - constant memory
        """
        try:
            # Measure request start time
            start_time = time.perf_counter()
            
            # Create configuration request
            config_request = ConfigureRequest(**performance_config_payload)
            
            # Send POST /configure request to Focus Server
            response = focus_server_api.configure_streaming_job(config_request)
            
            # Measure request end time
            end_time = time.perf_counter()
            latency_ms = (end_time - start_time) * 1000
            
            # Check if request succeeded
            success = hasattr(response, 'job_id') and response.job_id is not None
            job_id = response.job_id if hasattr(response, 'job_id') else None
            
            return {
                'job_id': job_id,
                'task_num': task_num,
                'success': success,
                'latency_ms': latency_ms,
                'error': None
            }
            
        except Exception as e:
            # Request failed - log error
            logger.error(f"Task {task_num} failed: {e}")
            return {
                'job_id': None,
                'task_num': task_num,
                'success': False,
                'latency_ms': None,
                'error': str(e)
            }
    
    # =====================================================
    # Execute concurrent task creation
    # =====================================================
    results = []
    
    # ThreadPoolExecutor - runs tasks in parallel
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks to thread pool
        futures = [executor.submit(create_task, i) for i in range(num_concurrent)]
        
        # Wait for all tasks to complete (as_completed yields futures as they finish)
        for future in as_completed(futures):
            result = future.result()
            results.append(result)
            
            # Log each result
            if result['success']:
                logger.info(f"âœ… Task {result['task_num']}: {result['latency_ms']:.2f}ms")
            else:
                logger.warning(f"âŒ Task {result['task_num']}: Failed")
    
    # =====================================================
    # Analyze results
    # =====================================================
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    success_rate = len(successful) / num_concurrent
    
    logger.info("=" * 60)
    logger.info(f"Concurrent Task Creation Results:")
    logger.info(f"  Total tasks:      {num_concurrent}")
    logger.info(f"  Successful:       {len(successful)}")
    logger.info(f"  Failed:           {len(failed)}")
    logger.info(f"  Success rate:     {success_rate:.1%}")
    
    if successful:
        latencies = [r['latency_ms'] for r in successful]
        avg_latency = statistics.mean(latencies)
        max_latency = max(latencies)
        logger.info(f"  Avg latency:      {avg_latency:.2f}ms")
        logger.info(f"  Max latency:      {max_latency:.2f}ms")
    
    logger.info("=" * 60)
    
    # =====================================================
    # Assertions
    # =====================================================
    MIN_SUCCESS_RATE = 0.90  # 90% success rate required
    
    assert success_rate >= MIN_SUCCESS_RATE, \
        f"Success rate {success_rate:.1%} < threshold {MIN_SUCCESS_RATE:.1%}"
    
    logger.info(f"âœ… Concurrent task creation: {success_rate:.1%} success rate")
```

---

### ××” ×§×•×¨×” ×¤×”? (Step-by-Step Explanation)

#### **×©×œ×‘ 1: ×”×’×“×¨×ª Configuration**
```python
num_concurrent = 20
max_workers = 10
```
- **num_concurrent**: ×›××” tasks ×œ×™×¦×•×¨ (20)
- **max_workers**: ×›××” threads ×œ×¨×•×¥ ×‘××§×‘×™×œ (10)

**×œ××” 10 workers ×•-20 tasks?**
- 10 workers â†’ 10 requests ××§×‘×™×œ×™× ×××©
- 20 tasks â†’ ×›×œ worker ×™×¨×™×¥ 2 tasks
- ×–×” ××“××” **realistic concurrency** (×œ× extreme)

---

#### **×©×œ×‘ 2: ×¤×•× ×§×¦×™×” ×œ×™×¦×™×¨×ª Task ×‘×•×“×“**
```python
def create_task(task_num: int) -> Dict[str, Any]:
```

×”×¤×•× ×§×¦×™×” ×”×–×•:
1. ×©×•×œ×—×ª `POST /configure` ×œ-Focus Server
2. ××•×“×“×ª latency
3. ××—×–×™×¨×” success/failure

**×œ××” ×‘×¦×•×¨×” ×”×–×•?**
- ×›×œ thread ××¨×™×¥ ××ª ×”×¤×•× ×§×¦×™×” ×”×–×•
- ThreadPoolExecutor ×× ×”×œ ××ª ×”-parallelism
- ×× ×—× ×• ×¨×§ ××’×“×™×¨×™× ××” ×›×œ task ×¢×•×©×”

---

#### **×©×œ×‘ 3: ThreadPoolExecutor**
```python
with ThreadPoolExecutor(max_workers=max_workers) as executor:
    futures = [executor.submit(create_task, i) for i in range(num_concurrent)]
```

**××” ×–×” `ThreadPoolExecutor`?**
- Python module ×-`concurrent.futures`
- ××¨×™×¥ ×¤×•× ×§×¦×™×•×ª ×‘-**threads ××§×‘×™×œ×™×**
- ××¡×¤×¨ threads = `max_workers`

**××” ×–×” `futures`?**
- `future` = obje`ct ×©××™×™×¦×’ ×ª×•×¦××” ×¢×ª×™×“×™×ª
- ×›×©×”-thread ××¡×™×™× â†’ ×”-future ××ª××œ× ×‘×ª×•×¦××”

**×œ××” `executor.submit`?**
- `submit(function, args)` â†’ ××•×¡×™×£ task ×œ×ª×•×¨
- ThreadPoolExecutor ××¨×™×¥ ×›×œ task ×›×©×™×© worker ×¤× ×•×™

---

#### **×©×œ×‘ 4: ×”××ª× ×” ×œ×ª×•×¦××•×ª**
```python
for future in as_completed(futures):
    result = future.result()
    results.append(result)
```

**××” ×–×” `as_completed`?**
- Generator ×©××—×–×™×¨ futures **×›×©×”× ××¡×™×™××™×**
- ×œ× ××—×›×” ×œ×›×•×œ× â†’ ××—×–×™×¨ ×‘×¡×“×¨ ×©××¡×™×™××™×
- ×™×¢×™×œ ×™×•×ª×¨ ×××©×¨ ×œ×—×›×•×ª ×œ×¡×•×£

**×œ××” `future.result()`?**
- ××—×–×™×¨ ××ª ×”×¢×¨×š ×©×”×¤×•× ×§×¦×™×” ×”×—×–×™×¨×”
- ×× ×”×™×™×ª×” exception â†’ ×–×•×¨×§ ××•×ª×”

---

#### **×©×œ×‘ 5: × ×™×ª×•×— ×ª×•×¦××•×ª**
```python
successful = [r for r in results if r['success']]
failed = [r for r in results if not r['success']]
success_rate = len(successful) / num_concurrent
```

**××” ××—×©×‘×™×?**
- ×›××” tasks ×”×¦×œ×™×—×•
- ×›××” × ×›×©×œ×•
- ××” ×”-success rate (%)

**×œ××” success rate ×—×©×•×‘?**
- 100% â†’ ××•×©×œ×, ××‘×œ ×œ× realistic
- 90% â†’ ××¦×•×™×Ÿ
- 80% â†’ ××§×•×‘×œ
- < 70% â†’ ×‘×¢×™×”!

---

### ×˜×¡×˜ 2: `test_concurrent_task_polling`

**××˜×¨×”**: ×œ×™×¦×•×¨ 10 tasks ×•××– **×œ×‘×“×•×§ ××•×ª× ×‘××§×‘×™×œ** (polling).

#### ×œ××” ×–×” ×—×©×•×‘?
- ×™×¦×™×¨×ª task â‰  ×©××™×œ×ª×ª task
- ××•×œ×™ ×™×¦×™×¨×” ×¢×•×‘×“×ª, ××‘×œ polling × ×›×©×œ ×ª×—×ª ×¢×•××¡?

```python
def test_concurrent_task_polling(self, focus_server_api, performance_config_payload):
    """
    Test PZ-13896.2: Poll multiple tasks concurrently.
    
    Steps:
        1. Create 10 tasks
        2. Poll all tasks concurrently
        3. Verify all tasks can be polled
    
    Expected:
        - All tasks can be polled concurrently
        - No interference between tasks
    
    Jira: PZ-13896
    Priority: HIGH
    """
    logger.info("Test PZ-13896.2: Concurrent task polling")
    
    num_tasks = 10
    
    # =====================================================
    # Step 1: Create tasks first
    # =====================================================
    job_ids = []
    logger.info(f"Creating {num_tasks} tasks...")
    
    for i in range(num_tasks):
        config_request = ConfigureRequest(**performance_config_payload)
        response = focus_server_api.configure_streaming_job(config_request)
        
        if hasattr(response, 'job_id') and response.job_id:
            job_ids.append(response.job_id)
    
    # Verify we created enough tasks
    assert len(job_ids) >= num_tasks * 0.8, \
        f"Only {len(job_ids)}/{num_tasks} tasks created successfully"
    
    logger.info(f"{len(job_ids)} tasks created successfully")
    
    # =====================================================
    # Step 2: Test passes - tasks were created concurrently
    # =====================================================
    logger.info("=" * 60)
    logger.info(f"Concurrent Task Polling Test Results:")
    logger.info(f"  Tasks Created: {len(job_ids)}/{num_tasks}")
    logger.info("=" * 60)
    logger.info(f"âœ… Concurrent task polling completed")
```

**×”×¢×¨×”**: ×”×˜×¡×˜ ×”×–×” ×›×¨×’×¢ **×œ× polling** ×‘×¤×•×¢×œ (TODO: implement polling).  
×”×•× ×¨×§ ×™×•×¦×¨ tasks ×•××•×•×“× ×©×”×™×¦×™×¨×” ×”×¦×œ×™×—×”.

---

### ×˜×¡×˜ 3: `test_concurrent_task_max_limit` (×”×›×™ ×—×©×•×‘!)

**××˜×¨×”**: ×œ××¦×•× ××ª **× ×§×•×“×ª ×”×©×‘×™×¨×”** (breaking point).

```python
def test_concurrent_task_max_limit(self, focus_server_api, performance_config_payload):
    """
    Test PZ-13896.3: Find maximum concurrent task limit.
    
    Steps:
        1. Gradually increase concurrent task count (10, 20, 30, 40, 50)
        2. Find the point where tasks start failing
        3. Document maximum supported concurrent tasks
    
    Expected:
        - System supports at least [MIN] concurrent tasks
        - Graceful degradation when limit exceeded
    
    Jira: PZ-13896
    Priority: HIGH
    """
    logger.info("Test PZ-13896.3: Maximum concurrent task limit")
    
    # =====================================================
    # Test different concurrency levels
    # =====================================================
    test_counts = [10, 20, 30, 40, 50]
    results_by_count = {}
    
    for count in test_counts:
        logger.info(f"\n{'='*60}")
        logger.info(f"Testing {count} concurrent tasks...")
        logger.info(f"{'='*60}")
        
        # Define worker function
        def create_task(task_num: int) -> bool:
            try:
                config_request = ConfigureRequest(**performance_config_payload)
                response = focus_server_api.configure_streaming_job(config_request)
                return hasattr(response, 'job_id') and response.job_id is not None
            except:
                return False
        
        # Execute concurrent task creation
        with ThreadPoolExecutor(max_workers=min(count, 20)) as executor:
            futures = [executor.submit(create_task, i) for i in range(count)]
            outcomes = [f.result() for f in as_completed(futures)]
        
        # Calculate success rate
        success_count = sum(outcomes)
        success_rate = success_count / count
        
        results_by_count[count] = {
            'success_count': success_count,
            'success_rate': success_rate
        }
        
        logger.info(f"Result: {success_count}/{count} succeeded ({success_rate:.1%})")
        
        # =====================================================
        # Stop if success rate drops below 80%
        # =====================================================
        if success_rate < 0.80:
            logger.info(f"âš ï¸ Success rate dropped below 80% at {count} tasks")
            break
        
        # Small delay between test rounds
        time.sleep(2)
    
    # =====================================================
    # Report findings
    # =====================================================
    logger.info("\n" + "=" * 60)
    logger.info("Maximum Concurrent Task Limit - Summary:")
    logger.info("=" * 60)
    
    for count, result in results_by_count.items():
        logger.info(f"  {count:3d} tasks: {result['success_count']:3d} succeeded ({result['success_rate']:.1%})")
    
    logger.info("=" * 60)
    
    # =====================================================
    # Assertions
    # =====================================================
    MIN_CONCURRENT_TASKS = 10
    
    # Find highest count with >= 90% success rate
    max_with_90_percent = max(
        [count for count, result in results_by_count.items() if result['success_rate'] >= 0.90],
        default=0
    )
    
    assert max_with_90_percent >= MIN_CONCURRENT_TASKS, \
        f"System only supports {max_with_90_percent} concurrent tasks (minimum: {MIN_CONCURRENT_TASKS})"
    
    logger.info(f"âœ… System supports at least {max_with_90_percent} concurrent tasks with 90%+ success")
```

---

### ××” ×§×•×¨×” ×‘×˜×¡×˜ ×”×–×”? (Detailed Walkthrough)

#### **×©×œ×‘ 1: ××¢×¨×š ×¨××•×ª Concurrency**
```python
test_counts = [10, 20, 30, 40, 50]
```
- ××ª×—×™×œ×™× ×‘-10 (×§×œ)
- ××’×“×™×œ×™× ×œ-20, 30, 40, 50 (×”×“×¨×’×ª×™)
- ×›×œ ×¨××” ×‘×•×“×§×ª ×™×›×•×œ×ª ×’×‘×•×”×” ×™×•×ª×¨

---

#### **×©×œ×‘ 2: ×œ×•×œ××” ×¢×œ ×›×œ ×¨××”**
```python
for count in test_counts:
```
- ××¨×™×¦×™× ××ª ×”×˜×¡×˜ ×¢× `count` tasks ×‘××§×‘×™×œ
- ××•×“×“×™× success rate
- ×¢×•×¦×¨×™× ×× success rate < 80%

---

#### **×©×œ×‘ 3: Worker Function ×¤×©×•×˜×”**
```python
def create_task(task_num: int) -> bool:
    try:
        # ... create task ...
        return True
    except:
        return False
```
- ××—×–×™×¨×” ×¨×§ `True/False` (×œ× dict ××¤×•×¨×˜)
- ×™×•×ª×¨ ×¤×©×•×˜ ×•××”×™×¨ ×œ× ×™×ª×•×—

---

#### **×©×œ×‘ 4: ×¨×™×¦×” ×¢× ThreadPoolExecutor**
```python
with ThreadPoolExecutor(max_workers=min(count, 20)) as executor:
```
**×œ××” `min(count, 20)`?**
- ×× `count=10` â†’ 10 workers
- ×× `count=50` â†’ 20 workers (×œ× 50!)
- ×œ××”? ×›×“×™ ×œ× ×œ×™×¦×•×¨ **×™×•×ª×¨ ××“×™ threads** (overhead)

---

#### **×©×œ×‘ 5: ×¢×¦×™×¨×” ×× success rate × ××•×š**
```python
if success_rate < 0.80:
    logger.info(f"âš ï¸ Success rate dropped below 80% at {count} tasks")
    break
```
**×œ××” 80%?**
- 80% = threshold ×œ××¦×‘ "×œ× ××§×•×‘×œ"
- ×× ×”×’×¢× ×• ×œ-80% â†’ ××¦×× ×• ××ª × ×§×•×“×ª ×”×©×‘×™×¨×”!
- ××™×Ÿ ×˜×¢× ×œ×”××©×™×š (×›×‘×¨ ×™×“×•×¢ ×©×–×” ×œ× ×¢×•×‘×“ ×˜×•×‘)

---

#### **×©×œ×‘ 6: ×“×™×•×•×— ×××¦××™×**
```python
logger.info("Maximum Concurrent Task Limit - Summary:")
for count, result in results_by_count.items():
    logger.info(f"  {count:3d} tasks: {result['success_count']:3d} succeeded ({result['success_rate']:.1%})")
```

**×“×•×’××” ×œ×¤×œ×˜**:
```
Maximum Concurrent Task Limit - Summary:
=============================================================
  10 tasks:  10 succeeded (100.0%)
  20 tasks:  19 succeeded (95.0%)
  30 tasks:  27 succeeded (90.0%)
  40 tasks:  32 succeeded (80.0%)
  50 tasks:  35 succeeded (70.0%) âš ï¸ Stopped here
=============================================================
âœ… System supports at least 30 concurrent tasks with 90%+ success
```

---

## ğŸ“ ××” ×œ×•××“×™× ××”×˜×¡×˜ ×”×–×”?

### ×ª×•×¦××•×ª ×¦×¤×•×™×•×ª:
1. **10 concurrent tasks** â†’ 100% success âœ… (baseline)
2. **20 concurrent tasks** â†’ 95% success âœ… (good)
3. **30 concurrent tasks** â†’ 90% success âœ… (acceptable)
4. **40 concurrent tasks** â†’ 80% success âš ï¸ (marginal)
5. **50 concurrent tasks** â†’ 70% success ğŸš« (breaking point)

**×”××¡×§× ×”**: ×”××¢×¨×›×ª ×ª×•××›×ª ×‘-**30 concurrent tasks ×‘××•×¤×Ÿ ×××™×Ÿ**.

---

### ×œ××” tasks × ×›×©×œ×™×?

| Cause | Description | Solution |
|-------|-------------|----------|
| **MongoDB Connection Pool** | Max 10 connections â†’ 11th task fails | Increase pool size |
| **RabbitMQ Channels** | Max 20 channels â†’ 21st task fails | Increase channel limit |
| **CPU Saturation** | 100% CPU â†’ slow responses â†’ timeouts | Scale horizontally |
| **Memory Exhaustion** | OOM Killer â†’ pods die | Increase memory limits |
| **Network Bandwidth** | Saturated â†’ packet loss | Upgrade network |

---

## ğŸ—£ï¸ ×©××œ×•×ª ×œ×¤×’×™×©×” (Questions for the Meeting)

### ×©××œ×•×ª ××“×™× ×™×•×ª:
1. **×›××” ××©×ª××©×™× ×¦×¤×•×™×™× ×‘×™×™×¦×•×¨?**
   - 10? 50? 100? 1000?
   - ××” ×ª×¨×—×™×© ×”-peak usage?

2. **××” ×”-SLA ×œ×§×‘×œ×ª concurrent requests?**
   - 90% success rate? 95%? 99%?

3. **××” ×§×•×¨×” ×›×©×—×•×¨×’×™× ××”×’×‘×•×œ?**
   - Error message: "System at capacity"?
   - Queueing?
   - Throttling?

4. **×”×× ×™×© ×ª×›× ×•×Ÿ ×œ-scaling?**
   - Horizontal scaling (more pods)?
   - Vertical scaling (bigger pods)?

5. **××” timeout ×œ-tasks?**
   - 30 seconds? 60 seconds?
   - ××” ×§×•×¨×” ×œtasks ×©×ª×§×•×¢×™×?

---

### ×©××œ×•×ª ×˜×›× ×™×•×ª:
6. **××” ×’×•×“×œ connection pool ×©×œ MongoDB?**
   - Default: 10? 50? 100?
   - ××” ×§×•×¨×” ×›×©×”×•× ××ª××œ×?

7. **××” ×’×•×“×œ channel pool ×©×œ RabbitMQ?**
   - ×›××” channels ×¤×ª×•×—×™× ×‘××§×‘×™×œ?

8. **××” ×”-resource limits ×‘-Kubernetes?**
   - CPU: ××§×¡×™××•× ×›××” cores?
   - Memory: ××§×¡×™××•× ×›××” GB?

9. **×”×× ×™×© rate limiting ×‘-API?**
   - ×›××” requests ×œ-second?
   - ×›××” requests ×œ-minute?

10. **××™×š ××‘×¦×¢×™× load balancing?**
    - Round-robin?
    - Least connections?
    - IP hash?

---

## ğŸ“Š ×˜×‘×œ×ª ×¡×™×›×•× - Concurrent Task Scenarios

| Scenario | Concurrent Tasks | Expected Success Rate | System State |
|----------|-----------------|---------------------|--------------|
| **Low Load** | 10 | 100% | âœ… Normal |
| **Normal Load** | 20 | 95% | âœ… Good |
| **High Load** | 30 | 90% | âœ… Acceptable |
| **Near Capacity** | 40 | 80% | âš ï¸ Warning |
| **Over Capacity** | 50+ | < 80% | ğŸš« Degraded |

---

## âœ… Checklist ×œ×¤× ×™ ×”×¤×’×™×©×”

- [ ] ×§×¨××ª×™ ××ª ×”××¡××š ×”×–×” ×œ×¢×•××§
- [ ] ×”×‘× ×ª×™ ××” ×–×” concurrent tasks ×•××™×š ×–×” ×©×•× ×” ×-sequential
- [ ] ×”×‘× ×ª×™ ××™×š ThreadPoolExecutor ×¢×•×‘×“
- [ ] ×™×•×“×¢ ×œ×”×¡×‘×™×¨ ××ª ×”×”×‘×“×œ ×‘×™×Ÿ 3 ×”×˜×¡×˜×™×
- [ ] ×™×•×“×¢ ××” ×”-bottlenecks ×”×¦×¤×•×™×™×
- [ ] ×”×›× ×ª×™ ×©××œ×•×ª ×¡×¤×¦×™×¤×™×•×ª ×¢×œ connection pools
- [ ] ×¡×§×¨×ª×™ ××ª ×”×§×•×“ ×‘-`test_performance_high_priority.py`
- [ ] ×™×•×“×¢ ××” success rate × ×—×©×‘ ××§×•×‘×œ

---

## ğŸ“Œ × ×§×•×“×•×ª ××¤×ª×— ×œ×–×›×•×¨

1. **Concurrency â‰  Parallelism** (××‘×œ ×§×¨×•×‘!)
2. **ThreadPoolExecutor** ×× ×”×œ threads ×‘×¦×•×¨×” ×™×¢×™×œ×”
3. **Success rate 90% = ××¦×•×™×Ÿ, 80% = ××§×•×‘×œ, < 70% = ×‘×¢×™×”**
4. **Breaking point = × ×§×•×“×” ×©×‘×” success rate ×™×•×¨×“ ××ª×—×ª ×œ-80%**
5. **×”×˜×¡×˜ ×”×–×” ××’×œ×” bottlenecks ×œ×¤× ×™ ×©×”× ×§×•×¨×™× ×‘×™×™×¦×•×¨!**

---

**× ×›×ª×‘ ×¢×‘×•×¨**: Roy Avrahami  
**×ª××¨×™×š**: ××•×§×˜×•×‘×¨ 2025  
**Jira**: PZ-13896

---

