# ğŸ¯ ×ª×•×›× ×™×ª ×¤×¢×•×œ×” - ×¢×“×›×•×Ÿ Scope ×”×˜×¡×˜×™× ×œ××—×¨ ×¤×’×™×©×ª ×”×‘×”×¨×”

**×ª××¨×™×š:** 27 ××•×§×˜×•×‘×¨ 2025  
**Jira Reference:** PZ-13756  
**××˜×¨×”:** ×¢×“×›×•×Ÿ ×¡×•×•×™×˜×ª ×”×˜×¡×˜×™× ×‘×”×ª×× ×œ×”× ×—×™×•×ª ×”×¤×’×™×©×”  
**××—×¨×™×•×ª:** QA Automation Architect

---

## ğŸ“‹ ×ª×§×¦×™×¨ ×× ×”×œ×™× (Executive Summary)

×œ××—×¨ ×¤×’×™×©×ª ×”×‘×”×¨×”, ×–×•×”×• **×©×™× ×•×™×™× ×§×¨×™×˜×™×™×** ×‘-scope ×”×˜×¡×˜×™×:

### âœ… **IN SCOPE - ××” ×©× ×©××¨:**
1. **K8s/Orchestration** - Job lifecycle, resource allocation, port exposure, observability
2. **Focus Server API** - Pre-launch validations (port, data availability, time-range, config)
3. **System Behavior (infra)** - Clean startup, stability, predictable error handling, rollback/cleanup
4. **Concurrency** - ×ª××™×›×” ×‘-200 concurrent Jobs

### âŒ **OUT OF SCOPE - ××” ×©×™×•×¦×:**
1. **Internal Job processing ("Baby")** - ×‘×“×™×§×•×ª ×¤× ×™××™×•×ª ×©×œ ×¢×™×‘×•×“ ×”-Job
2. **Algorithm/data correctness** - ×ª×§×™× ×•×ª ××œ×’×•×¨×™×ª××™× ×•× ×ª×•× ×™×
3. **Spectrogram/content validation** - ××™××•×ª ×ª×•×›×Ÿ ×”×¡×¤×§×˜×¨×•×’×¨××”
4. **Full gRPC stream content checks** - ×‘×“×™×§×•×ª ××œ××•×ª ×©×œ ×ª×•×›×Ÿ stream

### ğŸ”„ **MODIFIED SCOPE - ××” ×©××©×ª× ×”:**
- **gRPC:** ×œ×©××•×¨ ×¨×§ **transport readiness** (port/handshake), ×‘×œ×™ ××™××•×ª stream content

### ğŸ“Œ **BACKLOG:**
- Restore/implement `GET /metadata/{job_id}` + create bug ticket

---

## ğŸ” × ×™×ª×•×— ××¦×‘ × ×•×›×—×™ - Current State Analysis

### ×¡×˜×˜×™×¡×˜×™×§×” ×›×œ×œ×™×ª:

```
ğŸ“Š ××¦×‘ ×§×™×™×:
â”œâ”€â”€ ğŸŸ¢ Integration Tests:  ~82 ×˜×¡×˜×™×
â”œâ”€â”€ ğŸŸ¡ Data Quality:        6 ×˜×¡×˜×™×
â”œâ”€â”€ ğŸŸ¤ Infrastructure:      27 ×˜×¡×˜×™×
â”œâ”€â”€ ğŸ”´ Load/Performance:    10+ ×˜×¡×˜×™×
â”œâ”€â”€ ğŸ”¬ Unit Tests:          73 ×˜×¡×˜×™×
â””â”€â”€ ğŸ¨ UI Tests:            2 ×˜×¡×˜×™×
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TOTAL:                     ~200 ×˜×¡×˜×™×
```

---

## ğŸ¯ ×ª×•×›× ×™×ª ×¤×¢×•×œ×” ××¤×•×¨×˜×ª - Detailed Action Plan

---

## ğŸ“ **PHASE 1: ×–×™×”×•×™ ×•×¡×™×•×•×’ ×˜×¡×˜×™× ×§×™×™××™×**

### 1.1 ×˜×¡×˜×™× ×©×¦×¨×™×›×™× **×œ××—×™×§×” ××œ××”** âŒ

#### A. `test_spectrogram_pipeline.py` - **××—×™×§×” ×—×œ×§×™×ª**

**Location:** `tests/integration/api/test_spectrogram_pipeline.py`  
**Status:** âš ï¸ **MIXED - ×—×œ×§ ×œ××—×•×§, ×—×œ×§ ×œ×©××•×¨**

**×˜×¡×˜×™× ×œ××—×™×§×”:**
```python
# âŒ OUT OF SCOPE - Spectrogram content validation
class TestSpectrogramContentValidation:
    def test_spectrogram_intensity_values()      # âŒ ×œ××—×•×§
    def test_spectrogram_frequency_bins()        # âŒ ×œ××—×•×§
    def test_spectrogram_time_resolution()       # âŒ ×œ××—×•×§
    def test_spectrogram_color_mapping()         # âŒ ×œ××—×•×§ (content)
```

**×˜×¡×˜×™× ×œ×©××•×¨:**
```python
# âœ… IN SCOPE - Configuration validation
class TestNFFTConfiguration:
    def test_valid_nfft_power_of_2()             # âœ… ×œ×©××•×¨ (config validation)
    def test_nfft_variations()                   # âœ… ×œ×©××•×¨ (config validation)

class TestConfigurationCompatibility:
    def test_high_throughput_configuration()     # âœ… ×œ×©××•×¨ (config validation)
    def test_low_throughput_configuration()      # âœ… ×œ×©××•×¨ (config validation)

class TestSpectrogramPipelineErrors:
    def test_zero_nfft()                         # âœ… ×œ×©××•×¨ (error handling)
    def test_negative_nfft()                     # âœ… ×œ×©××•×¨ (error handling)
```

**Action Items:**
- [ ] ×œ×¡×§×•×¨ ××ª ×”×§×•×‘×¥ ×©×•×¨×” ××—×¨ ×©×•×¨×”
- [ ] ×œ××—×•×§ ×˜×¡×˜×™× ×©×‘×•×“×§×™× spectrogram content
- [ ] ×œ×©××•×¨ ×˜×¡×˜×™× ×©×‘×•×“×§×™× configuration validation
- [ ] ×œ×¢×“×›×Ÿ ×©× ×§×•×‘×¥ ×œ-`test_config_validation_nfft.py`

---

#### B. `test_dynamic_roi_adjustment.py` - **×‘×“×™×§×” × ×“×¨×©×ª**

**Location:** `tests/integration/api/test_dynamic_roi_adjustment.py`  
**Status:** âš ï¸ **REVIEW REQUIRED**

**×©××œ×•×ª ×œ×‘×“×™×§×”:**
1. ×”×× ×”×˜×¡×˜ ×‘×•×“×§ **Baby processing** ×¤× ×™××™?
2. ×”×× ×”×˜×¡×˜ ×‘×•×“×§ **algorithm correctness**?
3. ××• ×©×”×•× ×‘×•×“×§ ×¨×§ **API behavior** ×•-**RabbitMQ commands**?

**×”×—×œ×˜×”:**
- ×× ×‘×•×“×§ ×¨×§ **API + RabbitMQ** â†’ âœ… ×œ×©××•×¨
- ×× ×‘×•×“×§ **Baby processing** â†’ âŒ ×œ××—×•×§

**Action Items:**
- [ ] ×œ×§×¨×•× ××ª ×”×§×•×‘×¥
- [ ] ×œ×–×”×•×ª ××” ×‘×“×™×•×§ × ×‘×“×§
- [ ] ×œ×”×—×œ×™×˜: ×©××•×¨/××—×§/×¢×“×›×Ÿ

---

#### C. ×˜×¡×˜×™× ×¢× `baby` ×‘-code - **××—×™×§×”/×¢×“×›×•×Ÿ**

**×§×‘×¦×™× ×©× ××¦××•:**
```
âœ— tests/conftest.py                              # fixtures - ×œ×‘×“×•×§
âœ— tests/integration/api/test_dynamic_roi_adjustment.py  # ×œ×‘×“×•×§
âœ— tests/integration/api/test_spectrogram_pipeline.py    # ×¢×“×›×•×Ÿ ×—×œ×§×™
âœ— tests/unit/test_models_validation.py          # unit test - OK
âœ— tests/unit/test_validators.py                 # unit test - OK
âœ— tests/data_quality/test_mongodb_data_quality.py   # data quality - OK
```

**Action Items:**
- [ ] ×œ×¡×§×•×¨ ×›×œ ×§×•×‘×¥ ×¢× `baby`
- [ ] ×œ×•×•×“× ×©×œ× × ×©××¨×• ×‘×“×™×§×•×ª ×©×œ Baby processing
- [ ] ×œ×¢×“×›×Ÿ fixtures ×× ×¦×¨×™×š

---

### 1.2 ×˜×¡×˜×™× ×©×¦×¨×™×›×™× **×¢×“×›×•×Ÿ** ğŸ”„

#### A. gRPC Transport Tests - **×¢×“×›×•×Ÿ Scope**

**×“×¨×™×©×”:** ×œ×©××•×¨ ×¨×§ **transport readiness** (port/handshake), **×‘×œ×™** stream content validation

**×˜×¡×˜×™× ×§×™×™××™× ×œ×‘×“×™×§×”:**
```bash
# ×—×¤×© ×˜×¡×˜×™× ×¢× gRPC
grep -r "grpc\|gRPC" tests/ --include="*.py"
```

**Action Items:**
- [ ] ×œ××¦×•× ×›×œ ×˜×¡×˜×™ gRPC
- [ ] ×œ×•×•×“× ×©×”× ×‘×•×“×§×™× ×¨×§:
  - âœ… Port availability
  - âœ… Connection handshake
  - âœ… Transport readiness
- [ ] **×œ××—×•×§** ×›×œ ×‘×“×™×§×•×ª ×©×œ:
  - âŒ Stream content validation
  - âŒ Data correctness in stream
  - âŒ Message parsing

---

### 1.3 ×˜×¡×˜×™× ×©×¦×¨×™×›×™× **×ª×•×¡×¤×ª** â•

#### A. Concurrent Jobs - **200 Jobs Capacity**

**Status:** âœ… **×§×™×™× ×—×œ×§×™×ª** ×‘-`tests/load/test_job_capacity_limits.py`

**××” ×§×™×™×:**
```python
BASELINE_JOBS = 1
LIGHT_LOAD_JOBS = 5
MEDIUM_LOAD_JOBS = 10
HEAVY_LOAD_JOBS = 20
EXTREME_LOAD_JOBS = 50
STRESS_LOAD_JOBS = 100    # âš ï¸ ×¢×“ 100 ×‘×œ×‘×“
```

**××” ×—×¡×¨:**
```python
TARGET_CAPACITY_JOBS = 200  # âŒ ×—×¡×¨!
```

**Action Items:**
- [ ] ×œ×”×•×¡×™×£ ×˜×¡×˜ ×—×“×©: `test_200_concurrent_jobs_capacity()`
- [ ] ×œ×‘×“×•×§:
  - âœ… 200 jobs × ×•×¦×¨×™× ×‘×”×¦×œ×—×”
  - âœ… Actual capacity × ××“×“×ª
  - âœ… Readiness timings × ×¨×©××™×
- [ ] ×× ×¡×‘×™×‘×” ×œ× ××¦×œ×™×—×” â†’ **Infra Gap Report**
  - Actual capacity achieved
  - Readiness timings
  - Infrastructure recommendations

**×“×•×’××” ×œ×˜×¡×˜ ×—×“×©:**
```python
@pytest.mark.load
@pytest.mark.capacity
@pytest.mark.critical
def test_200_concurrent_jobs_target_capacity(focus_server_api, config_manager):
    """
    Test: 200 Concurrent Jobs - Target Capacity
    
    Validates that the environment can support 200 concurrent jobs.
    If environment cannot meet target, generates Infra Gap Report.
    
    Success Criteria:
    - DEV/Staging: Must support 200 jobs
    - Other envs: Report actual capacity + gap analysis
    
    Related: Meeting decision - Support 200 concurrent Jobs
    """
    TARGET_CAPACITY = 200
    env = config_manager.environment
    
    logger.info(f"ğŸ¯ Testing 200 concurrent jobs on {env} environment...")
    
    # Create 200 jobs
    results = create_concurrent_jobs(
        api=focus_server_api,
        num_jobs=TARGET_CAPACITY,
        config_payload=standard_config_payload(),
        max_workers=50
    )
    
    # Analyze results
    success_count = len([r for r in results if r['success']])
    success_rate = success_count / TARGET_CAPACITY
    
    # Generate report
    if success_rate < 1.0:
        generate_infra_gap_report(
            environment=env,
            target_capacity=TARGET_CAPACITY,
            actual_capacity=success_count,
            readiness_timings=results.readiness_times,
            recommendations=[
                "Scale K8s cluster resources",
                "Optimize Focus Server deployment",
                "Review resource limits"
            ]
        )
    
    # Assertion based on environment
    if env in ["dev", "staging"]:
        assert success_rate >= 0.95, (
            f"Target environment {env} MUST support 200 jobs. "
            f"Achieved: {success_count}/200 ({success_rate*100:.1f}%)"
        )
    else:
        logger.warning(
            f"Environment {env} achieved {success_count}/200 jobs. "
            f"See Infra Gap Report for details."
        )
```

---

#### B. Focus Server Pre-Launch Validations - **×˜×¡×˜×™× ×—×“×©×™×**

**×“×¨×™×©×”:** ×œ×‘×“×•×§ **Pre-launch validations** ×©×œ Focus Server API:
- Port availability
- Data availability (Live/Historic)
- Time-range checks
- Config validation (channels, frequency, NFFT, view type)

**×˜×¡×˜×™× ×—×¡×¨×™×:**

##### 1. Port Availability Validation
```python
# File: tests/integration/api/test_prelaunch_validations.py

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_port_availability_before_job_creation():
    """
    Test: Port Availability Pre-Launch Validation
    
    Validates that Focus Server checks port availability
    BEFORE creating a job.
    
    Expected Behavior:
    - If port in use â†’ Reject with clear error
    - If port free â†’ Proceed with job creation
    
    Related: Meeting decision - Pre-launch validations
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 2. Data Availability Validation (Live/Historic)
```python
@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_data_availability_live_mode():
    """
    Test: Data Availability Validation - Live Mode
    
    Validates that Focus Server checks if live data
    is available before accepting job.
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_data_availability_historic_mode():
    """
    Test: Data Availability Validation - Historic Mode
    
    Validates that Focus Server checks if historic data
    exists in requested time range.
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 3. Time-Range Validation
```python
@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_time_range_validation_future_timestamps():
    """
    Test: Time-Range Validation - Future Timestamps
    
    Validates rejection of future timestamps in historic mode.
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_time_range_validation_reversed_range():
    """
    Test: Time-Range Validation - Reversed Range
    
    Validates rejection of start_time > end_time.
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 4. Config Validation (channels, frequency, NFFT, view type)
```python
@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_config_validation_channels_out_of_range():
    """
    Test: Config Validation - Channels Out of Range
    
    Validates rejection of channel ranges exceeding system limits.
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_config_validation_frequency_exceeds_nyquist():
    """
    Test: Config Validation - Frequency Exceeds Nyquist
    
    Validates rejection of frequency > Nyquist limit.
    """
    pass  # ×§×™×™× ×‘-test_config_validation_high_priority.py - ×œ×•×•×“×

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_config_validation_invalid_nfft():
    """
    Test: Config Validation - Invalid NFFT
    
    Validates rejection of invalid NFFT values.
    """
    pass  # ×§×™×™× ×‘-test_spectrogram_pipeline.py - ×œ×•×•×“×

@pytest.mark.integration
@pytest.mark.api
@pytest.mark.prelaunch
def test_config_validation_invalid_view_type():
    """
    Test: Config Validation - Invalid View Type
    
    Validates rejection of unsupported view types.
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

**Action Items:**
- [ ] ×œ×™×¦×•×¨ ×§×•×‘×¥ ×—×“×©: `tests/integration/api/test_prelaunch_validations.py`
- [ ] ×œ×××© ××ª ×›×œ ×”×˜×¡×˜×™× ×œ××¢×œ×”
- [ ] ×œ×•×•×“× ×©××™×Ÿ ×“×•×¤×œ×™×§×˜×™× ×¢× ×˜×¡×˜×™× ×§×™×™××™×
- [ ] ×œ×§×©×¨ ×œ-Jira tickets

---

#### C. K8s Job Lifecycle - **×˜×¡×˜×™× ×—×“×©×™×**

**×“×¨×™×©×”:** ×œ×‘×“×•×§ **K8s orchestration** ×©×œ Jobs:
- Job creation
- Job execution (run)
- Job cancellation
- Resource allocation
- Port exposure
- Observability

**×˜×¡×˜×™× ×§×™×™××™×:**
- `tests/infrastructure/test_external_connectivity.py` - ×™×© K8s connectivity
- `tests/load/test_job_capacity_limits.py` - ×™×© job creation

**×˜×¡×˜×™× ×—×¡×¨×™×:**

##### 1. Job Lifecycle Complete Flow
```python
# File: tests/infrastructure/test_k8s_job_lifecycle.py

@pytest.mark.infrastructure
@pytest.mark.kubernetes
@pytest.mark.job_lifecycle
def test_k8s_job_creation_and_pod_spawn():
    """
    Test: K8s Job Creation â†’ Pod Spawn
    
    Validates that creating a Focus Server job
    triggers K8s pod creation with correct labels.
    
    Steps:
    1. Create job via API
    2. Query K8s for corresponding pod
    3. Validate pod labels and annotations
    4. Validate pod status (Running)
    
    Related: Meeting decision - K8s Job lifecycle
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 2. Job Resource Allocation
```python
@pytest.mark.infrastructure
@pytest.mark.kubernetes
@pytest.mark.resources
def test_k8s_job_resource_allocation():
    """
    Test: K8s Job Resource Allocation
    
    Validates that jobs receive allocated resources:
    - CPU requests/limits
    - Memory requests/limits
    - Storage volumes
    
    Related: Meeting decision - Resource allocation
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 3. Job Port Exposure
```python
@pytest.mark.infrastructure
@pytest.mark.kubernetes
@pytest.mark.networking
def test_k8s_job_port_exposure():
    """
    Test: K8s Job Port Exposure
    
    Validates that job ports are properly exposed:
    - gRPC port accessible
    - Port mapping correct
    - Service discovery works
    
    Related: Meeting decision - Port exposure
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 4. Job Cancellation and Cleanup
```python
@pytest.mark.infrastructure
@pytest.mark.kubernetes
@pytest.mark.cleanup
def test_k8s_job_cancellation_and_cleanup():
    """
    Test: K8s Job Cancellation â†’ Pod Cleanup
    
    Validates clean cancellation:
    1. Cancel job via API
    2. Verify pod termination
    3. Verify resource cleanup
    4. Verify no orphaned resources
    
    Related: Meeting decision - Cleanup and rollback
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 5. Job Observability
```python
@pytest.mark.infrastructure
@pytest.mark.kubernetes
@pytest.mark.observability
def test_k8s_job_observability():
    """
    Test: K8s Job Observability
    
    Validates that job state is observable:
    - Pod logs accessible
    - Pod events tracked
    - Metrics exposed
    - Status updates propagated
    
    Related: Meeting decision - Observability
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

**Action Items:**
- [ ] ×œ×™×¦×•×¨ ×§×•×‘×¥ ×—×“×©: `tests/infrastructure/test_k8s_job_lifecycle.py`
- [ ] ×œ×××© ××ª ×›×œ ×”×˜×¡×˜×™× ×œ××¢×œ×”
- [ ] ×œ×”×©×ª××© ×‘-`KubernetesManager` fixture ×§×™×™×
- [ ] ×œ×§×©×¨ ×œ-Jira tickets

---

#### D. System Behavior (Infra) - **×˜×¡×˜×™× ×—×“×©×™×**

**×“×¨×™×©×”:** ×œ×‘×“×•×§ **System Behavior**:
- Clean startup
- Stability over time
- Predictable error handling (no data, port in use)
- Proper rollback/cleanup

**×˜×¡×˜×™× ×§×™×™××™×:**
- `tests/performance/test_mongodb_outage_resilience.py` - ×™×© error handling
- `tests/infrastructure/test_basic_connectivity.py` - ×™×© connectivity

**×˜×¡×˜×™× ×—×¡×¨×™×:**

##### 1. Clean Startup
```python
# File: tests/infrastructure/test_system_behavior.py

@pytest.mark.infrastructure
@pytest.mark.startup
@pytest.mark.critical
def test_focus_server_clean_startup():
    """
    Test: Focus Server Clean Startup
    
    Validates clean startup sequence:
    1. All dependencies available (MongoDB, K8s)
    2. Configuration loaded correctly
    3. Services initialized in order
    4. Health check passes
    5. Ready to accept requests
    
    Related: Meeting decision - Clean startup
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 2. Stability Over Time
```python
@pytest.mark.infrastructure
@pytest.mark.stability
@pytest.mark.slow
def test_focus_server_stability_over_time():
    """
    Test: Focus Server Stability Over Time
    
    Validates system stability over 1 hour:
    - Create jobs every 5 minutes
    - Monitor memory usage (no leaks)
    - Monitor CPU usage (stable)
    - Monitor error rates (low)
    - Verify no crashes or restarts
    
    Duration: 1 hour
    
    Related: Meeting decision - Stability over time
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 3. Predictable Error Handling - No Data
```python
@pytest.mark.infrastructure
@pytest.mark.error_handling
def test_predictable_error_no_data_available():
    """
    Test: Predictable Error Handling - No Data
    
    Validates clear error when no data available:
    - Historic mode: No recordings in time range
    - Expected: HTTP 404 with clear message
    - No crash, no 500 errors
    
    Related: Meeting decision - Predictable error handling
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 4. Predictable Error Handling - Port in Use
```python
@pytest.mark.infrastructure
@pytest.mark.error_handling
def test_predictable_error_port_in_use():
    """
    Test: Predictable Error Handling - Port in Use
    
    Validates clear error when port unavailable:
    - Create job on port X
    - Try to create another job on same port
    - Expected: HTTP 409 Conflict with clear message
    - No crash, no 500 errors
    
    Related: Meeting decision - Predictable error handling
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

##### 5. Proper Rollback on Failure
```python
@pytest.mark.infrastructure
@pytest.mark.rollback
def test_proper_rollback_on_job_creation_failure():
    """
    Test: Proper Rollback on Failure
    
    Validates rollback when job creation fails:
    1. Trigger failure during job creation
    2. Verify no partial resources left
    3. Verify K8s pod cleaned up
    4. Verify system state unchanged
    
    Related: Meeting decision - Proper rollback/cleanup
    """
    pass  # ×œ×”×•×¡×™×£ ××™××•×©
```

**Action Items:**
- [ ] ×œ×™×¦×•×¨ ×§×•×‘×¥ ×—×“×©: `tests/infrastructure/test_system_behavior.py`
- [ ] ×œ×××© ××ª ×›×œ ×”×˜×¡×˜×™× ×œ××¢×œ×”
- [ ] ×œ×§×©×¨ ×œ-Jira tickets

---

### 1.4 ×˜×¡×˜×™× ×©**× ×©××¨×™× ×œ×œ× ×©×™× ×•×™** âœ…

×”×˜×¡×˜×™× ×”×‘××™× **×ª×•×××™× ×œ-scope ×”×—×“×©** ×•× ×©××¨×™× ×›××•×ª ×©×”×:

#### âœ… Infrastructure Tests
- `tests/infrastructure/test_basic_connectivity.py` - âœ… ×œ×©××•×¨
- `tests/infrastructure/test_external_connectivity.py` - âœ… ×œ×©××•×¨
- `tests/infrastructure/test_pz_integration.py` - âœ… ×œ×©××•×¨

#### âœ… Data Quality Tests
- `tests/data_quality/test_mongodb_data_quality.py` - âœ… ×œ×©××•×¨
  - Collections validation
  - Schema validation
  - Metadata completeness
  - Indexes validation
  - Historical vs Live classification

#### âœ… Integration Tests (×—×œ×§)
- `tests/integration/api/test_config_validation_high_priority.py` - âœ… ×œ×©××•×¨
  - Config validation (IN SCOPE)
  - API pre-launch checks (IN SCOPE)

#### âœ… Load Tests
- `tests/load/test_job_capacity_limits.py` - âœ… ×œ×©××•×¨ (×¢× ×ª×•×¡×¤×•×ª)
  - Capacity testing framework ×§×™×™×
  - ×¦×¨×™×š ×œ×”×•×¡×™×£ ×˜×¡×˜ ×œ-200 concurrent jobs

#### âœ… Unit Tests
- `tests/unit/test_validators.py` - âœ… ×œ×©××•×¨
- `tests/unit/test_models_validation.py` - âœ… ×œ×©××•×¨
- `tests/unit/test_config_loading.py` - âœ… ×œ×©××•×¨
- `tests/unit/test_basic_functionality.py` - âœ… ×œ×©××•×¨

---

## ğŸ“ **PHASE 2: ××™××•×© ×”×©×™× ×•×™×™× - Implementation**

### 2.1 ××—×™×§×ª ×˜×¡×˜×™× (Deletion)

**Action Items:**
- [ ] **Step 1:** ×’×™×‘×•×™ (Backup)
  ```bash
  # Create backup branch
  git checkout -b backup/pre-scope-refinement-$(date +%Y%m%d)
  git push origin backup/pre-scope-refinement-$(date +%Y%m%d)
  
  # Return to main branch
  git checkout develop
  git pull origin develop
  
  # Create feature branch
  git checkout -b feature/scope-refinement-meeting-updates
  ```

- [ ] **Step 2:** ××—×™×§×ª ×˜×¡×˜×™× OUT OF SCOPE
  ```bash
  # Review and delete spectrogram content validation tests
  # (Manual review required - partial deletion)
  code tests/integration/api/test_spectrogram_pipeline.py
  
  # After manual cleanup, commit
  git add tests/integration/api/test_spectrogram_pipeline.py
  git commit -m "refactor(tests): Remove spectrogram content validation tests - OUT OF SCOPE"
  ```

- [ ] **Step 3:** ××—×™×§×ª/×¢×“×›×•×Ÿ ×˜×¡×˜×™× ×¢× Baby processing
  ```bash
  # Review each file with 'baby' references
  grep -r "baby\|Baby" tests/ --include="*.py" -l
  
  # Manual review and cleanup needed
  # Commit each file separately with clear message
  ```

- [ ] **Step 4:** ×¢×“×›×•×Ÿ gRPC ×˜×¡×˜×™× (transport only)
  ```bash
  # Find gRPC tests
  grep -r "grpc\|gRPC" tests/ --include="*.py" -l
  
  # Update to test only transport readiness
  # Remove stream content validation
  ```

---

### 2.2 ×ª×•×¡×¤×ª ×˜×¡×˜×™× ×—×“×©×™× (Addition)

**Priority Order:**

#### Priority 1 (Critical) ğŸ”´
- [ ] **200 Concurrent Jobs Test**
  - File: `tests/load/test_job_capacity_limits.py`
  - Add: `test_200_concurrent_jobs_target_capacity()`
  - Add: `generate_infra_gap_report()` function
  - Estimated time: 4 hours

- [ ] **K8s Job Lifecycle Tests**
  - File: `tests/infrastructure/test_k8s_job_lifecycle.py` (NEW)
  - Add: All 5 tests (creation, resources, ports, cancellation, observability)
  - Estimated time: 8 hours

#### Priority 2 (High) ğŸŸ 
- [ ] **Pre-Launch Validations Tests**
  - File: `tests/integration/api/test_prelaunch_validations.py` (NEW)
  - Add: All 10 tests (port, data, time-range, config validations)
  - Estimated time: 6 hours

- [ ] **System Behavior Tests**
  - File: `tests/infrastructure/test_system_behavior.py` (NEW)
  - Add: All 5 tests (startup, stability, error handling, rollback)
  - Estimated time: 8 hours

#### Priority 3 (Medium) ğŸŸ¡
- [ ] **GET /metadata/{job_id} Implementation** (Backlog item)
  - Create Jira bug ticket
  - Document expected behavior
  - Create placeholder test (skip until implemented)
  - Estimated time: 2 hours (just documentation + ticket)

---

### 2.3 ×¢×“×›×•×Ÿ ×ª×™×¢×•×“ (Documentation)

**Action Items:**
- [ ] ×¢×“×›×Ÿ `tests/README.md` ×¢× scope ×”×—×“×©
- [ ] ×¢×“×›×Ÿ `tests/TESTS_LOCATION_GUIDE_HE.md`
- [ ] ×¢×“×›×Ÿ `tests/TEST_REORGANIZATION_SUMMARY.md`
- [ ] ×¦×•×¨ ××¡××š ×—×“×©: `documentation/meetings/SCOPE_REFINEMENT_SUMMARY.md`
- [ ] ×¢×“×›×Ÿ ×›×œ ×”-README.md ×‘×ª×™×§×™×•×ª ×”×˜×¡×˜×™×

**Template ×œ×¢×“×›×•×Ÿ README:**
```markdown
# Test Category Name

**Last Updated:** 27 October 2025  
**Scope Refined:** Following meeting decision (PZ-13756)

## âœ… IN SCOPE (After Meeting)
- K8s Job lifecycle
- Focus Server pre-launch validations
- System behavior (startup, stability, error handling)
- 200 concurrent jobs capacity

## âŒ OUT OF SCOPE (Removed)
- Internal Job processing ("Baby")
- Algorithm/data correctness
- Spectrogram content validation
- Full gRPC stream content checks

## ğŸ”„ MODIFIED SCOPE
- gRPC: Transport readiness only (port/handshake)
```

---

## ğŸ“ **PHASE 3: ×‘×“×™×§×” ×•××™××•×ª - Testing & Validation**

### 3.1 ×”×¨×¦×ª ×›×œ ×”×˜×¡×˜×™×

**Action Items:**
- [ ] ×”×¨×¥ Unit Tests
  ```bash
  pytest tests/unit/ -v --tb=short
  ```

- [ ] ×”×¨×¥ Infrastructure Tests
  ```bash
  pytest tests/infrastructure/ -v --tb=short
  ```

- [ ] ×”×¨×¥ Integration Tests
  ```bash
  pytest tests/integration/ -v --tb=short
  ```

- [ ] ×”×¨×¥ Data Quality Tests
  ```bash
  pytest tests/data_quality/ -v --tb=short
  ```

- [ ] ×”×¨×¥ Load Tests
  ```bash
  pytest tests/load/ -v --tb=short -m "not slow"
  ```

- [ ] ×”×¨×¥ ×˜×¡×˜×™× ×—×“×©×™× ×‘× ×¤×¨×“
  ```bash
  # K8s Job Lifecycle
  pytest tests/infrastructure/test_k8s_job_lifecycle.py -v -s
  
  # Pre-Launch Validations
  pytest tests/integration/api/test_prelaunch_validations.py -v -s
  
  # System Behavior
  pytest tests/infrastructure/test_system_behavior.py -v -s
  
  # 200 Concurrent Jobs
  pytest tests/load/test_job_capacity_limits.py::test_200_concurrent_jobs -v -s
  ```

---

### 3.2 Code Review

**Action Items:**
- [ ] Self-review:
  - ×§×¨× ××ª ×›×œ ×”×©×™× ×•×™×™×
  - ×‘×“×•×§ ×©××™×Ÿ ×“×•×¤×œ×™×§×˜×™×
  - ×‘×“×•×§ ×©×”×¡×¨×ª ×›×œ OUT OF SCOPE

- [ ] Peer review:
  - ×‘×§×© review ×-team member
  - ×ª×¢×“ feedback
  - ×¢×“×›×Ÿ ×œ×¤×™ ×”×¢×¨×•×ª

- [ ] Linting & Formatting:
  ```bash
  # Run black
  black tests/ --check
  
  # Run flake8
  flake8 tests/ --max-line-length=120
  
  # Run mypy
  mypy tests/ --ignore-missing-imports
  ```

---

## ğŸ“ **PHASE 4: ××™× ×˜×’×¨×¦×™×” ×•-CI/CD**

### 4.1 ×¢×“×›×•×Ÿ CI/CD Pipeline

**Action Items:**
- [ ] ×¢×“×›×Ÿ `.github/workflows/tests.yml` (×× ×§×™×™×)
- [ ] ×”×•×¡×£ job ×™×™×¢×•×“×™ ×œ-200 concurrent jobs test
- [ ] ×”×•×¡×£ job ×™×™×¢×•×“×™ ×œ-K8s lifecycle tests
- [ ] ×¢×“×›×Ÿ thresholds ×œ×¤×™ scope ×”×—×“×©

**×“×•×’××”:**
```yaml
# .github/workflows/tests.yml

jobs:
  infrastructure-tests:
    name: Infrastructure Tests (IN SCOPE)
    runs-on: ubuntu-latest
    steps:
      - name: Run Infrastructure Tests
        run: |
          pytest tests/infrastructure/ -v \
            -m "not slow" \
            --junitxml=reports/infrastructure.xml

  capacity-tests:
    name: 200 Concurrent Jobs Capacity
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Run Capacity Test
        run: |
          pytest tests/load/test_job_capacity_limits.py::test_200_concurrent_jobs \
            -v -s \
            --junitxml=reports/capacity.xml
      
      - name: Upload Infra Gap Report
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: infra-gap-report
          path: reports/infra_gap_*.json
```

---

### 4.2 Xray Integration

**Action Items:**
- [ ] ××¤×” ×˜×¡×˜×™× ×—×“×©×™× ×œ-Jira tickets
- [ ] ×¦×•×¨ Test Executions ×‘-Xray
- [ ] ×§×©×¨ ×˜×¡×˜×™× ×œ-Test Plans
- [ ] ×¢×“×›×Ÿ Test Coverage reports

---

## ğŸ“ **PHASE 5: Backlog Items**

### 5.1 GET /metadata/{job_id} Restoration

**Action Items:**
- [ ] **Step 1:** Create Jira Bug Ticket
  ```
  Title: Restore GET /metadata/{job_id} endpoint
  
  Description:
  The GET /metadata/{job_id} endpoint is not currently available
  in Focus Server API.
  
  This endpoint is needed for:
  - Querying job status after creation
  - Retrieving job metadata dynamically
  - Monitoring job progress
  
  Expected Behavior:
  GET /metadata/{job_id} should return:
  - job_id
  - status (running/completed/failed)
  - stream_port
  - stream_url
  - view_type
  - metadata (PRR, dx, etc.)
  
  Priority: Medium
  Component: Focus Server API
  ```

- [ ] **Step 2:** Document Current Workaround
  ```markdown
  ## Current Workaround
  
  Since GET /metadata/{job_id} is not available, we:
  1. Store job metadata from POST /configure response
  2. Use stored metadata for subsequent operations
  3. Cannot query dynamic status updates
  
  ## Limitations
  - No way to check if job is still running
  - No way to retrieve metadata if configure response lost
  - Cannot monitor job progress dynamically
  ```

- [ ] **Step 3:** Create Placeholder Test
  ```python
  @pytest.mark.skip(reason="Endpoint not implemented yet - Jira: PZ-XXXXX")
  @pytest.mark.backlog
  def test_get_job_metadata_endpoint():
      """
      Test: GET /metadata/{job_id}
      
      Status: â³ PENDING IMPLEMENTATION
      Jira: PZ-XXXXX
      
      This test will be enabled once the endpoint is restored.
      """
      pass
  ```

---

## ğŸ“Š ×¡×™×›×•× ×•××¢×§×‘ - Summary & Tracking

### ×¡×˜×˜×™×¡×˜×™×§×ª ×˜×¡×˜×™× - ×œ×¤× ×™ ×•××—×¨×™

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category                    â”‚ Before   â”‚ After    â”‚ Change  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¢ Integration              â”‚ ~82      â”‚ ~65      â”‚ -17     â”‚
â”‚ ğŸŸ¡ Data Quality             â”‚ 6        â”‚ 6        â”‚ 0       â”‚
â”‚ ğŸŸ¤ Infrastructure           â”‚ 27       â”‚ 42       â”‚ +15     â”‚
â”‚ ğŸ”´ Load/Performance         â”‚ 10       â”‚ 11       â”‚ +1      â”‚
â”‚ ğŸ”¬ Unit                     â”‚ 73       â”‚ 73       â”‚ 0       â”‚
â”‚ ğŸ¨ UI                       â”‚ 2        â”‚ 2        â”‚ 0       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL                       â”‚ ~200     â”‚ ~199     â”‚ -1      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Changes Breakdown:
- Removed: ~20 tests (spectrogram content, baby processing)
- Added: ~19 tests (K8s lifecycle, pre-launch, system behavior, capacity)
- Net change: -1 test

Quality Improvement: âœ…
- Removed out-of-scope tests
- Added critical infrastructure tests
- Better alignment with actual system requirements
```

---

### Timeline & Effort Estimation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase                       â”‚ Effort       â”‚ Duration    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 1: Analysis           â”‚ 4 hours      â”‚ 0.5 days    â”‚
â”‚ Phase 2: Implementation     â”‚ 28 hours     â”‚ 3.5 days    â”‚
â”‚ Phase 3: Testing            â”‚ 8 hours      â”‚ 1 day       â”‚
â”‚ Phase 4: CI/CD Integration  â”‚ 4 hours      â”‚ 0.5 days    â”‚
â”‚ Phase 5: Backlog Items      â”‚ 2 hours      â”‚ 0.25 days   â”‚
â”‚ Documentation               â”‚ 4 hours      â”‚ 0.5 days    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL                       â”‚ 50 hours     â”‚ 6.25 days   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With contingency (20%): ~7.5 days
Target completion: November 5, 2025
```

---

### Checklist - Master Tracking

#### âœ… Phase 1: Analysis
- [ ] ×§×¨× ××ª ×›×œ ×”×˜×¡×˜×™× ×”×§×™×™××™×
- [ ] ×–×™×”×” ×˜×¡×˜×™× OUT OF SCOPE
- [ ] ×–×™×”×” ×˜×¡×˜×™× IN SCOPE
- [ ] ×–×™×”×” gaps (×˜×¡×˜×™× ×—×¡×¨×™×)
- [ ] ×¦×•×¨ ×¨×©×™××ª Action Items

#### âœ… Phase 2: Implementation
- [ ] ××—×§ ×˜×¡×˜×™× OUT OF SCOPE
- [ ] ×¢×“×›×Ÿ ×˜×¡×˜×™× MODIFIED SCOPE (gRPC)
- [ ] ×”×•×¡×£ ×˜×¡×˜ 200 concurrent jobs
- [ ] ×”×•×¡×£ K8s job lifecycle tests (5 tests)
- [ ] ×”×•×¡×£ Pre-launch validations tests (10 tests)
- [ ] ×”×•×¡×£ System behavior tests (5 tests)

#### âœ… Phase 3: Testing
- [ ] ×”×¨×¥ ×›×œ ×”×˜×¡×˜×™× ×”×—×“×©×™×
- [ ] ×”×¨×¥ regression ×¢×œ ×›×œ ×”×˜×¡×˜×™×
- [ ] ×‘×¦×¢ code review
- [ ] ×ª×§×Ÿ linting errors

#### âœ… Phase 4: CI/CD
- [ ] ×¢×“×›×Ÿ CI/CD pipeline
- [ ] ××™× ×˜×’×¨×¦×™×” ×¢× Xray
- [ ] ×¢×“×›×Ÿ Test Plans

#### âœ… Phase 5: Backlog
- [ ] ×¦×•×¨ Jira ticket ×œ-GET /metadata/{job_id}
- [ ] ×¦×•×¨ placeholder test

#### âœ… Documentation
- [ ] ×¢×“×›×Ÿ ×›×œ ×”-README files
- [ ] ×¦×•×¨ summary document
- [ ] ×¢×“×›×Ÿ Confluence (×× ×¨×œ×•×•× ×˜×™)

---

## ğŸ“ Lessons Learned & Best Practices

### ××” ×œ××“× ×• ××”×¤×’×™×©×”?

1. **Scope Creep Prevention**
   - ×—×©×•×‘ ×œ×”×’×“×™×¨ ×‘×‘×™×¨×•×¨ ××” IN SCOPE ×•××” OUT OF SCOPE
   - ×˜×¡×˜×™× ×¦×¨×™×›×™× ×œ×”×ª××§×“ ×‘-infrastructure/API behavior
   - ××™×Ÿ ×œ×‘×“×•×§ algorithm correctness ×‘-automation tests

2. **Testing Strategy**
   - Infrastructure tests > Content validation tests
   - Pre-launch validations ×§×¨×™×˜×™×™× ×œ×× ×™×¢×ª ×›×©×œ×™×
   - Capacity testing (200 jobs) must have gap analysis

3. **Communication**
   - ×ª×™×¢×•×“ ×‘×¨×•×¨ ×©×œ decisions ××¤×’×™×©×•×ª
   - Clear action items with owners
   - Regular updates to stakeholders

---

## ğŸ“ × ×§×•×“×•×ª ×§×©×¨ - Contacts

**Questions & Clarifications:**
- **Scope Questions:** [Product Owner Name]
- **Technical Questions:** [Tech Lead Name]
- **Jira/Xray:** [QA Manager Name]

---

**Created By:** QA Automation Architect  
**Date:** 27 October 2025  
**Version:** 1.0  
**Status:** âœ… READY FOR EXECUTION

---

**×”×¡××›×•×ª ×œ×‘×™×¦×•×¢:** ××¡××š ×–×” ××”×•×•×” ×ª×•×›× ×™×ª ×¢×‘×•×“×” ×¨×©××™×ª ×œ×¢×“×›×•×Ÿ ×¡×•×•×™×˜×ª ×”×˜×¡×˜×™× ×‘×”×ª×× ×œ×”×—×œ×˜×•×ª ×”×¤×’×™×©×”.

