# ×˜×¡×˜ 5: Performance â€“ /configure latency p95
## PZ-13571 - × ×™×ª×•×— ××§×™×£ ×•××¢××™×§

---

## ğŸ“‹ ×ª×§×¦×™×¨ ××”×™×¨ ×œ×¤×’×™×©×” (Quick Brief)

| **×©×“×”** | **×¢×¨×š** |
|---------|---------|
| **Jira ID** | PZ-13571 |
| **×©× ×”×˜×¡×˜** | Performance â€“ /configure latency p95 < 2.0s |
| **×¢×“×™×¤×•×ª** | ğŸŸ¡ **Medium (Low in original Jira)** |
| **×¡×•×’** | Performance Test (Smoke Test) |
| **×¡×˜×˜×•×¡ ××•×˜×•××¦×™×”** | âœ… **Automated** |
| **××©×š ×¨×™×¦×” ×¦×¤×•×™** | ~5-10 ×©× ×™×•×ª |
| **××•×¨×›×‘×•×ª ××™××•×©** | ğŸŸ¢ **× ××•×›×”** |
| **×§×•×‘×¥ ×˜×¡×˜** | (×œ× ×¦×•×™×Ÿ ×‘×“×•×§, ×›× ×¨××” ×—×œ×§ ×-`test_performance_high_priority.py`) |
| **Test Function** | `test_configure_latency` |
| **×ª×œ×•×™×•×ª** | Focus Server API |

---

## ğŸ¯ ××” ×”××˜×¨×” ×©×œ ×”×˜×¡×˜? (Test Objectives)

### ××˜×¨×” ××¡×˜×¨×˜×’×™×ª (Strategic Goal):
×œ×•×•×“× ×©-**control plane endpoint** (`POST /configure`) ×¢×•×‘×“ **××”×¨ ××¡×¤×™×§** ×ª×—×ª ×¢×•××¡ ××™× ×™××œ×™. ×–×”×• **smoke test** ×‘×¡×™×¡×™ ×œ×‘×™×¦×•×¢×™×.

### ××˜×¨×•×ª ×¡×¤×¦×™×¤×™×•×ª (Specific Goals):
1. **Baseline latency measurement** - ××” ×”-latency ×ª×—×ª ×ª× ××™× ××™×“×™××œ×™×™×?
2. **Sanity check** - ×”×× ×”-endpoint ××’×™×‘ ×‘×–××Ÿ ×¡×‘×™×¨?
3. **Regression detection** - ×”×× ×”×™×” regression ×‘×‘×™×¦×•×¢×™×?
4. **SLA verification (soft)** - P95 < 2.0 seconds

---

## ğŸ§ª ××” ×× ×™ ×¨×•×¦×” ×œ×‘×“×•×§? (What We're Testing)

### ×”×¡×¦× ×¨×™×• ×©×× ×—× ×• ×‘×•×“×§×™×:

**Scenario**: ×©×œ×™×—×ª **5 ×‘×§×©×•×ª sequential** ×œ-`POST /configure` ×¢× **live payload** (no time range).

#### ×œ××” ×¨×§ 5 ×‘×§×©×•×ª?
- ×–×”×• **smoke test** - ×‘×“×™×§×” ×§×œ×” ×•××”×™×¨×”
- ×œ× **load test** - ×œ× ×‘×•×“×§×™× ×ª×—×ª ×¢×•××¡
- **Baseline measurement** - ××” ×”-latency "× ×§×™" ×‘×œ×™ ×¢×•××¡?

#### ×œ××” live payload?
- **Live configuration** = no time range, no history lookup
- ×¤×©×•×˜ ×™×•×ª×¨ ×-historical
- ×œ× ×“×•×¨×© MongoDB queries ××•×¨×›×‘×™×
- **Fastest path** - ×××•×¨ ×œ×”×™×•×ª ×”××”×™×¨ ×‘×™×•×ª×¨

---

## ğŸ” ×”×”×‘×“×œ ×‘×™×Ÿ ×”×˜×¡×˜ ×”×–×” ×œ-PZ-13770

### PZ-13770 (`/config Latency P95/P99`):
- **100 requests** (comprehensive)
- **Sequential** (×œ× concurrent)
- **Detailed metrics**: P50, P95, P99, Min, Max, Avg
- **Thresholds**: P95 < 300ms, P99 < 500ms
- **Goal**: Full performance characterization

### PZ-13571 (`/configure Latency P95`):
- **5 requests** (smoke test)
- **Sequential** (×œ× concurrent)
- **Simple metric**: P95 only
- **Threshold**: P95 < 2.0s (much more lenient!)
- **Goal**: Quick sanity check

**××¡×§× ×”**: PZ-13571 ×”×•× **smoke test ×¤×©×•×˜**, PZ-13770 ×”×•× **performance test ××§×™×£**.

---

## ğŸ”¥ ××” ×”× ×—×™×¦×•×ª ×©×œ ×”×˜×¡×˜? (Why Is This Test Important?)

### ×œ××” ×¦×¨×™×š smoke test × ×¤×¨×“?

#### 1ï¸âƒ£ **Quick Feedback Loop**
**×ª×¨×—×™×©**:  
××—×¨×™ ×›×œ deploy, ×¨×•×¦×™× **feedback ××”×™×¨** - ×”×× ×”××¢×¨×›×ª ×¢×•×‘×“×ª?  
Smoke test ×¨×¥ ×ª×•×š **10 ×©× ×™×•×ª** â†’ ×ª×©×•×‘×” ××™×™×“×™×ª!

**×”×©×•×•××”**:
- **Smoke test** (5 requests): 10 seconds
- **Full test** (100 requests): 90 seconds
- **Load test** (1000 requests): 15 minutes

**××¡×§× ×”**: Smoke test × ×•×ª×Ÿ feedback **9Ã— ××”×¨ ×™×•×ª×¨**!

---

#### 2ï¸âƒ£ **Pre-deployment Validation**
**×ª×¨×—×™×©**:  
×œ×¤× ×™ deploy ×œ-production, ×¨×•×¦×™× **sanity check** ××”×™×¨:
- ×”×× ×”-endpoint ×‘×›×œ×œ ×¢×•× ×”?
- ×”×× ×”×•× ×œ× **catastrophically slow**?

**×ª×•×¦××”**:
- ×× smoke test × ×›×©×œ â†’ **don't deploy!**
- ×× smoke test ×¢×•×‘×¨ â†’ proceed to full tests

---

#### 3ï¸âƒ£ **Regression Detection (Coarse-grained)**
**×ª×¨×—×™×©**:  
××—×¨×™ ×©×™× ×•×™ ×§×•×“, Latency ×§×¤×¥ ×-**200ms** ×œ-**5 seconds** (regression ×’×“×•×œ!).

**Smoke test ×™×–×”×” ××ª ×–×” ××™×“**:
- P95 = 5s >> 2s threshold â†’ **FAIL!**
- ××•× ×¢ deploy ×©×œ ×§×•×“ ×‘×¢×™×™×ª×™

---

### ××ª×™ ×”×˜×¡×˜ ×”×–×” **×œ×** ××¡×¤×™×§?

| Scenario | Smoke Test Detects? | Full Test Needed? |
|----------|-------------------|------------------|
| **Catastrophic regression** (200ms â†’ 5s) | âœ… Yes | No (already caught) |
| **Moderate regression** (200ms â†’ 400ms) | âŒ No (still < 2s) | âœ… Yes (PZ-13770) |
| **Subtle regression** (200ms â†’ 220ms) | âŒ No | âœ… Yes (trend analysis) |
| **Performance under load** | âŒ No (only 5 requests) | âœ… Yes (load tests) |
| **Outliers detection** | âŒ No (too few samples) | âœ… Yes (100+ samples) |

**××¡×§× ×”**: Smoke test ×ª×•×¤×¡ ×¨×§ **×‘×¢×™×•×ª ×’×“×•×œ×•×ª**, ×œ× **×‘×¢×™×•×ª subtle**.

---

## ğŸ› ï¸ ××™×š ×× ×™ ×××© ××•×ª×• ×‘×§×•×“? (Code Implementation)

### ×§×•×“ ××œ× ×¢× ×”×¡×‘×¨×™×:

```python
@pytest.mark.integration
@pytest.mark.performance
@pytest.mark.smoke
def test_configure_latency(focus_server_api, performance_config_payload):
    """
    Test PZ-13571: /configure latency p95 < 2.0s under minimal load.
    
    This is a smoke test for the /configure endpoint.
    It sends 5 sequential requests and measures p95 latency.
    
    Steps:
        1. Send 5 POST /configure requests
        2. Measure latency for each
        3. Calculate p95
        4. Verify p95 < 2.0s
    
    Expected:
        - p95 latency < 2.0 seconds
        - All requests succeed
        - No significant variance between runs
    
    Jira: PZ-13571
    Priority: Medium (Low in Jira, but useful as smoke test)
    """
    logger.info("Test PZ-13571: POST /configure latency p95 smoke test")
    
    # =====================================================
    # Configuration
    # =====================================================
    num_requests = 5           # Small number for smoke test
    latencies = []             # Store latencies
    
    logger.info(f"Sending {num_requests} POST /configure requests...")
    
    # =====================================================
    # Execute requests and measure latency
    # =====================================================
    for i in range(num_requests):
        try:
            # Measure request latency
            start_time = time.perf_counter()
            
            # Create live configure request (no time range)
            config_request = ConfigureRequest(**performance_config_payload)
            
            # Send POST /configure
            response = focus_server_api.configure_streaming_job(config_request)
            
            end_time = time.perf_counter()
            
            # Calculate latency in seconds (not milliseconds!)
            latency_seconds = end_time - start_time
            latencies.append(latency_seconds)
            
            logger.info(f"  Request {i+1}: {latency_seconds:.3f}s")
            
            # Verify response is valid
            assert response is not None, f"Request {i}: Response is None"
            assert hasattr(response, 'status') or hasattr(response, 'job_id'), \
                f"Request {i}: Invalid response structure"
            
        except Exception as e:
            logger.error(f"Request {i}: Error - {e}")
            raise
    
    # =====================================================
    # Calculate p95
    # =====================================================
    # Sort latencies
    latencies.sort()
    
    # Calculate p95 (for 5 requests, p95 is the 5th value - the max!)
    # int(5 * 0.95) = int(4.75) = 4 â†’ index 4 (0-indexed) = 5th value
    p95_index = int(len(latencies) * 0.95)
    p95 = latencies[p95_index]
    
    # Also calculate average for reference
    avg = sum(latencies) / len(latencies)
    
    # =====================================================
    # Log results
    # =====================================================
    logger.info("=" * 60)
    logger.info(f"POST /configure Smoke Test Results ({num_requests} requests):")
    logger.info(f"  Latencies: {[f'{lat:.3f}s' for lat in latencies]}")
    logger.info(f"  Average:   {avg:.3f}s")
    logger.info(f"  p95:       {p95:.3f}s â­")
    logger.info("=" * 60)
    
    # =====================================================
    # Assertions
    # =====================================================
    THRESHOLD_P95_SECONDS = 2.0  # 2 seconds (very lenient)
    
    assert p95 < THRESHOLD_P95_SECONDS, \
        f"p95 latency {p95:.3f}s exceeds threshold {THRESHOLD_P95_SECONDS}s"
    
    logger.info(f"âœ… p95 latency {p95:.3f}s < {THRESHOLD_P95_SECONDS}s")
    
    # Additional check: warn if any request took > 1 second
    slow_requests = [lat for lat in latencies if lat > 1.0]
    if slow_requests:
        logger.warning(
            f"âš ï¸ {len(slow_requests)} request(s) took > 1 second: "
            f"{[f'{lat:.3f}s' for lat in slow_requests]}"
        )
```

---

## ğŸ“ ××” ×œ×•××“×™× ××”×˜×¡×˜ ×”×–×”?

### ×ª×•×¦××•×ª ×˜×™×¤×•×¡×™×•×ª (Expected Results):

```
Test PZ-13571: POST /configure latency p95 smoke test
Sending 5 POST /configure requests...
  Request 1: 0.154s
  Request 2: 0.162s
  Request 3: 0.148s
  Request 4: 0.159s
  Request 5: 0.151s
=============================================================
POST /configure Smoke Test Results (5 requests):
  Latencies: ['0.148s', '0.151s', '0.154s', '0.159s', '0.162s']
  Average:   0.155s
  p95:       0.162s â­
=============================================================
âœ… p95 latency 0.162s < 2.0s
```

**×¤×¨×©× ×•×ª**: ×”××¢×¨×›×ª ×¢×•×‘×“×ª ××¦×•×™×Ÿ! **160ms average** = excellent!

---

### ×ª×•×¦××•×ª ×‘×¢×™×™×ª×™×•×ª:

```
Test PZ-13571: POST /configure latency p95 smoke test
Sending 5 POST /configure requests...
  Request 1: 1.854s
  Request 2: 2.103s
  Request 3: 1.947s
  Request 4: 2.254s  â† Exceeded 2s!
  Request 5: 2.120s  â† Exceeded 2s!
=============================================================
POST /configure Smoke Test Results (5 requests):
  Latencies: ['1.854s', '1.947s', '2.103s', '2.120s', '2.254s']
  Average:   2.056s
  p95:       2.254s â­
=============================================================
âŒ FAILURE: p95 latency 2.254s exceeds threshold 2.0s
âš ï¸ 2 request(s) took > 1 second: ['2.254s', '2.120s']
```

**×¤×¨×©× ×•×ª**: ×‘×¢×™×”! ×”××¢×¨×›×ª **××™×˜×™×ª ××“×™** ××¤×™×œ×• ×ª×—×ª ×¢×•××¡ ××™× ×™××œ×™.  
**Action Required**: ×—×§×•×¨ ××” ×’×•×¨× ×œ-latency ×’×‘×•×”.

---

## ğŸ—£ï¸ ×©××œ×•×ª ×œ×¤×’×™×©×” (Questions for the Meeting)

### ×©××œ×•×ª ××“×™× ×™×•×ª:
1. **×”×× threshold ×©×œ 2 seconds ×¡×‘×™×¨?**
   - ×–×” **10Ã— ×™×•×ª×¨ lenient** ×-PZ-13770 (300ms)!
   - ×œ××” ×”×‘×“×œ ×›×–×”?
   - ×”×× ×¦×¨×™×š ×œ×”×•×¨×™×“ ×œ-1 second?

2. **××ª×™ ×”×˜×¡×˜ ×”×–×” ×¨×¥?**
   - Pre-deployment?
   - Post-deployment?
   - Nightly?
   - ×‘×›×œ commit?

3. **××” ×§×•×¨×” ×›×©×”×•× × ×›×©×œ?**
   - Block deployment?
   - Alert only?
   - Manual investigation?

---

### ×©××œ×•×ª ×˜×›× ×™×•×ª:
4. **×œ××” ×¨×§ 5 requests ×•×œ× 10 ××• 20?**
   - ×”×× 5 ××¡×¤×™×§ ×œstatistical significance?

5. **×œ××” live payload ×•×œ× historical?**
   - ×”×× historical ×××•×¨ ×œ×”×™×•×ª ×™×•×ª×¨ ××™×˜×™?
   - ×¦×¨×™×š smoke test × ×¤×¨×“ ×œ-historical?

6. **×”×× ×™×© memory load tests?**
   - ×”×¢×¨×” ×‘-Jira: "need to add memory load tests"
   - ××ª×™ ×–×” ×™×§×¨×”?

---

## ğŸ“Š ×˜×‘×œ×ª ×”×©×•×•××” - Smoke vs. Full Test

| Aspect | PZ-13571 (Smoke) | PZ-13770 (Full) |
|--------|-----------------|----------------|
| **Requests** | 5 | 100 |
| **Duration** | 10s | 90s |
| **Threshold** | 2.0s | 300ms |
| **Metrics** | p95 only | P50, P95, P99, Min, Max |
| **Purpose** | Quick sanity | Comprehensive |
| **When to Run** | Every commit | Daily / Pre-release |
| **Failure Impact** | Block deploy | Investigate |

---

## âœ… Checklist ×œ×¤× ×™ ×”×¤×’×™×©×”

- [ ] ×§×¨××ª×™ ××ª ×”××¡××š ×”×–×”
- [ ] ×”×‘× ×ª×™ ××ª ×”×”×‘×“×œ ×‘×™×Ÿ smoke test ×œ-full test
- [ ] ×™×•×“×¢ ×œ××” smoke test ×—×©×•×‘ ×œ××¨×•×ª ×©×”×•× ×¤×©×•×˜
- [ ] ×”×‘× ×ª×™ ×œ××” threshold ×©×œ 2s ×›×œ ×›×š lenient
- [ ] ×”×›× ×ª×™ ×©××œ×•×ª ×¢×œ ×”-memory load tests (missing)
- [ ] ×™×•×“×¢ ××ª×™ ×”×˜×¡×˜ ×”×–×” ×¦×¨×™×š ×œ×¨×•×¥

---

## ğŸ“Œ × ×§×•×“×•×ª ××¤×ª×— ×œ×–×›×•×¨

1. **Smoke test â‰  Load test** - ××˜×¨×•×ª ×©×•× ×•×ª!
2. **5 requests = ××¡×¤×™×§ ×œsmoke, ×œ× ××¡×¤×™×§ ×œfull analysis**
3. **2 seconds threshold = very lenient** (10Ã— ×-PZ-13770)
4. **Smoke test ×ª×•×¤×¡ catastrophic regressions, ×œ× subtle ones**
5. **Fast feedback > comprehensive feedback** (×‘×”×§×©×¨ ×©×œ smoke tests)

---

## ğŸ¯ ×”××œ×¦×” ××™×©×™×ª ×œ×¤×’×™×©×”

×”×¦×¢ ×œ×”×•×¡×™×£:
1. **Memory load tests** (×›××ª×•×¢×“ ×‘-comment ×‘-Jira)
2. **Smoke test ×œ-historical config** (×œ× ×¨×§ live)
3. **Smoke test ×œ-/waterfall endpoint**
4. **Monitoring dashboard** ×œtracking latency trends

---

**× ×›×ª×‘ ×¢×‘×•×¨**: Roy Avrahami  
**×ª××¨×™×š**: ××•×§×˜×•×‘×¨ 2025  
**Jira**: PZ-13571

---

