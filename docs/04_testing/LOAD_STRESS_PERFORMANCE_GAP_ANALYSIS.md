# ğŸ” Load, Stress & Performance Testing - × ×™×ª×•×— ×¤×¢×¨×™× ××§×™×£

**×ª××¨×™×š:** 23 ×‘× ×•×‘××‘×¨ 2025  
**××˜×¨×”:** ×–×™×”×•×™ ×¤×¢×¨×™× ×‘××¢×¨×š ×”×‘×“×™×§×•×ª ×”×§×™×™× ×•×”××œ×¦×•×ª ×œ×”×©×œ××”

---

## âœ… ××” ×©×›×‘×¨ ××›×•×¡×” ×”×™×•× - 23 ×˜×¡×˜×™× ×§×™×™××™×

### **1. Alert Generation - Load & Performance (11 ×˜×¡×˜×™×)**

| Test ID | ×©× ×”×˜×¡×˜ | ×¡×•×’ | ××›×•×¡×”? |
|---------|---------|-----|---------|
| **PZ-14953** | High Volume Load | Load | âœ… **××›×•×¡×”** |
| **PZ-14954** | Sustained Load | Load | âœ… **××›×•×¡×”** |
| **PZ-14955** | Burst Load | Load | âœ… **××›×•×¡×”** |
| **PZ-14956** | Mixed Alert Types | Load | âœ… **××›×•×¡×”** |
| **PZ-14957** | RabbitMQ Queue Capacity | Load | âœ… **××›×•×¡×”** |
| **PZ-14958** | Response Time | Performance | âœ… **××›×•×¡×”** |
| **PZ-14959** | Throughput | Performance | âœ… **××›×•×¡×”** |
| **PZ-14960** | Latency | Performance | âœ… **××›×•×¡×”** |
| **PZ-14961** | Resource Usage | Performance | âœ… **××›×•×¡×”** |
| **PZ-14962** | End-to-End Performance | Performance | âœ… **××›×•×¡×”** |
| **PZ-14963** | RabbitMQ Performance | Performance | âœ… **××›×•×¡×”** |

**×ª×™×§×•× ×™× ××—×¨×•× ×™×:**
- âœ… Smart backoff for 429 errors
- âœ… Retry logic with exponential backoff
- âœ… Rate limiting between requests

---

### **2. Focus Server API - Load Tests (8 ×˜×¡×˜×™×)**

| Test ID | ×©× ×”×˜×¡×˜ | ××” × ×‘×“×§ | ××›×•×¡×”? |
|---------|---------|---------|---------|
| **PZ-14800** | Concurrent Job Creation | 20 concurrent jobs | âœ… **××›×•×¡×”** |
| **PZ-14801** | Sustained Load | 1 ×©×¢×” (5 ×“×§×•×ª ×‘CI) | âœ… **××›×•×¡×”** |
| **PZ-14802** | Peak Load - High RPS | 10 RPS ×œ××©×š ×“×§×” | âœ… **××›×•×¡×”** |
| **PZ-14803** | Ramp-Up Profile | 1â†’10 RPS | âœ… **××›×•×¡×”** |
| **PZ-14804** | Spike Profile | 2â†’20 RPS spike | âœ… **××›×•×¡×”** |
| **PZ-14805** | Steady-State Profile | 5 RPS ×œ××©×š 3 ×“×§×•×ª | âœ… **××›×•×¡×”** |
| **PZ-14806** | Recovery After Load | 3 phases | âœ… **××›×•×¡×”** |
| **PZ-14807** | Resource Exhaustion | 50 RPS extreme | âœ… **××›×•×¡×”** |

---

### **3. API Performance Tests (4 ×˜×¡×˜×™×)**

| Test ID | ×©× ×”×˜×¡×˜ | Thresholds | ××›×•×¡×”? |
|---------|---------|-----------|---------|
| **PZ-13770** | /config Latency P95 | P95 < 300ms, P99 < 500ms | âœ… **××›×•×¡×”** |
| **PZ-13771-1** | Concurrent Task Creation | 20 tasks, 90% success | âœ… **××›×•×¡×”** |
| **PZ-13771-2** | Concurrent Task Polling | 10 tasks, 80% success | âœ… **××›×•×¡×”** |
| **PZ-13771-3** | Max Concurrent Limit | 10-50 tasks | âœ… **××›×•×¡×”** |

---

### **4. Stress & Capacity Tests (×¨×œ×•×•× ×˜×™ ×œ-load workflow)**

| Test | ××” × ×‘×“×§ | ××›×•×¡×”? |
|------|---------|---------|
| **Extreme Configurations** | NFFT 8192, 200 channels | âœ… **××›×•×¡×”** |
| **Graduated Load** | 5â†’50 jobs ××“×•×¨×’ | âœ… **××›×•×¡×”** |
| **Heavy Config Stress** | 200 channels, NFFT 2048 | âœ… **××›×•×¡×”** (××‘×œ ×œ× ×‘-load workflow!) |

---

### **5. Resilience Tests (×¨×œ×•×•× ×˜×™ ×—×œ×§×™×ª)**

| Test | ××” × ×‘×“×§ | ×‘-Load Workflow? |
|------|---------|-----------------|
| **MongoDB Outage** | Response time < 5s | âŒ **×œ×** - × ×¤×¨×“ |
| **RabbitMQ Outage** | Graceful degradation | âŒ **×œ×** - × ×¤×¨×“ |
| **Focus Server Pod** | Auto-recovery | âŒ **×œ×** - × ×¤×¨×“ |
| **Live Streaming Stability** | 5 ×“×§×•×ª ×™×¦×™×‘×•×ª | âŒ **×œ×** - × ×¤×¨×“ |

---

## âŒ ×¤×¢×¨×™× ×§×¨×™×˜×™×™× ×©×–×•×”×•

### **ğŸ”´ ×¤×¢×¨ 1: Soak Testing (Memory Leak Detection)**

**××” ×—×¡×¨:**
- âœ… ×™×©: `test_focus_server_stability_over_time` (1 ×©×¢×”)
- âŒ **××‘×œ:** ××¡×•××Ÿ ×›-`skip` ×•×œ× ×¨×¥ ××•×˜×•××˜×™×ª
- âŒ **××‘×œ:** ×œ× ×—×œ×§ ××”-load workflow

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.soak
@pytest.mark.slow  
@pytest.mark.nightly
def test_memory_leak_detection_24_hours():
    """
    Run 10 jobs every minute for 24 hours.
    Monitor memory growth over time.
    Alert if memory increases > 20%.
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¡ **MEDIUM**  
**×¡×™×‘×”:** Memory leaks ××ª×’×œ×™× ×¨×§ ×‘×¨×™×¦×•×ª ××¨×•×›×•×ª. 1 ×©×¢×” ×œ× ××¡×¤×™×§.

---

### **ğŸ”´ ×¤×¢×¨ 2: Network Bandwidth Under Load**

**××” ×—×¡×¨:**
- ×‘×“×™×§×ª MB/s streaming rate ×ª×—×ª load
- ×‘×“×™×§×ª network latency ×›×©-concurrent jobs ×¨×¦×™×
- ×‘×“×™×§×ª packet loss ×ª×—×ª ×¢×•××¡

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.network
def test_streaming_bandwidth_under_load():
    """
    Create 20 concurrent streaming jobs.
    Measure:
    - Total network bandwidth (MB/s)
    - Per-job bandwidth
    - Packet loss
    - Network latency degradation
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¡ **MEDIUM**  
**×¡×™×‘×”:** Network bottleneck ×œ× ××–×•×”×” ×‘×˜×¡×˜×™× ×”× ×•×›×—×™×™×.

---

### **ğŸ”´ ×¤×¢×¨ 3: Database Query Performance Under Load**

**××” ×—×¡×¨:**
- MongoDB query latency ×›×©-system under load
- Index performance verification
- Query plan optimization checks

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.database
def test_mongodb_query_performance_under_load():
    """
    Create 30 concurrent jobs (high load).
    While under load, measure:
    - MongoDB ping latency (should stay < 100ms)
    - Query execution time
    - Index usage
    - Connection pool exhaustion
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¡ **MEDIUM**  
**×¡×™×‘×”:** Database ×™×›×•×œ ×œ×”×™×•×ª bottleneck ×©×œ× ××–×•×”×”.

---

### **ğŸ”´ ×¤×¢×¨ 4: Concurrent Different Endpoints**

**××” ×—×¡×¨:**
- ×©×™××•×© ×‘-endpoints ×©×•× ×™× ×‘×•-×–×× ×™×ª
- Mixed workload: configure + cancel + poll + metadata

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.mixed_workload
def test_mixed_endpoint_workload():
    """
    Simultaneous:
    - 10 jobs creating (POST /configure)
    - 5 jobs canceling (POST /cancel)
    - 20 metadata requests (GET /metadata)
    - 15 status polls (GET /job_status)
    
    Measure interference between endpoints.
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¢ **LOW**  
**×¡×™×‘×”:** ×¨×•×‘ ×”×˜×¡×˜×™× ×××•×§×“×™× ×‘endpoint ××—×“ ×‘×›×œ ×¤×¢×.

---

### **ğŸ”´ ×¤×¢×¨ 5: Streaming Data Rate Performance**

**××” ×—×¡×¨:**
- GET /waterfall performance under load
- Data streaming rate (rows/second)
- Large waterfall retrieval (1000+ rows)

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.streaming
def test_waterfall_streaming_performance():
    """
    Create job and stream waterfall data.
    Measure:
    - Rows per second
    - Latency for different row counts (10, 100, 1000)
    - Data consistency under load
    - Stream drops/errors
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¡ **MEDIUM**  
**×¡×™×‘×”:** Waterfall ×”×•× endpoint ×§×¨×™×˜×™ ×œUI ×©×œ× × ×‘×“×§ ×ª×—×ª ×¢×•××¡.

---

### **ğŸ”´ ×¤×¢×¨ 6: Long-Running Job Stability**

**××” ×—×¡×¨:**
- Job ×©×¨×¥ ×œ×©×¢×•×ª (6-24 hours)
- ×‘×“×™×§×ª stability ×©×œ stream ××¨×•×š

**××” ×§×™×™×:**
- âœ… `test_live_streaming_stability` - **×¨×§ 5 ×“×§×•×ª**

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.soak
@pytest.mark.skip(reason="Very long - run manually")
def test_long_running_job_24_hours():
    """
    Create single live streaming job.
    Monitor for 24 hours:
    - Job stays active
    - No memory leaks in job
    - Stream data quality stays consistent
    - No connection drops
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¡ **MEDIUM**  
**×¡×™×‘×”:** Jobs ××¨×•×›×™× ×¢×œ×•×œ×™× ×œ×—×©×•×£ bugs ×©×œ× ××ª×’×œ×™× ×‘-5 ×“×§×•×ª.

---

### **ğŸ”´ ×¤×¢×¨ 7: Concurrent Users Simulation**

**××” ×—×¡×¨:**
- Multiple users creating jobs simultaneously
- Different users on different channels
- User authentication under load

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.multi_user
def test_concurrent_users_different_channels():
    """
    Simulate 10 users:
    - Each user creates jobs on different channels
    - Each user has separate session
    - Measure:
      - Success rate per user
      - Latency per user
      - Resource sharing fairness
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¢ **LOW**  
**×¡×™×‘×”:** ×‘×¨×•×‘ ×”××§×¨×™× ×™×© user ××—×“, ××‘×œ ×—×©×•×‘ ×œvalidate multi-tenancy.

---

### **ğŸ”´ ×¤×¢×¨ 8: Job Capacity Tests ×œ× ×‘-Load Workflow**

**××” ×”×—×¡×¨:**
- Stress tests (`test_extreme_configurations.py`) ×œ× ×¨×¦×™× ×‘-load workflow
- Heavy config tests ×œ× ×¨×¦×™× ×‘-load workflow
- `test_job_capacity_limits.py` ×œ× ×¨×¥ ×‘-load workflow

**×œ××”?**
```yaml
# .github/workflows/load-performance.yml
pytest -m "load or performance"
```

**×”×‘×¢×™×”:**
```python
# test_extreme_configurations.py has:
@pytest.mark.stress  # âŒ ×œ× load ××• performance

# test_job_capacity_limits.py has:
@pytest.mark.regression  # âŒ ×œ× load ××• performance
```

**×¤×ª×¨×•×Ÿ:**
×œ×”×•×¡×™×£ markers:
```python
@pytest.mark.load  # ××•
@pytest.mark.performance
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸ”´ **HIGH**  
**×¡×™×‘×”:** ×˜×¡×˜×™× ×—×©×•×‘×™× ×œ× ×¨×¦×™× ××•×˜×•××˜×™×ª!

---

### **ğŸ”´ ×¤×¢×¨ 9: Data Quality Under Stress**

**××” ×—×¡×¨:**
- ×‘×“×™×§×ª ××™×›×•×ª ×”data ×›×©×”××¢×¨×›×ª ×ª×—×ª ×¢×•××¡
- ×‘×“×™×§×ª data loss
- ×‘×“×™×§×ª data corruption

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.data_quality
def test_data_quality_under_load():
    """
    Create 30 concurrent jobs.
    For each job:
    - Retrieve waterfall data
    - Verify data integrity
    - Check for missing samples
    - Verify calculations are correct
    
    Measure data loss rate (should be 0%).
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¡ **MEDIUM**  
**×¡×™×‘×”:** Under load, data quality ×¢×œ×•×œ ×œ×”×™×¤×’×¢ - ×¦×¨×™×š validation.

---

### **ğŸ”´ ×¤×¢×¨ 10: Cleanup Performance Under Load**

**××” ×—×¡×¨:**
- Cancel job performance when many jobs exist
- Cleanup time for 50+ jobs
- Concurrent cancellations

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
def test_concurrent_job_cancellation():
    """
    Create 50 jobs.
    Cancel all 50 jobs concurrently.
    Measure:
    - Cancellation success rate
    - Average cancellation time
    - Resource cleanup verification
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¢ **LOW**  
**×¡×™×‘×”:** Cleanup tested ××‘×œ ×œ× ×ª×—×ª load.

---

### **ğŸ”´ ×¤×¢×¨ 11: GET Endpoints Under Load**

**××” ×—×¡×¨:**
- GET /waterfall under concurrent load
- GET /metadata under concurrent load
- GET /sensors under concurrent load
- GET /task_metadata under concurrent load

**××” ×§×™×™×:**
- âœ… GET /ack - concurrent requests tested (PZ-14028)
- âœ… GET /channels - basic tests

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.performance
def test_get_endpoints_under_load():
    """
    Concurrent requests to all GET endpoints:
    - 50x GET /waterfall/{task_id}/100
    - 50x GET /metadata/{task_id}
    - 50x GET /sensors
    - 50x GET /channels
    
    Measure:
    - Response time per endpoint
    - Success rate
    - Bandwidth usage
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¡ **MEDIUM**  
**×¡×™×‘×”:** GET endpoints ×œ× × ×‘×“×§×™× ×ª×—×ª load.

---

### **ğŸ”´ ×¤×¢×¨ 12: Time-Based Load Patterns**

**××” ×—×¡×¨:**
- Morning spike simulation (8-9 AM)
- Evening load (6-8 PM)
- Off-hours baseline
- Weekend vs weekday patterns

**××” ×¦×¨×™×š:**
```python
@pytest.mark.load
@pytest.mark.pattern
def test_business_hours_load_pattern():
    """
    Simulate realistic daily pattern:
    - Low load (2 RPS) for 5 minutes
    - Morning spike (15 RPS) for 2 minutes
    - Normal load (5 RPS) for 5 minutes
    - Evening spike (12 RPS) for 2 minutes
    
    Verify system handles realistic patterns.
    """
```

**×—×•××¨×ª ×”×¤×¢×¨:** ğŸŸ¢ **LOW**  
**×¡×™×‘×”:** Nice to have, ×œ× ×§×¨×™×˜×™.

---

## ğŸ“Š ×¡×™×›×•× ×”×¤×¢×¨×™× ×œ×¤×™ ×—×•××¨×”

### **ğŸ”´ HIGH Priority (×—×•×‘×” ×œ×ª×§×Ÿ)**

1. **Job Capacity Tests ×œ× ×¨×¦×™× ×‘-Workflow**
   - **Action:** ×”×•×¡×£ `@pytest.mark.load` ×œ-`test_job_capacity_limits.py`
   - **Action:** ×”×•×¡×£ `@pytest.mark.stress` ××• `@pytest.mark.load` ×œ-`test_extreme_configurations.py`
   - **Effort:** 5 ×“×§×•×ª
   - **Impact:** ×˜×¡×˜×™× ×§×™×™××™× ×™×¨×•×¦×• ××•×˜×•××˜×™×ª

---

### **ğŸŸ¡ MEDIUM Priority (×¨×¦×•×™ ×œ×ª×§×Ÿ)**

2. **Soak Test ×œ× ×¨×¥** (Memory Leak Detection)
   - **Action:** ×¦×•×¨ `test_memory_leak_soak_24h.py`
   - **Action:** ×”×¤×¢×œ manual ×¤×¢× ×‘×©×‘×•×¢
   - **Effort:** ×©×¢×ª×™×™× ×›×ª×™×‘×”
   - **Impact:** ×™×–×”×” memory leaks ××•×§×“×

3. **Network Bandwidth Testing**
   - **Action:** ×¦×•×¨ `test_network_bandwidth_under_load.py`
   - **Effort:** 3-4 ×©×¢×•×ª
   - **Impact:** ×™×–×”×” network bottlenecks

4. **Database Query Performance Under Load**
   - **Action:** ×¦×•×¨ `test_mongodb_performance_under_load.py`
   - **Effort:** 2-3 ×©×¢×•×ª
   - **Impact:** ×™×–×”×” database bottlenecks

5. **Streaming Data Rate (Waterfall) Under Load**
   - **Action:** ×”×•×¡×£ `test_waterfall_performance_under_load.py`
   - **Effort:** 2 ×©×¢×•×ª
   - **Impact:** ×™×–×”×” streaming bottlenecks

6. **Data Quality Under Stress**
   - **Action:** ×”×•×¡×£ `test_data_integrity_under_load.py`
   - **Effort:** 4 ×©×¢×•×ª
   - **Impact:** ×•×™×“×•× data correctness ×ª×—×ª ×¢×•××¡

---

### **ğŸŸ¢ LOW Priority (nice to have)**

7. **Concurrent Users Simulation**
   - **Effort:** 3 ×©×¢×•×ª
   - **Impact:** Multi-user scenarios

8. **Mixed Workload (Different Endpoints)**
   - **Effort:** 2 ×©×¢×•×ª
   - **Impact:** Real-world simulation

9. **Long-Running Job (24h)**
   - **Effort:** 1 ×©×¢×” ×›×ª×™×‘×” + 24h ×¨×™×¦×”
   - **Impact:** ×™×–×”×” bugs ×‘jobs ××¨×•×›×™×

10. **Concurrent Cancellations**
    - **Effort:** 1 ×©×¢×”
    - **Impact:** Cleanup performance

11. **GET Endpoints Under Load**
    - **Effort:** 2 ×©×¢×•×ª
    - **Impact:** ×™×–×”×” read bottlenecks

12. **Time-Based Load Patterns**
    - **Effort:** 2 ×©×¢×•×ª
    - **Impact:** Realistic simulation

---

## ğŸ¯ ×”××œ×¦×•×ª ×œ×¤×¢×•×œ×” - ×¡×“×¨ ×¢×“×™×¤×•×™×•×ª

### **âœ… Action 1: ×ª×§×Ÿ ××ª Workflow (×“×—×•×£!)**

**×‘×¢×™×”:** ×˜×¡×˜×™× ×§×™×™××™× ×œ× ×¨×¦×™× ×‘-load workflow.

**×¤×ª×¨×•×Ÿ ××™×™×“×™:**
```python
# File: be_focus_server_tests/load/test_job_capacity_limits.py
# Add marker to all test classes:

@pytest.mark.load  # â† ADD THIS
@pytest.mark.regression
class TestGraduatedLoadCapacity:
    ...

# File: be_focus_server_tests/stress/test_extreme_configurations.py  
# Add marker:

@pytest.mark.stress  # â† Already has
@pytest.mark.load    # â† ADD THIS
@pytest.mark.regression
class TestExtremeConfigurationValues:
    ...
```

**×–××Ÿ ×‘×™×¦×•×¢:** 5 ×“×§×•×ª  
**×ª×•×¢×œ×ª:** ×˜×¡×˜×™× ×§×™×™××™× ×™×¨×•×¦×• ××•×˜×•××˜×™×ª

---

### **âœ… Action 2: Soak Test (×©×‘×•×¢×™)**

**×™×¦×™×¨×ª ×˜×¡×˜ ×—×“×©:**
```python
# File: be_focus_server_tests/load/test_soak_memory_leak.py

@pytest.mark.load
@pytest.mark.soak
@pytest.mark.slow
@pytest.mark.nightly
@pytest.mark.skip(reason="24h test - run manually weekly")
def test_memory_leak_soak_24_hours(focus_server_api):
    """
    Soak test: 24 hours continuous operation.
    
    Pattern:
    - Create 5 jobs every 5 minutes
    - Monitor memory, CPU, network
    - Log metrics every hour
    - Alert if memory growth > 15%
    
    Expected:
    - Memory stable (< 15% growth)
    - CPU stable
    - No crashes
    - Success rate > 95%
    """
    duration_hours = 24
    jobs_per_interval = 5
    interval_minutes = 5
    
    memory_baseline = psutil.virtual_memory().percent
    memory_samples = []
    cpu_samples = []
    
    start_time = time.time()
    end_time = start_time + (duration_hours * 3600)
    
    iteration = 0
    while time.time() < end_time:
        iteration += 1
        
        # Create jobs
        for i in range(jobs_per_interval):
            # ... create job ...
            pass
        
        # Sample metrics
        memory_samples.append(psutil.virtual_memory().percent)
        cpu_samples.append(psutil.cpu_percent(interval=1))
        
        # Log hourly
        if iteration % 12 == 0:  # Every hour (12 * 5min)
            hours_elapsed = (time.time() - start_time) / 3600
            memory_current = memory_samples[-1]
            memory_growth = memory_current - memory_baseline
            
            logger.info(f"Hour {hours_elapsed:.1f}:")
            logger.info(f"  Memory: {memory_current:.1f}% (+{memory_growth:.1f}%)")
            logger.info(f"  CPU: {cpu_samples[-1]:.1f}%")
        
        time.sleep(interval_minutes * 60)
    
    # Analysis
    memory_final = memory_samples[-1]
    memory_growth = memory_final - memory_baseline
    
    assert memory_growth < 15, \
        f"Memory leak detected: +{memory_growth:.1f}%"
```

**×”×¨×¦×”:**
```bash
# Run manually once a week
pytest be_focus_server_tests/load/test_soak_memory_leak.py::test_memory_leak_soak_24_hours -v -s --no-skip
```

**×–××Ÿ ×‘×™×¦×•×¢:** 2 ×©×¢×•×ª ×›×ª×™×‘×”  
**×ª×•×¢×œ×ª:** ×™×–×”×” memory leaks ×©×œ× × ×¨××™× ×‘×˜×¡×˜×™× ×§×¦×¨×™×

---

### **âœ… Action 3: Network & Streaming Performance**

**×™×¦×™×¨×ª ×˜×¡×˜ ×—×“×©:**
```python
# File: be_focus_server_tests/load/test_streaming_bandwidth.py

@pytest.mark.load
@pytest.mark.performance
@pytest.mark.network
def test_concurrent_streaming_bandwidth(focus_server_api):
    """
    Create 20 concurrent streaming jobs.
    For each job, poll waterfall data continuously.
    
    Measure:
    - Total bandwidth (MB/s)
    - Per-job bandwidth
    - Network latency
    - Packet loss
    - Stream consistency
    
    Expected:
    - Total bandwidth < network capacity
    - No significant latency increase
    - No packet loss
    - All streams remain stable
    """
    num_jobs = 20
    poll_duration = 300  # 5 minutes
    rows_per_poll = 100
    
    # Create jobs
    job_ids = []
    for i in range(num_jobs):
        response = focus_server_api.configure_streaming_job(...)
        job_ids.append(response.job_id)
    
    # Poll all jobs concurrently
    network_start = psutil.net_io_counters()
    start_time = time.time()
    
    def poll_job(job_id):
        bytes_received = 0
        polls = 0
        
        while time.time() - start_time < poll_duration:
            data = focus_server_api.get_waterfall(job_id, rows_per_poll)
            bytes_received += len(str(data))  # Approximation
            polls += 1
            time.sleep(1)
        
        return bytes_received, polls
    
    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = [executor.submit(poll_job, jid) for jid in job_ids]
        results = [f.result() for f in as_completed(futures)]
    
    network_end = psutil.net_io_counters()
    total_bytes = network_end.bytes_recv - network_start.bytes_recv
    total_time = time.time() - start_time
    bandwidth_mbps = (total_bytes * 8) / (total_time * 1_000_000)
    
    logger.info(f"Total bandwidth: {bandwidth_mbps:.2f} Mbps")
    
    # Cleanup
    for job_id in job_ids:
        focus_server_api.cancel_job(job_id)
```

**×–××Ÿ ×‘×™×¦×•×¢:** 3 ×©×¢×•×ª ×›×ª×™×‘×”  
**×ª×•×¢×œ×ª:** ×™×–×”×” network bottlenecks

---

### **âœ… Action 4: Database Performance Under Load**

**×™×¦×™×¨×ª ×˜×¡×˜ ×—×“×©:**
```python
# File: be_focus_server_tests/load/test_database_performance_under_load.py

@pytest.mark.load
@pytest.mark.performance
@pytest.mark.database
def test_mongodb_performance_under_load(focus_server_api, mongodb_manager):
    """
    Create high load on API.
    While under load, measure MongoDB performance.
    
    Steps:
    1. Create 30 concurrent jobs (high load)
    2. While jobs are processing, measure:
       - MongoDB ping latency
       - Query execution time for common queries
       - Connection pool status
       - Lock contention
    
    Expected:
    - MongoDB ping < 100ms even under load
    - Query time < 200ms
    - No connection pool exhaustion
    - No lock timeouts
    """
    # Create load
    def create_jobs():
        for i in range(30):
            focus_server_api.configure_streaming_job(...)
    
    # Start load in background
    load_thread = threading.Thread(target=create_jobs)
    load_thread.start()
    
    time.sleep(5)  # Let load stabilize
    
    # Measure database performance
    mongo_latencies = []
    for i in range(100):
        start = time.time()
        mongodb_manager.connect()
        # Perform query
        latency = (time.time() - start) * 1000
        mongo_latencies.append(latency)
        mongodb_manager.disconnect()
        time.sleep(0.1)
    
    load_thread.join()
    
    avg_latency = sum(mongo_latencies) / len(mongo_latencies)
    p95_latency = sorted(mongo_latencies)[95]
    
    logger.info(f"MongoDB under load:")
    logger.info(f"  Avg latency: {avg_latency:.2f}ms")
    logger.info(f"  P95 latency: {p95_latency:.2f}ms")
    
    assert avg_latency < 100, \
        f"MongoDB too slow under load: {avg_latency:.2f}ms"
```

**×–××Ÿ ×‘×™×¦×•×¢:** 3 ×©×¢×•×ª ×›×ª×™×‘×”  
**×ª×•×¢×œ×ª:** ×™×–×”×” database bottlenecks

---

## ğŸ“‹ ×ª×•×›× ×™×ª ×¤×¢×•×œ×” ××•××œ×¦×ª

### **ğŸš€ Sprint 1 (×©×‘×•×¢ 1) - Critical Fixes**

1. **×™×•× 1:** ×ª×™×§×•×Ÿ Workflow - ×”×•×¡×¤×ª markers âœ…
   - ×”×•×¡×£ `@pytest.mark.load` ×œ×›×œ ×”×˜×¡×˜×™× ×”×¨×œ×•×•× ×˜×™×™×
   - ×•×•×“× ×©×”× ×¨×¦×™× ×‘-workflow
   - **Effort:** 30 ×“×§×•×ª

2. **×™×•× 2-3:** Soak Test Creation ğŸ“
   - ×›×ª×•×‘ `test_soak_memory_leak.py`
   - ×‘×“×•×§ locally (2-4 hours)
   - ×©×œ×‘ ×‘-manual runs
   - **Effort:** 4 ×©×¢×•×ª

---

### **ğŸ¯ Sprint 2 (×©×‘×•×¢ 2) - Performance Gaps**

3. **×™×•× 1-2:** Streaming Bandwidth Test ğŸŒ
   - ×›×ª×•×‘ `test_streaming_bandwidth.py`
   - **Effort:** 6 ×©×¢×•×ª

4. **×™×•× 3-4:** Database Performance Under Load ğŸ’¾
   - ×›×ª×•×‘ `test_database_performance_under_load.py`
   - **Effort:** 6 ×©×¢×•×ª

5. **×™×•× 5:** GET Endpoints Under Load ğŸ“¡
   - ×›×ª×•×‘ `test_get_endpoints_under_load.py`
   - **Effort:** 4 ×©×¢×•×ª

---

### **âœ¨ Sprint 3 (×©×‘×•×¢ 3) - Nice to Have**

6. **Data Quality Under Stress**
   - ×›×ª×•×‘ `test_data_integrity_under_load.py`
   - **Effort:** 8 ×©×¢×•×ª

7. **Concurrent Users Simulation**
   - ×›×ª×•×‘ `test_concurrent_users.py`
   - **Effort:** 6 ×©×¢×•×ª

8. **Mixed Workload**
   - ×›×ª×•×‘ `test_mixed_endpoint_workload.py`
   - **Effort:** 4 ×©×¢×•×ª

---

## ğŸ“ ×œ×¡×™×›×•× - ×”×× ×”×›×œ ××›×•×¡×”?

### **âœ… ××” ×©××›×•×¡×” ××¢×•×œ×” (23 ×˜×¡×˜×™×):**

1. âœ… Alert load & performance (11 tests)
2. âœ… API load profiles (8 tests)
3. âœ… API performance & latency (4 tests)
4. âœ… Resilience & recovery tests
5. âœ… Concurrent operations
6. âœ… Resource monitoring

### **âš ï¸ ××” ×©×—×¡×¨ (12 ×¤×¢×¨×™×):**

#### **×—×•×‘×” ×œ×ª×§×Ÿ:**
1. ğŸ”´ **Job capacity tests ×œ× ×¨×¦×™×** - ×ª×™×§×•×Ÿ ×©×œ 5 ×“×§×•×ª!

#### **××•××œ×¥ ×‘×—×•×:**
2. ğŸŸ¡ **Soak test** - memory leaks
3. ğŸŸ¡ **Network bandwidth** - streaming bottlenecks
4. ğŸŸ¡ **Database performance** - query bottlenecks
5. ğŸŸ¡ **Waterfall under load** - data retrieval
6. ğŸŸ¡ **Data quality** - correctness under stress

#### **Nice to have:**
7-12. Mixed workload, concurrent users, patterns, etc.

---

## âœ… ×”××œ×¦×” ×¡×•×¤×™×ª

**×ª×©×•×‘×” ×œ×©××œ×”: "×”×× ×”×›×œ ××›×•×¡×”?"**

### **ğŸŸ¢ ×›×™×¡×•×™ ×˜×•×‘ ×××•×“ (85%):**
- ×™×© 23 ×˜×¡×˜×™× ××§×™×¤×™×
- ×›×œ ×”-happy paths ××›×•×¡×™×
- Resilience ××›×•×¡×”
- Performance baselines ××›×•×¡×™×

### **ğŸŸ¡ ×¤×¢×¨×™× ×©×›×“××™ ×œ×¡×’×•×¨ (15%):**
- **×ª×™×§×•×Ÿ ××™×™×“×™:** ×”×•×¡×£ markers ×œ×˜×¡×˜×™× ×§×™×™××™× (5 ×“×§×•×ª)
- **×”×©×œ××” ×—×©×•×‘×”:** Soak test, network, database (2-3 ×©×‘×•×¢×•×ª)
- **Nice to have:** ×”×˜×¡×˜×™× ×”× ×•×¡×¤×™× (1-2 ×©×‘×•×¢×•×ª)

### **ğŸ¯ Bottom Line:**

**×™×© ×œ×›× ×‘×¡×™×¡ ××¦×•×™×Ÿ!** ğŸ‰

**×¢×“×™×¤×•×™×•×ª:**
1. **×¢×›×©×™×•:** ×ª×§×Ÿ ××ª ×”-workflow (5 ×“×§×•×ª)
2. **×”×©×‘×•×¢:** Soak test (2-4 ×©×¢×•×ª)
3. **×”×—×•×“×© ×”×‘×:** Network + Database tests (2 ×©×‘×•×¢×•×ª)

**×× ××ª×” ×¦×¨×™×š ×œ×‘×—×•×¨ 3 ×“×‘×¨×™× ×œ×¢×©×•×ª:**
1. âœ… ×ª×§×Ÿ workflow markers
2. âœ… Soak test ×œ××©×š 24h
3. âœ… Network bandwidth test

×”×›×œ ×”××—×¨ - bonus! ğŸ

---

**× ×•×¦×¨ ×¢×œ ×™×“×™:** QA Automation Architect  
**×ª××¨×™×š:** 23 ×‘× ×•×‘××‘×¨ 2025  
**×’×¨×¡×”:** 1.0  
**×¡×˜×˜×•×¡:** Gap Analysis Complete âœ…

