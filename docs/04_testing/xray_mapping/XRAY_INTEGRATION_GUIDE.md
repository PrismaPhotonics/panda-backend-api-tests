# ğŸ”— Xray Integration Guide - Complete Setup

**Date:** October 27, 2025  
**Status:** âœ… Ready to Use  
**Implementation:** Based on your original request model

---

## ğŸ“‹ What Was Created?

### âœ… Configuration Files
1. **`config/xray_config.yaml`** - Xray configuration
2. **`tests/conftest_xray.py`** - pytest integration hooks

### âœ… Scripts
3. **`scripts/xray_upload.py`** - Upload script for Xray Cloud
4. **`.github/workflows/xray_upload.yml`** - CI/CD integration

### âœ… Documentation
5. **`XRAY_INTEGRATION_GUIDE.md`** (this file) - Complete guide

---

## ğŸ¯ Quick Start

### 1. Setup Environment Variables

```bash
# Linux/Mac
export XRAY_CLIENT_ID="your_client_id"
export XRAY_CLIENT_SECRET="your_client_secret"

# Windows PowerShell
$env:XRAY_CLIENT_ID="your_client_id"
$env:XRAY_CLIENT_SECRET="your_client_secret"

# Windows CMD
set XRAY_CLIENT_ID=your_client_id
set XRAY_CLIENT_SECRET=your_client_secret
```

### 2. Mark Tests with Xray Keys

```python
# tests/integration/api/test_example.py
import pytest

@pytest.mark.xray("PZ-13909")
def test_historic_config_missing_end_time():
    """Test PZ-13909: Historic Configuration Missing end_time Field"""
    pass

@pytest.mark.xray("PZ-13907", "PZ-13909")  # One test covers multiple Xray tests
def test_comprehensive_historic_validation():
    """This one test validates both PZ-13907 and PZ-13909"""
    pass

@pytest.mark.anchor("PZ-5000")
def test_high_level_historic_flow():
    """Anchor test for historic playback"""
    pass
```

### 3. Run Tests with Xray Integration

```bash
# Run tests with Xray
pytest tests/ --xray

# Run specific test
pytest tests/integration/api/test_example.py::test_historic_config_missing_end_time --xray

# Generate reports
pytest tests/ \
  --xray \
  --junitxml=reports/junit.xml \
  --html=reports/report.html
```

### 4. Upload Results to Xray

```bash
# Upload automatically detected report
python scripts/xray_upload.py

# Upload specific format
python scripts/xray_upload.py --format json
python scripts/xray_upload.py --format junit

# Link to existing Test Execution
python scripts/xray_upload.py --test-exec-key PZ-EXE-123
```

---

## ğŸ—ï¸ Architecture: Anchor Test Model

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Automated Test (pytest)                         â”‚
â”‚                                                  â”‚
â”‚  @pytest.mark.xray("PZ-13909")                  â”‚
â”‚  def test_historic_config():                     â”‚
â”‚      pass                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Xray Test: PZ-13909 (Anchor)                    â”‚
â”‚  Type: Automated                                 â”‚
â”‚  Status: Automated                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼ (Linked via Issues/Test Sets)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Manual Tests / Requirements                      â”‚
â”‚  â€¢ PZ-13907 (manual)                            â”‚
â”‚  â€¢ PZ-13908 (manual)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Anchor Tests?

âœ… **One-to-Many Mapping:** One automated test can validate multiple manual tests  
âœ… **Flexible:** Easy to refactor later to 1:1 if needed  
âœ… **Clear Traceability:** Links show coverage  
âœ… **No Breaking Changes:** Manual tests stay as-is

---

## ğŸ“Š Example: Mapping Current Tests

Based on your CSV, here's how to map:

### Test 1: PZ-13909 - Historic Configuration Missing end_time

```python
# tests/integration/api/test_prelaunch_validations.py
@pytest.mark.xray("PZ-13909")
def test_time_range_validation_missing_end_time(focus_server_api):
    """PZ-13909: Historic Configuration Missing end_time Field"""
    # Your test logic
    pass
```

### Test 2: PZ-13984 - Future Timestamp Validation

```python
# tests/integration/api/test_prelaunch_validations.py
@pytest.mark.xray("PZ-13984")
def test_time_range_validation_future_timestamps(focus_server_api):
    """PZ-13984: Future Timestamp Validation Gap"""
    # Your existing test (already has the bug!)
    pass
```

### Test 3: PZ-13985 - LiveMetadata Missing Fields

```python
# tests/integration/api/test_api_endpoints_high_priority.py
@pytest.mark.xray("PZ-13985")
def test_get_live_metadata(focus_server_api):
    """PZ-13985: LiveMetadata Missing Required Fields"""
    # Your existing test
    pass
```

---

## ğŸ”§ Step-by-Step Implementation

### Step 1: Add Xray Markers to Existing Tests

```bash
# Find all test files
find tests/ -name "test_*.py" | head -5

# Example mapping:
# tests/integration/api/test_prelaunch_validations.py â†’ PZ-13909, PZ-13984
# tests/data_quality/test_mongodb_data_quality.py â†’ PZ-13983 (optional)
# tests/integration/api/test_api_endpoints_high_priority.py â†’ PZ-13985
```

### Step 2: Create Anchor Tests in Xray

For each category, create an Anchor Test:

1. **Go to Jira** â†’ Create Test Issue
2. **Type:** Test  
3. **Summary:** `Focus Server: Historic Playback (Anchor)`
4. **Test Type:** Automated
5. **Test Automation Status:** Automated
6. **Test Key:** `PZ-13909-ANCHOR` (for example)

### Step 3: Link Manual Tests to Anchor

1. **In Jira:** Open manual test (e.g., PZ-13907)
2. **Add link:** Link to PZ-13909-ANCHOR (Relates/Tests)
3. **Test Set:** Add both to same Test Set

### Step 4: Run Tests and Upload

```bash
# Run tests
pytest tests/ --xray -v

# Check generated reports
ls -lh reports/
# reports/xray-exec.json
# reports/junit.xml
# reports/report.html

# Upload to Xray
python scripts/xray_upload.py
```

### Step 5: Verify in Jira

1. **Go to Xray** â†’ Test Execution
2. **Find your execution** (created by upload)
3. **See results:** Pass/Fail per test
4. **Drill down:** Click test to see details

---

## ğŸ¨ CI/CD Integration

### GitHub Actions (Already Created!)

The workflow `.github/workflows/xray_upload.yml` will:

1. âœ… Run tests automatically
2. âœ… Generate Xray JSON
3. âœ… Upload to Xray
4. âœ… Comment on PRs
5. âœ… Upload artifacts

### Setup GitHub Secrets

```bash
# In GitHub repo â†’ Settings â†’ Secrets â†’ Actions
# Add:
XRAY_CLIENT_ID
XRAY_CLIENT_SECRET
```

### Manual Run

```bash
# Trigger via GitHub CLI
gh workflow run xray_upload.yml

# Or manually trigger in GitHub UI:
# Actions â†’ Upload Test Results to Xray â†’ Run workflow
```

---

## ğŸ“ˆ Results & Reporting

### What Gets Reported to Xray?

âœ… **Test Status:** PASSED / FAILED  
âœ… **Test Execution:** New execution created per run  
âœ… **Test Duration:** Start/finish time  
âœ… **Comments:** Error messages  
âœ… **Evidences:** Logs, screenshots (optional)

### Viewing Results

1. **Jira â†’ Xray**
2. **Test Execution**
3. **Your Test** â†’ See status
4. **Test Plan Coverage** â†’ See which tests covered

---

## ğŸ”„ Migration Path

### Currently (Manual Only)

```
Jira Tests (Manual) â†’ Run manually â†’ Update Jira
```

### With This Integration (Hybrid)

```
Jira Anchor Tests (Automated) â†â†’ pytest (Automated)
      â†“
   Linked to Manual Tests
```

### Future (Full Automation)

```
Jira Tests (Automated) â†â†’ pytest (1:1) â†â†’ Full automation
```

---

## ğŸ› Troubleshooting

### "Authentication failed"

```bash
# Check environment variables
echo $XRAY_CLIENT_ID
echo $XRAY_CLIENT_SECRET

# Re-authenticate
export XRAY_CLIENT_ID="your_client_id"
export XRAY_CLIENT_SECRET="your_client_secret"
```

### "No Xray keys found"

```python
# Check that tests have markers
@pytest.mark.xray("PZ-1234")  # â† Make sure this exists
def test_something():
    pass
```

### "File not found: reports/xray-exec.json"

```bash
# Run tests first
pytest tests/ --xray

# Check that conftest_xray.py is loaded
pytest tests/ --collect-only | grep xray
```

---

## ğŸ“š Next Steps

1. âœ… **Add Xray markers to your tests** (use examples above)
2. âœ… **Create Anchor Tests in Jira** (1 per category)
3. âœ… **Link manual tests to anchors**
4. âœ… **Run first upload** to test
5. âœ… **Monitor results in Xray**

---

## ğŸ¯ Summary

**What you asked for:**
> "×œ×©×™×™×›×™× ×‘×™×Ÿ Xray ×œ×‘×™×Ÿ ×‘×“×™×§×•×ª ×”××•×˜×•××¦×™×” ×’× ×›×©××™×Ÿ ×”×ª×××” 1:1"

**What you got:**
âœ… Anchor Test model (no 1:1 required!)  
âœ… pytest markers support  
âœ… Automatic JSON generation  
âœ… CI/CD integration  
âœ… Complete upload script  
âœ… Step-by-step guide

**Ready to use!** ğŸš€

---

## ğŸ“ Support

**Files created:**
- `config/xray_config.yaml`
- `tests/conftest_xray.py`
- `scripts/xray_upload.py`
- `.github/workflows/xray_upload.yml`
- `XRAY_INTEGRATION_GUIDE.md` (this file)

**Next:** Add `@pytest.mark.xray("KEY")` to your tests and run!

