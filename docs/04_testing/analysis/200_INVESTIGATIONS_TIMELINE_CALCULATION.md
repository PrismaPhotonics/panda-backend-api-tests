# חישוב תהליך: 200 חקירות באוטומציה
# Calculation: 200 Investigations Automation Process

**תאריך:** 2025-01-27  
**עדכון:** 2025-01-27 - תיקון הנחות שגויות  
**מטרה:** לחשב את התהליך המלא של יצירת 200 חקירות ותוך כמה זמן הן נסגרות

---

## ⚠️ אזהרות חשובות

### 1. קובץ התצורה לא מעודכן
**הקובץ:** `debug-codebase/pz/config/panda/templates/job-template.yml` **לא מעודכן!**

**מקורות מעודכנים:**
- ConfigMap של `grpc-job-template` ב-namespace של `panda`
- קובץ: `/mnt/panda/offline_deploy/linux-infra/charts/panda/templates/grpc-job/job.yml`

### 2. מנגנון Cleanup מורכב
**הבעיה:** כדי לחשב כמה זמן לוקח ל-Job להיסגר, צריך להבין:
- מתי הצריכה של CPU ו-Memory יורדת (זה החלק המורכב!)
- ה-cleanup job מחכה שהזכרון וה-CPU יהיו בצריכה נמוכה לאורך זמן

**מה שאנחנו יודעים:**
- Cleanup job בודק CPU ו-Memory
- הוא מחכה לצריכה נמוכה לאורך זמן
- **אבל:** לא יודעים מתי בדיוק הצריכה יורדת

### 3. חקירות לא בלתי תלויות
**הבעיה:** ההנחה שהחקירות בלתי תלויות **לא נכונה!**

**למה:**
- הכמות יכולה להשפיע על משך הזמן עד שחקירה תסתיים
- עם יותר חקירות במקביל, יכול להיות:
  - עומס על המערכת
  - עיכובים ב-cleanup
  - השפעה על זמן סגירה

### 4. צריכת הודעות gRPC
**הבעיה:** נראה שמישהו צורך את ההודעות מה-gRPC ואז הוא לא יפסיק.

**מה זה אומר:**
- אם יש consumer שצורך הודעות מה-gRPC stream ולא מפסיק
- ה-Job לא ייסגר כי הוא עדיין מזרים נתונים
- זה יכול להשפיע על זמן הסגירה

### 5. חוסר ודאות בזמן סגירה
**הבעיה:** **לא יודעים כמה זמן בדיוק לוקח ל-Job להיסגר.**

**למה:**
- לא יודעים איך הריסוטים משפיעים על זה
- לא יודעים מתי בדיוק הצריכה יורדת
- לא יודעים אם יש consumers אחרים שצורכים הודעות

---

## 📊 פרמטרים מהקוד

**מקור:** `be_focus_server_tests/stress/test_investigation_stress_loop.py`

```python
MAX_OPEN_INVESTIGATIONS = 200  # N - maximum number of open investigations
NEW_INVESTIGATIONS_BATCH = 5    # n - number of new investigations per iteration
MAX_RETRIES = 3                 # Maximum retries for failed job creation
RETRY_DELAY_SECONDS = 2         # Delay between retries
GRPC_WAIT_TIMEOUT_SECONDS = 30  # Timeout for waiting for gRPC data
GRPC_MIN_FRAMES = 5             # Minimum number of frames to receive
```

**Delay בין איטרציות:** 1 שנייה (שורה 353: `time.sleep(1)`)

---

## 🔄 תהליך יצירת 200 חקירות

### מבנה האיטרציה:

```
ITERATION N:
  Step 0: Check active investigations count
  Step 1: Create 5 new investigations (sequential)
  Step 2: Wait for gRPC data for each (sequential)
  Step 3: Delay 1 second
  Loop back to Step 0
```

### זמן לכל חקירה (מתוך התיעוד):

| שלב | זמן | הערות |
|-----|-----|-------|
| **יצירת Job** | ~0.3 שניות | POST /configure |
| **חיבור ל-gRPC** | ~12 שניות | בעיית ביצועים שזוהתה |
| **בדיקת Frames** | ~6-7 שניות | תלוי במספר frames (5 frames minimum) |
| **ניתוק** | ~0.1 שניות | client.disconnect() |
| **סה"כ לחקירה** | **~19-20 שניות** | |

---

## 📈 חישוב זמן יצירת 200 חקירות

### מספר איטרציות:
```
200 חקירות ÷ 5 חקירות לאיטרציה = 40 איטרציות
```

### זמן לאיטרציה:

**חקירה אחת:**
- יצירה: 0.3 שניות
- חיבור: 12 שניות
- בדיקה: 6-7 שניות
- ניתוק: 0.1 שניות
- **סה"כ: ~19 שניות**

**5 חקירות ברצף (sequential):**
- חקירה 1: 19 שניות
- חקירה 2: 19 שניות
- חקירה 3: 19 שניות
- חקירה 4: 19 שניות
- חקירה 5: 19 שניות
- **סה"כ: 5 × 19 = 95 שניות**

**Delay בין איטרציות:** 1 שנייה

**זמן לאיטרציה כולל:**
```
95 שניות (5 חקירות) + 1 שנייה (delay) = 96 שניות
```

### זמן כולל ל-200 חקירות:

```
40 איטרציות × 96 שניות = 3,840 שניות = 64 דקות = ~1.07 שעות
```

**אבל:** זה בהנחה שכל חקירה רצה ברצף. בפועל, יש overlap כי:
- חקירה 1 מתחילה ב-t=0
- חקירה 2 מתחילה ב-t=19
- חקירה 3 מתחילה ב-t=38
- ...

**זמן אמיתי ליצירת 200 חקירות:**
```
40 איטרציות × 96 שניות = 3,840 שניות = 64 דקות
```

---

## ⏱️ מתי כל ה-200 חקירות נסגרות?

### ⚠️ חוסר ודאות - לא יודעים בדיוק!

**הבעיה:** לא יודעים כמה זמן בדיוק לוקח ל-Job להיסגר.

**למה:**
1. **מנגנון Cleanup מורכב:**
   - Cleanup job בודק CPU **ו-Memory** (לא רק CPU!)
   - הוא מחכה שהצריכה תהיה נמוכה לאורך זמן
   - **אבל:** לא יודעים מתי בדיוק הצריכה יורדת
   - זה תלוי בכמה זמן לוקח ל-Job להפסיק לזרום נתונים

2. **צריכת הודעות gRPC:**
   - נראה שמישהו צורך את ההודעות מה-gRPC ואז הוא לא יפסיק
   - אם יש consumer שצורך הודעות ולא מפסיק → ה-Job לא ייסגר
   - זה יכול להשפיע על זמן הסגירה

3. **השפעת כמות החקירות:**
   - החקירות לא בלתי תלויות
   - עם יותר חקירות במקביל:
     - עומס על המערכת
     - עיכובים ב-cleanup
     - השפעה על זמן סגירה

4. **ריסוטים:**
   - לא יודעים איך הריסוטים משפיעים על זמן הסגירה

### מה שאנחנו יודעים (מתוך `docs/07_infrastructure/JOB_DELETION_TIMELINE.md`):

**תרחיש אידיאלי:** הלקוח מתחבר, בודק נתונים, ומתנתק

**מה קורה אחרי ניתוק (בתיאוריה):**
1. הלקוח מתנתק מה-gRPC stream
2. ה-Kubernetes Job נשאר פתוח
3. `cleanup-job-$JOB_ID` בודק CPU ו-Memory כל 10 שניות
4. אם CPU ≤ 4m (millicores) במשך 5 בדיקות רצופות → מתחיל cleanup
5. זמן כולל: **5 × 10s = 50 שניות** (בתיאוריה)

**אבל בפועל:**
- לא יודעים מתי הצריכה יורדת
- לא יודעים אם יש consumers אחרים
- לא יודעים איך הכמות משפיעה

---

## 📊 חישוב זמן סגירה של כל ה-200 Jobs

### נקודת זמן: מתי כל Job נסגר?

**הנחה:** כל חקירה מתחילה, מתחברת, בודקת, ומתנתקת.

**תזמון:**
- חקירה 1 מתחילה ב: **t = 0 שניות**
- חקירה 1 מתנתקת ב: **t = 19 שניות**
- חקירה 1 נסגרת ב: **t = 19 + 50 = 69 שניות**

- חקירה 2 מתחילה ב: **t = 19 שניות**
- חקירה 2 מתנתקת ב: **t = 38 שניות**
- חקירה 2 נסגרת ב: **t = 38 + 50 = 88 שניות**

- חקירה 3 מתחילה ב: **t = 38 שניות**
- חקירה 3 מתנתקת ב: **t = 57 שניות**
- חקירה 3 נסגרת ב: **t = 57 + 50 = 107 שניות**

**נוסחה כללית:**
```
חקירה N מתחילה ב: t = (N-1) × 19 שניות
חקירה N מתנתקת ב: t = N × 19 שניות
חקירה N נסגרת ב: t = N × 19 + 50 שניות
```

### חקירה אחרונה (חקירה 200):

**חקירה 200 מתחילה ב:**
```
t = (200-1) × 19 = 199 × 19 = 3,781 שניות = 63.02 דקות
```

**חקירה 200 מתנתקת ב:**
```
t = 200 × 19 = 3,800 שניות = 63.33 דקות
```

**חקירה 200 נסגרת ב:**
```
t = 3,800 + 50 = 3,850 שניות = 64.17 דקות = ~1.07 שעות
```

---

## 🎯 תשובה: תוך כמה זמן כל ה-200 חקירות נסגרות?

### זמן סגירה של החקירה האחרונה:

**חקירה 200 נסגרת ב:**
```
3,850 שניות = 64.17 דקות = ~1.07 שעות
```

**אבל:** זה לא אומר שכל ה-200 נסגרות באותו זמן!

### התפלגות זמן סגירה:

| חקירה | מתחילה ב | מתנתקת ב | נסגרת ב |
|-------|----------|-----------|---------|
| **1** | 0 שניות | 19 שניות | **69 שניות** |
| **50** | 931 שניות | 950 שניות | **1,000 שניות** |
| **100** | 1,881 שניות | 1,900 שניות | **1,950 שניות** |
| **150** | 2,831 שניות | 2,850 שניות | **2,900 שניות** |
| **200** | 3,781 שניות | 3,800 שניות | **3,850 שניות** |

### זמן סגירה כולל:

**החקירה הראשונה נסגרת ב:** 69 שניות (~1.15 דקות)  
**החקירה האחרונה נסגרת ב:** 3,850 שניות (~64.17 דקות)

**כל ה-200 חקירות נסגרות תוך:** **~64.17 דקות** (מהתחלת התהליך)

---

## 📊 גרף זמן - מתי Jobs פתוחים

### מספר Jobs פתוחים בכל רגע:

```
t=0s:     Job 1 נוצר
t=19s:    Job 1 מתנתק, Job 2 נוצר
t=38s:    Job 2 מתנתק, Job 3 נוצר
...
t=69s:    Job 1 נסגר (50s אחרי ניתוק)
t=88s:    Job 2 נסגר (50s אחרי ניתוק)
...
t=3,800s: Job 200 מתנתק
t=3,850s: Job 200 נסגר (50s אחרי ניתוק)
```

### מספר Jobs פתוחים במקביל:

**בזמן t=0 עד t=19:**
- Job 1: פתוח (0-69s)
- **סה"כ: 1 Job**

**בזמן t=19 עד t=38:**
- Job 1: פתוח (0-69s)
- Job 2: פתוח (19-88s)
- **סה"כ: 2 Jobs**

**בזמן t=69 עד t=88:**
- Job 1: נסגר ב-t=69
- Job 2: פתוח (19-88s)
- Job 3: פתוח (38-107s)
- **סה"כ: 2 Jobs**

**בזמן t=3,800 עד t=3,850:**
- Job 200: פתוח (3,781-3,850s)
- Jobs 199, 198, 197, 196: עדיין פתוחים (כל אחד נסגר 50s אחרי ניתוק)
- **סה"כ: ~5 Jobs** (תלוי בדיוק של הזמנים)

### שיא מספר Jobs במקביל:

**חישוב:**
- כל חקירה נשארת פתוחה 50 שניות אחרי ניתוק
- זמן בין חקירות: 19 שניות
- מספר Jobs במקביל = 50 / 19 = **~2.6 Jobs בממוצע**

**אבל בפועל:**
- בזמן יצירה רציפה: יכול להיות עד **~3 Jobs במקביל**
- בזמן יצירה עם delay: יכול להיות עד **~2 Jobs במקביל**

---

## 🔍 חישוב מפורט: מתי כל Job נסגר

### נוסחה:

```
Job N מתחיל ב: start_time(N) = (N-1) × 19 שניות
Job N מתנתק ב: disconnect_time(N) = N × 19 שניות
Job N נסגר ב: close_time(N) = N × 19 + 50 שניות
```

### דוגמאות:

| Job | מתחיל | מתנתק | נסגר | זמן פתוח |
|-----|-------|--------|------|----------|
| 1 | 0s | 19s | **69s** | 69s |
| 10 | 171s | 190s | **240s** | 69s |
| 50 | 931s | 950s | **1,000s** | 69s |
| 100 | 1,881s | 1,900s | **1,950s** | 69s |
| 150 | 2,831s | 2,850s | **2,900s** | 69s |
| 200 | 3,781s | 3,800s | **3,850s** | 69s |

---

## ✅ תשובות לשאלות

### 1. מה התהליך של יצירת 200 חקירות?

**תהליך:**
1. **40 איטרציות** (200 ÷ 5 = 40)
2. **כל איטרציה:**
   - יוצרת 5 חקירות ברצף
   - ממתינה ל-gRPC data לכל אחת (מקבל 5 frames minimum)
   - מתנתקת מה-stream אחרי קבלת מספיק frames
   - delay של 1 שנייה
3. **כל חקירה:**
   - יצירה: 0.3 שניות
   - חיבור: 12 שניות
   - בדיקה: 6-7 שניות (מקבל 5 frames)
   - ניתוק: 0.1 שניות

**זמן כולל ליצירה:** ~64 דקות

**הערה:** האוטומציה כן מתנתקת מה-stream אחרי קבלת מספיק frames (שורה 231: `self.grpc_client.disconnect()`)

---

### 2. תוך כמה זמן כל ה-200 חקירות נסגרות?

**⚠️ תשובה לא ודאית - לא יודעים בדיוק!**

**למה:**
1. **מנגנון Cleanup מורכב:**
   - Cleanup job בודק CPU **ו-Memory**
   - מחכה שהצריכה תהיה נמוכה לאורך זמן
   - **לא יודעים מתי בדיוק הצריכה יורדת**

2. **צריכת הודעות gRPC:**
   - נראה שמישהו צורך את ההודעות מה-gRPC ואז הוא לא יפסיק
   - אם יש consumer אחר שצורך הודעות → ה-Job לא ייסגר

3. **השפעת כמות החקירות:**
   - החקירות לא בלתי תלויות
   - עם יותר חקירות במקביל → עומס → עיכובים

**הערכה (בתיאוריה, אם הכל עובד אידיאלית):**
- **החקירה הראשונה נסגרת ב:** 69 שניות (~1.15 דקות)
- **החקירה האחרונה נסגרת ב:** 3,850 שניות (~64.17 דקות)
- **כל ה-200 נסגרות תוך:** **~64.17 דקות** מהתחלת התהליך

**אבל בפועל:**
- **לא יודעים כמה זמן בדיוק לוקח**
- תלוי בכמה זמן לוקח לצריכה לרדת
- תלוי אם יש consumers אחרים
- תלוי בעומס המערכת

---

## 📊 סיכום טבלאי

| פרמטר | ערך | הערות |
|--------|-----|-------|
| **מספר חקירות** | 200 | |
| **חקירות לאיטרציה** | 5 | |
| **מספר איטרציות** | 40 | 200 ÷ 5 |
| **זמן לחקירה** | ~19 שניות | יצירה + חיבור + בדיקה + ניתוק |
| **זמן לאיטרציה** | ~96 שניות | 5 חקירות + delay |
| **זמן יצירה כולל** | ~64 דקות | 40 × 96 שניות |
| **זמן ניקוי Job** | 50 שניות | אחרי ניתוק |
| **זמן סגירה ראשונה** | 69 שניות | Job 1 נסגר |
| **זמן סגירה אחרונה** | 3,850 שניות | Job 200 נסגר (~64.17 דקות) |
| **Jobs במקביל (ממוצע)** | ~2.6 | 50s / 19s |
| **Jobs במקביל (מקסימום)** | ~3 | בזמן יצירה רציפה |

---

## ⚠️ נקודות חשובות

### 1. Jobs נשארים פתוחים 50 שניות אחרי ניתוק

**השפעה:**
- כל Job נשאר פתוח 50 שניות אחרי שהלקוח מתנתק
- זה יוצר עומס על Kubernetes ו-Focus Server
- עם 200 חקירות: עד ~3 Jobs במקביל

### 2. זמן יצירה ארוך

**השפעה:**
- יצירת 200 חקירות לוקחת ~64 דקות
- זה בגלל שהחקירות רצות ברצף (sequential)
- כל חקירה ממתינה לסיום הקודמת

### 3. זמן סגירה כולל

**השפעה:**
- כל ה-200 Jobs נסגרות תוך ~64 דקות מהתחלה
- החקירה האחרונה נסגרת ב-3,850 שניות
- זה אומר שהתהליך כולו (יצירה + סגירה) לוקח ~64 דקות

---

## 💡 המלצות

### 1. לבדוק את הקובץ המעודכן

**לעשות:**
- לבדוק את ConfigMap של `grpc-job-template` ב-namespace של `panda`
- או לבדוק את הקובץ: `/mnt/panda/offline_deploy/linux-infra/charts/panda/templates/grpc-job/job.yml`
- לעדכן את התיעוד עם הפרמטרים האמיתיים

### 2. להבין את מנגנון Cleanup

**לעשות:**
- לבדוק איך בדיוק ה-cleanup job עובד
- להבין מתי בדיוק הצריכה של CPU ו-Memory יורדת
- לבדוק מה התנאים המדויקים לסגירה

### 3. לבדוק צריכת הודעות gRPC

**לעשות:**
- לבדוק אם יש consumers אחרים שצורכים הודעות מה-gRPC
- להבין למה הם לא מפסיקים
- לבדוק אם זה משפיע על זמן הסגירה

### 4. לבדוק השפעת כמות החקירות

**לעשות:**
- לבדוק אם כמות החקירות משפיעה על זמן הסגירה
- לבדוק אם יש עומס על המערכת
- לבדוק אם יש עיכובים ב-cleanup

### 5. לבדוק השפעת ריסוטים

**לעשות:**
- לבדוק איך ריסוטים משפיעים על זמן הסגירה
- לבדוק אם יש השפעה על cleanup

### 6. להגדיל Delay בין איטרציות

**כרגע:** 1 שנייה  
**מומלץ:** 5-10 שניות

**יתרונות:**
- נותן זמן ל-Jobs להיסגר
- מפחית עומס על המערכת
- מונע resource exhaustion

### 7. לנטר מספר Jobs פתוחים

**מומלץ:**
- לבדוק כמה Jobs פתוחים לפני יצירת חדש
- אם יש יותר מ-5 Jobs פתוחים, להמתין
- להוסיף logging של מספר Jobs פתוחים

### 8. לשפר זמן החיבור

**כרגע:** ~12 שניות  
**מומלץ:** לבדוק למה החיבורים איטיים ולשפר

---

## 📝 סיכום - מה אנחנו יודעים ומה לא

### ✅ מה אנחנו יודעים:
- תהליך יצירת 200 חקירות: ~64 דקות
- האוטומציה מתנתקת מה-stream אחרי קבלת מספיק frames
- Cleanup job בודק CPU ו-Memory
- יש delay של 1 שנייה בין איטרציות

### ❌ מה אנחנו לא יודעים:
- **כמה זמן בדיוק לוקח ל-Job להיסגר**
- מתי בדיוק הצריכה של CPU ו-Memory יורדת
- אם יש consumers אחרים שצורכים הודעות מה-gRPC
- איך כמות החקירות משפיעה על זמן הסגירה
- איך ריסוטים משפיעים על זמן הסגירה

---

**תאריך:** 2025-01-27  
**עדכון:** 2025-01-27 - תיקון הנחות שגויות  
**מחבר:** Automation Framework Analysis


