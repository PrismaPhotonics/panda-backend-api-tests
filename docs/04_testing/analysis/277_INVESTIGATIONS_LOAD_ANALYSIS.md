# ניתוח עומס: 277 חקירות ברצף
# Load Analysis: 277 Investigations in Sequence

**תאריך:** 2025-11-26  
**מטרה:** לנתח את העומס שהטסט יוצר על המערכת

---

## 🔍 איך הטסט עובד כרגע

### תהליך כל חקירה:

1. **יצירת Job** (~0.3 שניות)
   - `POST /configure` → יוצר Kubernetes Job (`grpc-job-*`)
   - Job מתחיל לרוץ ב-Kubernetes

2. **חיבור ל-gRPC Stream** (~12 שניות)
   - המתנה ל-job להיות ready
   - חיבור ל-gRPC server
   - **בעיה:** חיבור איטי (12+ שניות) - זוהה כבעיית ביצועים

3. **בדיקת 500 Frames** (~6-7 שניות)
   - קבלת נתונים מ-gRPC stream
   - בדיקת ערכי amplitude שליליים

4. **ניתוק** (מיידי)
   - `client.disconnect()` → סוגר את ה-gRPC connection
   - **אבל:** ה-Kubernetes Job נשאר פתוח!

5. **Delay** (1 שנייה)
   - `time.sleep(1)` → ממתין לפני החקירה הבאה

6. **עובר לחקירה הבאה**

---

## ⚠️ הבעיה: Jobs נשארים פתוחים

### מה קורה אחרי ניתוק:

**Job Lifecycle:**
- הלקוח מתנתק → gRPC connection נסגר
- **אבל:** ה-Kubernetes Job (`grpc-job-*`) נשאר רץ!
- ה-Job נמחק אוטומטית רק אחרי **~50 שניות** של CPU נמוך

**מנגנון מחיקה:**
- `cleanup-job-$JOB_ID` בודק את ה-CPU כל 10 שניות
- אם CPU ≤ 4m (millicores) במשך 5 בדיקות רצופות → מתחיל cleanup
- זמן כולל: **5 × 10s = 50 שניות**

---

## 📊 חישוב העומס

### זמן לכל חקירה:
```
יצירת Job:        ~0.3 שניות
חיבור ל-gRPC:     ~12 שניות (בעיית ביצועים!)
בדיקת Frames:     ~6-7 שניות
ניתוק:            ~0.1 שניות
Delay:            ~1 שנייה
─────────────────────────────
סה"כ:             ~20 שניות לחקירה
```

### זמן כולל ל-277 חקירות:
```
277 × 20 שניות = 5,540 שניות = ~92 דקות = ~1.5 שעות
```

### מספר Jobs פתוחים במקביל:

**תרחיש גרוע:**
- כל חקירה יוצרת job חדש
- Job נשאר פתוח ~50 שניות אחרי ניתוק
- אם יש delay של 1 שנייה בין חקירות:
  - חקירה 1: Job נשאר פתוח 50 שניות
  - חקירה 2: Job נשאר פתוח 50 שניות
  - ...
  - חקירה N: Job נשאר פתוח 50 שניות

**מספר Jobs במקביל:**
```
אם כל חקירה לוקחת 20 שניות, ו-Job נשאר פתוח 50 שניות:
מספר Jobs במקביל = 50 / 20 = ~2.5 Jobs בממוצע

אבל בפועל:
- חקירה 1: Job נשאר פתוח 50 שניות (מ-0 עד 50)
- חקירה 2: Job נשאר פתוח 50 שניות (מ-20 עד 70)
- חקירה 3: Job נשאר פתוח 50 שניות (מ-40 עד 90)
- ...

בזמן t=50:
- Job 1: עדיין פתוח (עד 50)
- Job 2: עדיין פתוח (עד 70)
- Job 3: עדיין פתוח (עד 90)
- Job 4: עדיין פתוח (עד 110)
- Job 5: עדיין פתוח (עד 130)

מספר Jobs במקביל = 50 / 20 = 2.5 בממוצע
```

**אבל בפועל, עם 277 חקירות:**
- יכול להיות עד **~13 Jobs במקביל** בזמן שיא
- זה תלוי בזמן החיבור (אם הוא משתנה)

---

## 🚨 סיכונים

### 1. עומס על Kubernetes
- **עד 13 Jobs במקביל** → עומס על ה-cluster
- כל Job = Pod + Resources (CPU, Memory)
- יכול לגרום ל:
  - עיכובים ביצירת Jobs חדשים
  - בעיות ביצועים
  - Resource exhaustion

### 2. עומס על Focus Server
- כל Job = gRPC server רץ
- כל gRPC server = משאבים (CPU, Memory, Network)
- יכול לגרום ל:
  - חיבורים איטיים יותר (כבר זוהה - 12+ שניות)
  - Timeouts
  - כשלונות

### 3. עומס על MongoDB
- כל Job = רשומות ב-MongoDB
- עדכונים תכופים של status
- יכול לגרום ל:
  - עיכובים ב-queries
  - בעיות ביצועים

---

## 💡 המלצות לשיפור

### 1. הגדלת Delay בין חקירות (מומלץ!)

**כרגע:** `time.sleep(1)` - 1 שנייה

**מומלץ:** `time.sleep(5)` - 5 שניות

**יתרונות:**
- נותן זמן ל-Jobs להיסגר לפני יצירת חדשים
- מפחית את מספר ה-Jobs במקביל
- מפחית את העומס על המערכת

**חסרונות:**
- מגדיל את זמן הריצה הכולל
- 277 × 5 שניות = 1,385 שניות = ~23 דקות נוספות

### 2. בדיקת מספר Jobs פתוחים לפני יצירת חדש

**אפשרות:**
- לבדוק כמה Jobs פתוחים כרגע
- אם יש יותר מ-N Jobs (למשל, 5), להמתין עד שיורד

**יתרונות:**
- מונע עומס יתר
- מתאים את עצמו למצב המערכת

**חסרונות:**
- דורש גישה ל-Kubernetes API
- מסובך יותר ליישום

### 3. Batch Processing (עיבוד בקבוצות)

**אפשרות:**
- לחלק את 277 החקירות לקבוצות של 10-20
- להריץ כל קבוצה, לחכות שה-Jobs ייסגרו, ואז להמשיך

**יתרונות:**
- שליטה טובה יותר על העומס
- מונע עומס יתר

**חסרונות:**
- מסובך יותר ליישום
- דורש ניטור של Jobs

### 4. שימוש ב-Job Cancellation (אם ייושם)

**אפשרות:**
- להשתמש ב-`DELETE /job/{job_id}` כדי לסגור Jobs מפורשות
- **אבל:** כרגע לא מיושם (מחזיר 404)

**יתרונות:**
- שליטה מלאה על Jobs
- ניקוי מיידי

**חסרונות:**
- דורש יישום ב-Backend
- לא זמין כרגע

---

## 📋 המלצה סופית

### אפשרות 1: הגדלת Delay (הכי פשוט)
```python
# במקום:
time.sleep(1)

# להשתמש ב:
time.sleep(5)  # או אפילו 10 שניות
```

**יתרונות:**
- פשוט ליישום
- מפחית עומס
- לא דורש שינויים גדולים

### אפשרות 2: Delay דינמי (מומלץ יותר)
```python
# לחשב delay בהתאם לזמן החיבור
# אם חיבור איטי, להגדיל delay
connection_time = ...  # זמן החיבור
delay = max(5, connection_time * 0.5)  # לפחות 5 שניות, או 50% מזמן החיבור
time.sleep(delay)
```

**יתרונות:**
- מתאים את עצמו למצב המערכת
- מפחית עומס בצורה חכמה

---

## 🔧 שינויים מומלצים

1. **הגדלת Delay מ-1 ל-5 שניות** (מינימום)
2. **הוספת Logging של מספר Jobs פתוחים** (לניטור)
3. **הוספת אפשרות להגדיר Delay מהקונסול** (`--delay-between-investigations`)

---

## 📊 השוואה: לפני ואחרי

| פרמטר | לפני (1s delay) | אחרי (5s delay) |
|--------|----------------|----------------|
| **זמן לחקירה** | ~20 שניות | ~24 שניות |
| **זמן כולל** | ~92 דקות | ~110 דקות |
| **Jobs במקביל** | עד 13 | עד 5 |
| **עומס על המערכת** | גבוה | בינוני |

---

## ✅ מסקנות

1. **הטסט כן מעמיס על המערכת** - עד 13 Jobs במקביל
2. **יש בעיית ביצועים** - חיבורים איטיים (12+ שניות)
3. **מומלץ להגדיל Delay** - לפחות 5 שניות בין חקירות
4. **מומלץ לנטר** - מספר Jobs פתוחים במהלך הריצה

